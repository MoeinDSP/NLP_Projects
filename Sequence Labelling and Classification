{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MoeinDSP/NLP_Projects/blob/main/Sequence%20Labelling%20and%20Classification\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giKsby3Lpdlp"
      },
      "source": [
        "# Sequence Labelling and Classification\n",
        "\n",
        "In this session we will train a Text classifier that makes use of a Bidirectional LSTM (Long Short-term Memory) model.\n",
        "\n",
        "In the second part of the tutorial we will first investigate Part-of-Speech (POS) tagging and Named-entity recognition (NER).\n",
        "- For this we will make use of the spaCy natural langauge processing API: https://spacy.io/\n",
        "- spaCy is an opensource API that provides state-of-the-art performance on sequence labeling tasks such as POS tagging and NER.\n",
        "- Parts of this tutorial are based on code from: https://towardsdatascience.com/named-entity-recognition-with-nltk-and-spacy-8c4a7d88e7da\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApdPEmRJXkPN"
      },
      "source": [
        "**Optional for Colab users**\n",
        "\n",
        "Before starting, we can set up the connection with the Google Dive storage, to keep there our documents.\n",
        "Just execute the following passages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOtount4XkPN",
        "outputId": "c8233d00-dd66-4422-b81c-72cad82eb2ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwjVehAkXkPO"
      },
      "source": [
        "Make sure that the variable path contains the correct sequence of folders separate by a `'/'` to get to your lecture files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OgUv_TfNXkPO",
        "outputId": "777a7145-22dc-4535-fd0d-c54aae6a0dec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Colab Notebooks/NLP/Practical_06__Sequential-Classifers-and-Labellers'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "path = 'Colab Notebooks/NLP/Practical_06__Sequential-Classifers-and-Labellers'\n",
        "\n",
        "os.chdir(f'/content/drive/MyDrive/{path}')\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMS2GYrKXkPO"
      },
      "source": [
        "## Sequence labelling with embeddings and a Recurrent Neural Network\n",
        "\n",
        "In this section of the notebook I will run through an example of using LSTM (Long Short-term Memory) network for text sequence labelling.\n",
        "We can train our own model for POS-tagging or NER.\n",
        "Moreover, we can use pre-trained embedding models to encode the input text.\n",
        "\n",
        "- We are going to use PyTorch (https://pytorch.org) to build and train our model. Pytorch is a state-of-the-art framework for deep leaning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6xs4SfcXkPP"
      },
      "source": [
        "### Data preparation\n",
        "\n",
        "As usual we start from data preparation.\n",
        "We can use the [CoNLL 2003](https://www.clips.uantwerpen.be/conll2003/ner/) corpus, which provides corpora for POS-tagging, Chunking and NER in English and German.\n",
        "Today we are going to focus on NER in English.\n",
        "\n",
        "You can find a copy the English split in the `docs/` directory.\n",
        "Usually the corpus should require preprocessing the data, here I am providing you with a version from Kaggle where documents have already been tagged (source: https://www.kaggle.com/datasets/alaakhaled/conll003-englishversion?resource=download)\n",
        "\n",
        "Let's start by loading the three files (train/validation/test) in memory and reading all of them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BONoKuGNXkPP",
        "outputId": "b06521f9-44cf-4b41-94b5-e6b137e4cc4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-DOCSTART- -X- -X- O\n",
            "\n",
            "EU NNP B-NP B-ORG\n",
            "rejects VBZ B-VP O\n",
            "German JJ B-NP B-MISC\n",
            "call NN I-NP O\n",
            "to TO B-VP O\n",
            "boycott VB I-VP O\n",
            "British JJ B-NP B-MISC\n",
            "lamb NN I-NP O\n",
            ". . O O\n",
            "\n",
            "Peter NNP B-NP B-PER\n",
            "Blackburn NNP I-NP I-PER\n",
            "\n",
            "BRUSSELS NNP B-NP B-LOC\n",
            "1996-08-22 CD I-NP O\n",
            "\n",
            "The DT B-NP O\n",
            "European NNP I-NP B-ORG\n",
            "Commission NNP I-NP I-ORG\n",
            "said VBD B-VP O\n",
            "on IN B-PP O\n",
            "Thursday NNP B-NP O\n",
            "it PRP B-NP O\n",
            "disagreed VBD B-VP O\n",
            "with IN B-PP O\n",
            "German JJ B-NP B-MISC\n",
            "advice NN I-NP O\n",
            "to TO B-PP O\n",
            "consumers NNS B-NP\n"
          ]
        }
      ],
      "source": [
        "raw_data = dict()\n",
        "\n",
        "for split in ['train', 'valid', 'test']:\n",
        "    with open(f'docs/CoNLL - 2003/{split}.txt') as f:\n",
        "        raw_data[split] = f.read().strip()\n",
        "\n",
        "print(raw_data['train'][:500])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vw6GFYkCXkPP"
      },
      "source": [
        "Now we can parse the data.\n",
        "Documents inside each split are separated by the sequence `-DOCSTART- -X- -X- O`.\n",
        "Sentences inside each document are separated by the sequence`\\n\\n` (two new-line characters).\n",
        "Each line inside a sentence represnets a token followed by the POS tag, the CHUNK tag and the NER tag, all separated by spaces.\n",
        "\n",
        "Here NER tags are written using a system called BIO-tagging.\n",
        "The 'B' stands for \"begin\" and introduces (starts) a new named entity, the tags are written as \"B-PER\" to indicate a person or \"B-LOC\" to indicate a location and so on.\n",
        "The 'I' stands for \"inside\" and continues a started named entity, the tags are written as \"I-PER\" to indicate a person or \"I-LOC\" to indicate a location and so on.\n",
        "The 'O' stands for outside, it means that the token is outside any named entity.\n",
        "There are other tagging systems.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xagcI6jWXkPP"
      },
      "outputs": [],
      "source": [
        "keys = ['text', 'pos_tag', 'chunk_tag', 'ner_tag']\n",
        "\n",
        "data = dict()\n",
        "\n",
        "for split in raw_data:\n",
        "    data[split] = list()\n",
        "    for doc in raw_data[split].split('-DOCSTART- -X- -X- O')[1:]:\n",
        "        for sentence in doc.strip().split('\\n\\n'):\n",
        "            data[split].append(list())\n",
        "            for elem in sentence.split('\\n'):\n",
        "                data[split][-1].append(dict(zip(keys, elem.split())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXZPjL6RXkPP",
        "outputId": "cc1e7ae0-dc0c-4d87-dce7-5f8a7d8e4d9a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'text': 'EU', 'pos_tag': 'NNP', 'chunk_tag': 'B-NP', 'ner_tag': 'B-ORG'},\n",
              " {'text': 'rejects', 'pos_tag': 'VBZ', 'chunk_tag': 'B-VP', 'ner_tag': 'O'},\n",
              " {'text': 'German', 'pos_tag': 'JJ', 'chunk_tag': 'B-NP', 'ner_tag': 'B-MISC'},\n",
              " {'text': 'call', 'pos_tag': 'NN', 'chunk_tag': 'I-NP', 'ner_tag': 'O'},\n",
              " {'text': 'to', 'pos_tag': 'TO', 'chunk_tag': 'B-VP', 'ner_tag': 'O'},\n",
              " {'text': 'boycott', 'pos_tag': 'VB', 'chunk_tag': 'I-VP', 'ner_tag': 'O'},\n",
              " {'text': 'British',\n",
              "  'pos_tag': 'JJ',\n",
              "  'chunk_tag': 'B-NP',\n",
              "  'ner_tag': 'B-MISC'},\n",
              " {'text': 'lamb', 'pos_tag': 'NN', 'chunk_tag': 'I-NP', 'ner_tag': 'O'},\n",
              " {'text': '.', 'pos_tag': '.', 'chunk_tag': 'O', 'ner_tag': 'O'}]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "data['train'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGQgUUNIXkPQ"
      },
      "source": [
        "Now all the labels are properly organised"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtmKiY5eXkPQ"
      },
      "source": [
        "At this point we need a system to encode and decode the labels into categorical entities.\n",
        "We can use the label encoder from Scikit-Learn for that (https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjLyqAhgXkPQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "pos_le = LabelEncoder().fit([token['pos_tag'] for split in data.values() for sentence in split for token in sentence])\n",
        "chunk_le = LabelEncoder().fit([token['pos_tag'] for split in data.values() for sentence in split for token in sentence])\n",
        "ner_le = LabelEncoder().fit([token['ner_tag'] for split in data.values() for sentence in split for token in sentence])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVFW52o8XkPQ"
      },
      "source": [
        "Now we have a module mapping from tags to IDs and vice-versa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93KtbCVBXkPQ",
        "outputId": "e1d5d1fa-497e-42cb-9b48-1274e8a0374d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "ner_tag = ['I-PER']\n",
        "ner_tag = ['I-LOC']\n",
        "ner_tag = ['B-PER']\n",
        "# ner_tag = ['O']\n",
        "\n",
        "ner_le.transform(ner_tag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFDxhaMnXkPQ",
        "outputId": "adb4aeec-8748-4ff4-8c2f-08cb62bca3f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['B-LOC'], dtype='<U6')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "ner_tag_id = [0]\n",
        "\n",
        "ner_le.inverse_transform(ner_tag_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOVxouSbXkPQ"
      },
      "source": [
        "How many NER tags do we have?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XP7h6lsQXkPQ",
        "outputId": "55adec31-b6aa-4449-be73-20d7f917451e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "len(ner_le.classes_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObAM_0yLXkPQ"
      },
      "source": [
        "Which are those tags?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cNrY9QmXkPQ",
        "outputId": "04bc1711-bb7c-44b6-9930-035c5561fd1b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['B-LOC', 'B-MISC', 'B-ORG', 'B-PER', 'I-LOC', 'I-MISC', 'I-ORG',\n",
              "       'I-PER', 'O'], dtype='<U6')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "ner_le.classes_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKcRUmgnXkPQ"
      },
      "source": [
        "Collect the same info for POS tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ywrLqj2XkPQ"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuOZxaJVXkPQ"
      },
      "source": [
        "Finally we separate our train-validation-test splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghCasG1MXkPQ"
      },
      "outputs": [],
      "source": [
        "train_data, valid_data, test_data = data.values()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NwBTbAlXkPQ"
      },
      "source": [
        "### Defining and training the RNN model for NER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKmcrDFTXkPQ"
      },
      "source": [
        "We start by installing PyTorch and importing the required modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjlYyBUhXkPR",
        "outputId": "31e206ab-08a7-4889-8cf0-a010f396d55d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOz8WMvJHrXs",
        "outputId": "bb54774e-0fe3-41ed-801b-71f292b3fd28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyMkbwDLXkPR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfmmttGYXkPR"
      },
      "source": [
        "Then we load the Word Embedding model we want to use. We can re-use the 50 dimensional GloVe emebddings from last time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTTztembXkPR"
      },
      "outputs": [],
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "we_model = api.load(\"glove-wiki-gigaword-300\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uExHPXquXkPR"
      },
      "source": [
        "Before creating the LSTM we decide where to train our model, either cpu or gpu, depending on which is avaialble."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtlzrvG5XkPR",
        "outputId": "7fc76e22-b7cc-4843-e92c-df367a5db90d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQ3aDdLKXkPR"
      },
      "source": [
        "Now we can create our RNN module.\n",
        "Here are the available modules for PyTorch: https://pytorch.org/docs/stable/nn.html#recurrent-layers\n",
        "\n",
        "We define a custom LSTM using PyTorch API.\n",
        "In our model we stack one or more LSTM layers (we can make it variable) and we put a linear layer (a.k.a. dense layer or fully connected layer on top of it).\n",
        "\n",
        "When you define a neural network in PyTorch you need it to extend the `torch.nn.Module` class and implement the forward method (the one that computes the output)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQkVBi_bXkPR"
      },
      "outputs": [],
      "source": [
        "class CustomLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, n_lstm=1):\n",
        "        super().__init__()\n",
        "        # List of LSTM layers\n",
        "        self.lstm = nn.ModuleList([\n",
        "            nn.LSTM(\n",
        "                input_size=input_size if i == 0 else hidden_size,\n",
        "                hidden_size=hidden_size,\n",
        "                batch_first=True,\n",
        "                bidirectional=True,\n",
        "                dropout=0.2\n",
        "            )\n",
        "            for i in range(n_lstm)\n",
        "        ])\n",
        "        # Lat linear projection\n",
        "        self.cls_head = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Run though all the LSTM layers\n",
        "        for lstm_layer in self.lstm:\n",
        "            # Compute new hidden representation\n",
        "            x, _ = lstm_layer(x)\n",
        "            # Average the hidden output from the two directions of the LSTM\n",
        "            x = (x[..., :x.size(-1) // 2] + x[..., x.size(-1) // 2:]) / 2\n",
        "        # Apply last lineat projection\n",
        "        y = self.cls_head(x)\n",
        "\n",
        "        return y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uw6Vx9LOXkPR"
      },
      "source": [
        "Let's create an instance of our LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPTLsJBLXkPR",
        "outputId": "cd2aa3e6-93ec-4404-aff6-b04baf81c27e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomLSTM(\n",
              "  (lstm): ModuleList(\n",
              "    (0-2): 3 x LSTM(300, 300, batch_first=True, dropout=0.2, bidirectional=True)\n",
              "  )\n",
              "  (cls_head): Linear(in_features=300, out_features=9, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "lstm = CustomLSTM(300, 300, len(ner_le.classes_), n_lstm=3)\n",
        "lstm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOnljCiCXkPR"
      },
      "source": [
        "Now we can move the LSTM to the target device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPqved6HXkPR"
      },
      "outputs": [],
      "source": [
        "lstm = lstm.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFpAIMl6XkPa"
      },
      "source": [
        "Once we have the model we need to create an optimizer that will take care of updating the weights. Here are the available optimizers: https://pytorch.org/docs/stable/optim.html.\n",
        "I'm going to use RMSProp.\n",
        "\n",
        "The optimizer needs to receive the parameters of the neural network and the selected learning rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFekRmmIXkPa"
      },
      "outputs": [],
      "source": [
        "lr = 0.0005\n",
        "optimizer = torch.optim.RMSprop(params=lstm.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3ASQNmFXkPa"
      },
      "source": [
        "Now we need to prepare our data.\n",
        "Before doing so we prepare a function that maps a mini-batch of samples (i.e., a subset of the lists of dictionaries we prepared) to input tensors to use with our model. The function willl take care of:\n",
        "- Mapping all words to their embeddings with size $d$\n",
        "- Collect the emebddings of the same sentence into a matrix with shape $(n_\\textit{words in sentence}, d)$\n",
        "- Collect the different matrices of the same batch into a single tensor with shape $(n_\\textit{batch elements}, n_\\textit{words in longest sentence}, d)$ (this will be input).\n",
        "- Mapping all the labels to their IDs\n",
        "- Collecting all the IDs of the same sentence into a vector with size $n_\\textit{words in sentence}$\n",
        "- Collecting all the different vectors into a matrix with shape $(n_\\textit{batch elements}, n_\\textit{words in longest sentence})$ (this will be target output).\n",
        "\n",
        "Note that different sentences have different lengths, to cope with this issue we apply a process called padding: we are going to add to the input tensor and the target output matrix  dummy values to have all the same \"sentence length\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IaGkRWFlXkPb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def collate(mini_batch):\n",
        "    # Get the length of the longest sentence\n",
        "    longest_len = max(len(sample) for sample in mini_batch)\n",
        "    # Create an input tensor with all zero values\n",
        "    input_embeds = np.zeros((len(mini_batch), longest_len, 300))\n",
        "    # Create a target output matrix with all -100 (PyTorch ignores this value by default)\n",
        "    output_lbl = np.full((len(mini_batch), longest_len), -100)\n",
        "    # Fill the tensor and the matrix\n",
        "    for i, sample in enumerate(mini_batch):\n",
        "        for j, token in enumerate(sample):\n",
        "            # Manage missing tokens in vocabulary\n",
        "            if token['text'].lower() in we_model:\n",
        "                input_embeds[i,j] = we_model[token['text'].lower()]\n",
        "            output_lbl[i,j] = ner_le.transform([token['ner_tag']])[0]\n",
        "    # Convert to PyTorch tensor\n",
        "    input_embeds = torch.tensor(input_embeds, dtype=torch.float)\n",
        "    output_lbl = torch.tensor(output_lbl)\n",
        "\n",
        "    return input_embeds, output_lbl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtUbxPYkXkPb"
      },
      "source": [
        "How does an encoded batch looks like? Let's enode the first three sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2T-85SA1XkPb",
        "outputId": "c4b800fd-a4c8-4162-dd12-26ac38e53fca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[{'text': 'EU', 'pos_tag': 'NNP', 'chunk_tag': 'B-NP', 'ner_tag': 'B-ORG'},\n",
              "  {'text': 'rejects', 'pos_tag': 'VBZ', 'chunk_tag': 'B-VP', 'ner_tag': 'O'},\n",
              "  {'text': 'German',\n",
              "   'pos_tag': 'JJ',\n",
              "   'chunk_tag': 'B-NP',\n",
              "   'ner_tag': 'B-MISC'},\n",
              "  {'text': 'call', 'pos_tag': 'NN', 'chunk_tag': 'I-NP', 'ner_tag': 'O'},\n",
              "  {'text': 'to', 'pos_tag': 'TO', 'chunk_tag': 'B-VP', 'ner_tag': 'O'},\n",
              "  {'text': 'boycott', 'pos_tag': 'VB', 'chunk_tag': 'I-VP', 'ner_tag': 'O'},\n",
              "  {'text': 'British',\n",
              "   'pos_tag': 'JJ',\n",
              "   'chunk_tag': 'B-NP',\n",
              "   'ner_tag': 'B-MISC'},\n",
              "  {'text': 'lamb', 'pos_tag': 'NN', 'chunk_tag': 'I-NP', 'ner_tag': 'O'},\n",
              "  {'text': '.', 'pos_tag': '.', 'chunk_tag': 'O', 'ner_tag': 'O'}],\n",
              " [{'text': 'Peter', 'pos_tag': 'NNP', 'chunk_tag': 'B-NP', 'ner_tag': 'B-PER'},\n",
              "  {'text': 'Blackburn',\n",
              "   'pos_tag': 'NNP',\n",
              "   'chunk_tag': 'I-NP',\n",
              "   'ner_tag': 'I-PER'}],\n",
              " [{'text': 'BRUSSELS',\n",
              "   'pos_tag': 'NNP',\n",
              "   'chunk_tag': 'B-NP',\n",
              "   'ner_tag': 'B-LOC'},\n",
              "  {'text': '1996-08-22',\n",
              "   'pos_tag': 'CD',\n",
              "   'chunk_tag': 'I-NP',\n",
              "   'ner_tag': 'O'}]]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "train_data[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wuZ5_q4XkPb",
        "outputId": "5c31fa1c-60db-4313-bad8-c326c84c471d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the input is: torch.Size([3, 9, 300])\n",
            "The shape of the output is: torch.Size([3, 9])\n"
          ]
        }
      ],
      "source": [
        "embeds, lbl = collate(train_data[:3])\n",
        "\n",
        "print(f\"The shape of the input is: {embeds.size()}\")\n",
        "print(f\"The shape of the output is: {lbl.size()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGKJiKjMXkPb",
        "outputId": "4d20e393-a5aa-4b34-82c2-0b3a9bc97063"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.5473, -0.2364, -0.2143,  ..., -0.3137, -0.4393,  0.1852],\n",
              "         [ 0.4056, -0.0393, -0.2357,  ..., -0.2026,  0.1970,  0.4861],\n",
              "         [-0.1740,  0.2612, -0.5919,  ..., -0.1950,  0.2041,  0.3530],\n",
              "         ...,\n",
              "         [ 0.4436, -0.2418,  0.2366,  ...,  0.1857, -0.2956, -0.1999],\n",
              "         [ 0.1964, -0.2666,  0.1819,  ...,  0.1678,  0.0395,  0.4751],\n",
              "         [-0.1256,  0.0136,  0.1031,  ..., -0.3422, -0.0224,  0.1368]],\n",
              "\n",
              "        [[ 0.1093, -0.1402,  0.0930,  ...,  0.3865,  0.3444,  0.0214],\n",
              "         [-0.4132,  0.2175, -0.0505,  ..., -0.4873, -0.4033, -0.3469],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         ...,\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
              "\n",
              "        [[ 0.4693, -0.0993,  0.0016,  ..., -0.4687, -0.7363,  0.1922],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         ...,\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "embeds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhGEiUIJXkPb",
        "outputId": "31cc868d-c1ff-43b4-8b22-cd250c0fde5f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   2,    8,    1,    8,    8,    8,    1,    8,    8],\n",
              "        [   3,    7, -100, -100, -100, -100, -100, -100, -100],\n",
              "        [   0,    8, -100, -100, -100, -100, -100, -100, -100]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "lbl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OVQpLMlXkPb"
      },
      "source": [
        "Now we can finally wrap a DataLoader around our samples. PyTorch data loaders take care of generating batches on a given data set. We just need to set the batch size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "po78xTDaXkPb"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, collate_fn=collate, shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size, collate_fn=collate)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, collate_fn=collate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxzgtIjZXkPb"
      },
      "source": [
        "We can train the lst iterating over the data set for a given number of epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iySokQbJXkPb",
        "outputId": "dc5023f8-7e35-466d-c384-867064ea30f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 110/110 [00:31<00:00,  3.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 110/110 [00:34<00:00,  3.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 3/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 110/110 [00:30<00:00,  3.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 4/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 110/110 [00:29<00:00,  3.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 5/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 110/110 [00:31<00:00,  3.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 6/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 110/110 [00:30<00:00,  3.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 7/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 110/110 [00:29<00:00,  3.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 8/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 110/110 [00:29<00:00,  3.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 9/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 110/110 [00:30<00:00,  3.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 10/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 110/110 [00:31<00:00,  3.54it/s]\n"
          ]
        }
      ],
      "source": [
        "# Import nice loading bar using tqdm\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Set model in training mode\n",
        "lstm.train()\n",
        "\n",
        "# Accumulator of loss\n",
        "history = []\n",
        "\n",
        "n_epochs = 10\n",
        "\n",
        "# Iterate over epochs\n",
        "for i in range(n_epochs):\n",
        "    print(f\"Starting epoch {i + 1}/{n_epochs}\")\n",
        "    # Iterate over training batches\n",
        "    for embeds, lbl in tqdm(train_loader):\n",
        "        # Zero your gradients for every batch!\n",
        "        optimizer.zero_grad()\n",
        "        # Move input and output to target device\n",
        "        embeds = embeds.to(device)\n",
        "        lbl = lbl.to(device)\n",
        "        # Compute logits (i.e., softmax values before exponential normalisation)\n",
        "        logits = lstm(embeds)\n",
        "        # Flatten logits to a shape (batch_size * max_sentence_len, n_classes)\n",
        "        logits = logits.reshape(-1, len(ner_le.classes_))\n",
        "        # Flatten targets to a shape (batch_size * max_sentence_len)\n",
        "        lbl = lbl.reshape(-1)\n",
        "        # Compute loss\n",
        "        loss = F.cross_entropy(logits, lbl)\n",
        "        # Compute gradients\n",
        "        loss.backward()\n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "        # Save loss\n",
        "        history.append(loss.detach())\n",
        "\n",
        "history = [loss.cpu().item() for loss in history]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVeUY6ONXkPb"
      },
      "source": [
        "Now we can plot the evolution of the loss at each update"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "hlB3uqseXkPb",
        "outputId": "ea94a4e4-f24f-45ae-a0dc-452b7ce48219"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Loss')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(range(len(history)), history)\n",
        "plt.xlabel('Update step')\n",
        "plt.ylabel('Loss')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CD3oP7LMXkPb"
      },
      "source": [
        "We can also test out model using the dedicated split. We iterate over the mini batches, collect the prediction as the value with the highest logit value and we store these values until we go through the entire data set. Then we compute the classification report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHLkLpTcXkPb",
        "outputId": "0425cfcf-5851-4b16-a03f-bce874ce32c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [00:08<00:00,  3.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC       0.93      0.93      0.93      1837\n",
            "      B-MISC       0.91      0.80      0.85       922\n",
            "       B-ORG       0.89      0.84      0.86      1341\n",
            "       B-PER       0.96      0.95      0.95      1842\n",
            "       I-LOC       0.85      0.82      0.83       257\n",
            "      I-MISC       0.87      0.61      0.72       346\n",
            "       I-ORG       0.83      0.77      0.80       751\n",
            "       I-PER       0.99      0.95      0.97      1307\n",
            "           O       0.99      0.99      0.99     42759\n",
            "\n",
            "    accuracy                           0.98     51362\n",
            "   macro avg       0.91      0.85      0.88     51362\n",
            "weighted avg       0.97      0.98      0.97     51362\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Set model in evaluation mode\n",
        "lstm.eval()\n",
        "\n",
        "# Accumulators for target labels and predictions\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "# Disable gradients\n",
        "with torch.no_grad():\n",
        "    # Iterate over validation batches\n",
        "    for embeds, lbl in tqdm(valid_loader):\n",
        "        # Move input and output to target device\n",
        "        embeds = embeds.to(device)\n",
        "        # Compute logits (i.e., softmax values before exponential normalisation)\n",
        "        logits = lstm(embeds)\n",
        "        # Get predictions as the index corresponding to the highest logit score\n",
        "        pred_lbl = torch.argmax(logits, dim=-1)\n",
        "        # Append predicted labels\n",
        "        y_pred.append(pred_lbl.reshape(-1).cpu().numpy())\n",
        "        # Append target labels\n",
        "        y_true.append(lbl.reshape(-1).numpy())\n",
        "\n",
        "# Concatenate all the vectors of target labels and predicted labels\n",
        "y_true = np.concatenate(y_true)\n",
        "y_pred = np.concatenate(y_pred)\n",
        "# Remove elements to ignore (the -100 labels)\n",
        "mask = y_true == -100\n",
        "y_true = y_true[~mask]\n",
        "y_pred = y_pred[~mask]\n",
        "\n",
        "# Finally compute classification report\n",
        "print()\n",
        "print(classification_report(y_true, y_pred, target_names=ner_le.classes_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ym-G2h-xXkPb"
      },
      "source": [
        "What do we see from these results?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovToorHEXkPb"
      },
      "source": [
        "We can play a bit with the model directly.\n",
        "\n",
        "Let's define a function to compute the predictions given a sentence. We will use the NLTK tokenizer to split the sentence into word tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYWr8JyhXkPb",
        "outputId": "3077870f-7908-4920-96a1-d6015341b45f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def predict(sample):\n",
        "    # Tokenize sample\n",
        "    tokenized_sample = word_tokenize(sample)\n",
        "    # Create an input tensor with all zero values\n",
        "    input_embeds = np.zeros((1, len(tokenized_sample), 300))\n",
        "    # Fill the tensor and the matrix\n",
        "    for i, token in enumerate(tokenized_sample):\n",
        "        # Manage missing tokens in vocabulary\n",
        "        if token.lower() in we_model:\n",
        "            input_embeds[0, i] = we_model[token.lower()]\n",
        "    # Convert to PyTorch tensor\n",
        "    input_embeds = torch.tensor(input_embeds, dtype=torch.float, device=device)\n",
        "    # Run model over input\n",
        "    logits = lstm(input_embeds)\n",
        "    # Get predictions as the index corresponding to the highest logit score\n",
        "    pred_lbl = torch.argmax(logits, dim=-1)\n",
        "    # Decode labels\n",
        "    pred_labels = ner_le.inverse_transform(pred_lbl.reshape(-1).cpu().numpy())\n",
        "    # Group together tokens and predicted NER labels\n",
        "    labelled_sample = [{'text': token, 'ner_tag': str(lbl)} for token, lbl in zip(tokenized_sample, pred_labels)]\n",
        "\n",
        "    return labelled_sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEC_9swOXkPc"
      },
      "source": [
        "And now call it on a custom sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bb0EkaTfXkPc",
        "outputId": "700b7635-b8f3-4c04-a150-19945a7cc95a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'text': 'Hello', 'ner_tag': 'B-PER'},\n",
              " {'text': ',', 'ner_tag': 'O'},\n",
              " {'text': 'my', 'ner_tag': 'O'},\n",
              " {'text': 'name', 'ner_tag': 'O'},\n",
              " {'text': 'is', 'ner_tag': 'O'},\n",
              " {'text': 'Nicolò', 'ner_tag': 'B-MISC'},\n",
              " {'text': 'Brunello', 'ner_tag': 'O'},\n",
              " {'text': ',', 'ner_tag': 'O'},\n",
              " {'text': 'I', 'ner_tag': 'O'},\n",
              " {'text': 'am', 'ner_tag': 'O'},\n",
              " {'text': 'from', 'ner_tag': 'O'},\n",
              " {'text': 'Italy', 'ner_tag': 'B-LOC'},\n",
              " {'text': 'and', 'ner_tag': 'O'},\n",
              " {'text': 'I', 'ner_tag': 'O'},\n",
              " {'text': 'like', 'ner_tag': 'O'},\n",
              " {'text': 'pizza', 'ner_tag': 'O'},\n",
              " {'text': '.', 'ner_tag': 'O'}]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "sample = \"Hello, my name is Nicolò Brunello, I am from Italy and I like pizza.\"\n",
        "\n",
        "predict(sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ff5-0SUKXkPc"
      },
      "source": [
        "Look how our custom model fails flawlessly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6G3EZtdXkPc"
      },
      "source": [
        "### Defining and training the RNN model for POS-tagging or Chunking\n",
        "\n",
        "You can do this at home to start getting familiar with PyTorch and RNNs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QitvSR1gXkPc"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMb8j2-2XkPc"
      },
      "source": [
        "## Text Classification with a Recurrent Neural Network\n",
        "\n",
        "In this last section of the notebook I will run through a quick example of using a Bidirectional LSTM (Long Short-term Memory) network for text classification.\n",
        "- RNNs extend embedding-based classification of text by taking word-order into account. They were, until relatively recently, the state-of-the-art when it came to training text classifiers.\n",
        "- Tensorflow is sophisticated toolkit for building Deep Neural Network models. We will use it to build the model. The tutorial follows mostly this Tensorflow tutorial: https://www.tensorflow.org/tutorials/text/text_classification_rnn\n",
        "    - Tensorflow is to deep learning learning what Java is to programming (joking...?)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysjOGZrnXkPc"
      },
      "source": [
        "### Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdiXno9jXkPc"
      },
      "source": [
        "First let's load the Twitter dataset we used in the second session:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WX-qsv-IXkPc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6cb0918-5a42-4f40-f8c9-7c365cba0ca8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/twitter_samples.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('twitter_samples')\n",
        "\n",
        "from nltk.corpus import twitter_samples\n",
        "positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "negative_tweets = twitter_samples.strings('negative_tweets.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdKS2HdEXkPc"
      },
      "source": [
        "Remove emoticons from the positive and negative examples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQqqGPlYXkPc"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "emoticon_regex = '(\\:\\w+\\:|\\<[\\/\\\\]?3|[\\(\\)\\\\\\D|\\*\\$][\\-\\^]?[\\:\\;\\=]|[\\:\\;\\=B8][\\-\\^]?[3DOPp\\@\\$\\*\\\\\\)\\(\\/\\|])(?=\\s|[\\!\\.\\?]|$)'\n",
        "positive_tweets_noemoticons = [re.sub(emoticon_regex,'',tweet) for tweet in positive_tweets]\n",
        "negative_tweets_noemoticons = [re.sub(emoticon_regex,'',tweet) for tweet in negative_tweets]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMo6g9mcXkPc"
      },
      "source": [
        "And create the examples and labels as we did before. This time we will use numeric labels (0,1) instead of text labels ('negative','positive'), since the deep learning library we will use requires numeric class labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVAlgu-IXkPc"
      },
      "outputs": [],
      "source": [
        "tweets_x = positive_tweets_noemoticons + negative_tweets_noemoticons\n",
        "tweets_y = [1]*len(positive_tweets) + [0]*len(negative_tweets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpMJO18SXkPc"
      },
      "source": [
        "And again, split the data into training, validation and test:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2eXMPFuXkPc"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "temp_x, test_x, temp_y, test_y = train_test_split(tweets_x, tweets_y, test_size=0.2)\n",
        "train_x, valid_x, train_y, valid_y = train_test_split(temp_x, temp_y, test_size=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFRtKN0gXkPc"
      },
      "source": [
        "Now that we have the training and validation data prepared, we can import the Tensorflow library, and use it to load the training and validaton datasets into the tensorflow format. Note that:\n",
        "- Tensorflow comes installed on Google Colab.\n",
        "- If you run this notebook on your own machine you will need to first install tensorflow using '!pip install'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
      ],
      "metadata": {
        "id": "wmwzZwBVMpbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "XxX5PQ1-XkPc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f31abf8-9500-446a-c14e-eada10f6046d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gykDCG4YXkPc"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "train_tf = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
        "valid_tf = tf.data.Dataset.from_tensor_slices((valid_x, valid_y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeZgqPQYXkPc"
      },
      "source": [
        "Training will run on *batches* of the data at a time, so we need to create them.\n",
        "- We first use the shuffle command to randomise the order of the training data. (The buffer-size limits the number of instances loaded into memory when shuffling and is only for efficiency -- you could remove it.)\n",
        "- We then create the batches. Each batch will contain 64 examples.\n",
        "- The validation data needs to have the same format as the training data, so we batch it too."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3k_AJMVXkPc"
      },
      "outputs": [],
      "source": [
        "train_dataset = train_tf.shuffle(buffer_size=10000).batch(batch_size=64).prefetch(tf.data.AUTOTUNE)\n",
        "valid_dataset = valid_tf.batch(batch_size=64).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCIJun8hXkPc"
      },
      "source": [
        "Let's have a look at the first batch in the training data. It consists of:\n",
        "- an array of strings (tweets)\n",
        "- an array of binary values (class labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4sqXOO8JXkPd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37f18cbd-f417-4dbb-9290-e7d49f8e327f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<tf.Tensor: shape=(64,), dtype=string, numpy=\n",
            "array([b'How about you just have a nice convo like a normal person instead of posting how u feel about 200 of your closest twitter friends ',\n",
            "       b'OKAY PLEAS EDOMNT FCK QIH MY FEELINGS SHXBS ENOUGH!!!!  #ZaynIsComingBackOnJuly26',\n",
            "       b'i want all of kylie jenners clothes ',\n",
            "       b'Hi BAM ! @BarsAndMelody \\nCan you follow my bestfriend @969Horan696 ? \\nShe loves you a lot  \\nSee you in Warsaw &lt \\nLove you &lt x2',\n",
            "       b'@lnnamnd hi! we made some changes in our design, hope you like it  https://t.co/EXt098Yq1b',\n",
            "       b\"@SMARTCares it wasn't indicated on the SMS I received. \",\n",
            "       b\"@javeedna that's a build up for Sunday \",\n",
            "       b'@_mspxo the name of the movie sounds sad itself ',\n",
            "       b'Hi BAM ! @BarsAndMelody \\nCan you follow my bestfriend @969Horan696 ? \\nShe loves you a lot  \\nSee you in Warsaw &lt \\nLove you &lt x46',\n",
            "       b'Someone sc me ',\n",
            "       b'@natalielms95 @jxhun @SharonMelaniex  why is this so accurate :-((((',\n",
            "       b'@KhaleesiMiley I want ',\n",
            "       b\"@CurlyxStyls i want a sponsor but my acc is new so i don't have even 1k \",\n",
            "       b\"Should I still sell socks? It's too expensive  150-160 pesos is so expensive + you gotta pay for the sf  http://t.co/JYLqWawIog\",\n",
            "       b'Hello  Get Youth Job Opportunities follow &gt;&gt; @tolajobjobs @NomfundoCom',\n",
            "       b'@MSaito6 @rekoinmanila @AdeccoWaytoWork \\nI will keep fighting for what i wanted to be  \\n\\n#KunoriforCEO #CEO1Month',\n",
            "       b'What a painful way to die ',\n",
            "       b'@Jime_JB21 FOLLOWED ME THANKS, AND\\n@justinbieber PLEASE FOLLOWED ME TOO ',\n",
            "       b'@clawdeeeeya :((( me too i have exams soon sighssss',\n",
            "       b\"@ericszmanda The happiest birthday to you! I hope you'll have a wonderful day! \",\n",
            "       b'@Bosslogic @amellywood @CW_Arrow @ARROWwriters Thank you! ',\n",
            "       b'My SNAPCHAT - AbbyMill18 #snapchat #snapchatme #wet #sex #sexy #indiemusic #hotels  http://t.co/5OLTvTAO95',\n",
            "       b'@DrSadafAlvi @FatimahLove92 @AliJaved93 @Iqbal92S @defilibrator @kiran1144 @tahseenfurqan Janjua is my friend.',\n",
            "       b'Flying panda at Airforce City, Clark Field Pampanga Hot Air Balloon Festival! http://t.co/oi7X2seSGi #retweet #cute #hotairballoon',\n",
            "       b'Stats for the week have arrived. 1 new follower and NO unfollowers  via http://t.co/a7adI6uFtX.',\n",
            "       b'No one is brave enough to watch all my snapchat story ',\n",
            "       b'@kbreeezy__  and nope haha she flies out of Dallas',\n",
            "       b'bts was 2 weeks ago ', b'Feeling like shit ',\n",
            "       b\"everyone's on holiday \", b'My original ticket was \\xc2\\xa319 ',\n",
            "       b'@kylaaareese me too ', b'@BelgianKeeper follow trick nonce ',\n",
            "       b'@sylar316 Nice ', b'Early birds are gone already das nice ',\n",
            "       b\"@lifelesscurves hopefully not  but sulli was like that too.........well, there was injured amber too, but she's still there haha sigh f(x)\",\n",
            "       b\"Rain is God's way of telling me that it's time for a nap  hehe\",\n",
            "       b\"I want to watch a movie, listen to Sizwe, eat and write my assignments at the same time.... But I can't do that \",\n",
            "       b'Hi, imiss you ', b\"@IsaiahPander I'd like that! \",\n",
            "       b'#FollowFriday @murtishaw @aqui_fr @FRTechStartups for being top influencers in my community this week ',\n",
            "       b'@SoggyStones should be online ',\n",
            "       b'if me and laura dont meet next year im gonna be so sad :((',\n",
            "       b\"@choivernope why not?  yes I'll stream~\",\n",
            "       b'#FollowFriday @MBandScott_ @Eric_FLE @pointsolutions3 for being top new followers in my community this week ',\n",
            "       b'Missing you ', b'I CANT WATCH TONIGHTS ANDROMEDA :(((',\n",
            "       b'BABY BOY :((((',\n",
            "       b'@DespiteOfficial we had a listen last night  As You Bleed is an amazing track. When are you in Scotland?!',\n",
            "       b'wednesday needs to hurry ',\n",
            "       b\"Fell asleep at like 6:30 and now can't fall asleep and I have to be up in two hours \",\n",
            "       b'u sound upset  https://t.co/JZBFBKld8Q',\n",
            "       b'@onlytheshelley 6pm is when the doors open for everyone with  (VIP/general) tickets to get there seats early and watch support acts!!',\n",
            "       b'Nice one Baz.  So lucky to be working for and with such a wonderful company of people.   https://t.co/InHUY4fkdG',\n",
            "       b'@anissapenaa  it would it really would',\n",
            "       b'My head always hurts if I stay up late lmao ',\n",
            "       b'@smiffy sorry Matthew   &lt', b'Sorry for being inactive. ',\n",
            "       b'Remember someone  \\xe2\\x99\\xab See You Again (feat. Charlie Puth) by Wiz Khalifa \\xe2\\x80\\x94 https://t.co/vVAyGndwnL',\n",
            "       b\"i slept all day and now i can't sleep \",\n",
            "       b'How do I check all the people i wanna unblock everyone ',\n",
            "       b'\"@yettygeers: dont give up and know that better days are coming  http://t.co/ZqpwgCmw0b\"',\n",
            "       b'@_KatKennedy Ack! I do think you should read it  I have heard only good things so far. It just seems.. awesome, hih ',\n",
            "       b\"@Coicele Oh, that doedn't sound good at all. \"], dtype=object)>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
            "array([1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
            "       1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
            "       1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0],\n",
            "      dtype=int32)>)\n"
          ]
        }
      ],
      "source": [
        "for batch in train_dataset.take(1):\n",
        "  print(batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTwmMzIoXkPd"
      },
      "source": [
        "Now that we have the text data in the format required, we can vectorize it. We will need to make use a specific text vectorization module from tensorflow to do this.\n",
        "- We first limit the vocabulary of the vectorizer to 5000,\n",
        "- then extract only the text portion of the training dataset,\n",
        "- and finally fit the vectorizer to the text using the 'adapt' method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6BrcfEoXkPd"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import TextVectorization\n",
        "vectorizer = TextVectorization(max_tokens=5000)\n",
        "train_text = train_dataset.map(lambda text, label: text)\n",
        "vectorizer.adapt(train_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lVOC3srXkPd"
      },
      "source": [
        "Let's print out the first tokens form the vocabulary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDErP-eLXkPd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0162586b-4b12-4600-8bbc-4e06973b689a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " np.str_('i'),\n",
              " np.str_('to'),\n",
              " np.str_('you'),\n",
              " np.str_('the'),\n",
              " np.str_('a'),\n",
              " np.str_('and'),\n",
              " np.str_('my'),\n",
              " np.str_('for'),\n",
              " np.str_('me'),\n",
              " np.str_('it'),\n",
              " np.str_('in'),\n",
              " np.str_('is'),\n",
              " np.str_('so'),\n",
              " np.str_('have'),\n",
              " np.str_('of'),\n",
              " np.str_('im'),\n",
              " np.str_('but'),\n",
              " np.str_('this'),\n",
              " np.str_('on'),\n",
              " np.str_('that'),\n",
              " np.str_('its'),\n",
              " np.str_('thanks'),\n",
              " np.str_('be'),\n",
              " np.str_('your'),\n",
              " np.str_('no'),\n",
              " np.str_('just'),\n",
              " np.str_('like'),\n",
              " np.str_('not'),\n",
              " np.str_('all'),\n",
              " np.str_('u'),\n",
              " np.str_('follow'),\n",
              " np.str_('with'),\n",
              " np.str_('at'),\n",
              " np.str_('love'),\n",
              " np.str_('we'),\n",
              " np.str_('please'),\n",
              " np.str_('too'),\n",
              " np.str_('are'),\n",
              " np.str_('was'),\n",
              " np.str_('get'),\n",
              " np.str_('good'),\n",
              " np.str_('dont'),\n",
              " np.str_('can'),\n",
              " np.str_('do'),\n",
              " np.str_('now'),\n",
              " np.str_('day'),\n",
              " np.str_('up'),\n",
              " np.str_('want'),\n",
              " np.str_('see'),\n",
              " np.str_('cant'),\n",
              " np.str_('thank'),\n",
              " np.str_('if'),\n",
              " np.str_('will'),\n",
              " np.str_('what'),\n",
              " np.str_('time'),\n",
              " np.str_('one'),\n",
              " np.str_('miss'),\n",
              " np.str_('know'),\n",
              " np.str_('amp'),\n",
              " np.str_('back'),\n",
              " np.str_('happy'),\n",
              " np.str_('out'),\n",
              " np.str_('much'),\n",
              " np.str_('about'),\n",
              " np.str_('when'),\n",
              " np.str_('go'),\n",
              " np.str_('why'),\n",
              " np.str_('hi'),\n",
              " np.str_('really'),\n",
              " np.str_('they'),\n",
              " np.str_('new'),\n",
              " np.str_('today'),\n",
              " np.str_('more'),\n",
              " np.str_('great'),\n",
              " np.str_('hope'),\n",
              " np.str_('he'),\n",
              " np.str_('from'),\n",
              " np.str_('still'),\n",
              " np.str_('our'),\n",
              " np.str_('am'),\n",
              " np.str_('how'),\n",
              " np.str_('here'),\n",
              " np.str_('as'),\n",
              " np.str_('been'),\n",
              " np.str_('ill'),\n",
              " np.str_('sorry'),\n",
              " np.str_('us'),\n",
              " np.str_('well'),\n",
              " np.str_('thats'),\n",
              " np.str_('got'),\n",
              " np.str_('oh'),\n",
              " np.str_('need'),\n",
              " np.str_('an'),\n",
              " np.str_('work'),\n",
              " np.str_('some'),\n",
              " np.str_('lt'),\n",
              " np.str_('would'),\n",
              " np.str_('followed')]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "vocab = vectorizer.get_vocabulary()\n",
        "vocab[:100]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2AnCbfIXkPd"
      },
      "source": [
        "Note that the first two tokens in the vocabulary are the empty token '', and the unknown token '[UNK]'. The latter is used to mask out-of-vocabulary tokens in the text\n",
        "\n",
        "We can now use the vectorizer to encode a tweet:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "reL7OIXpXkPd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "658aea25-acd5-4ef9-c0e7-d0c526503ede"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tweet:      This is my first tweet! It contains one out-of-vocabulary term. Any suggestions for extending this tweet?\n",
            "Encoded:    [ 19  13   8 201 247  11   1  57   1   1 152   1   9   1  19 247]\n",
            "Recovered:  this is my first tweet it [UNK] one [UNK] [UNK] any [UNK] for [UNK] this tweet\n"
          ]
        }
      ],
      "source": [
        "text = 'This is my first tweet! It contains one out-of-vocabulary term. Any suggestions for extending this tweet?'\n",
        "encoding = vectorizer([text]).numpy()[0]\n",
        "print('Tweet:     ', text)\n",
        "print('Encoded:   ', encoding)\n",
        "print('Recovered: ',' '.join([vocab[i] for i in encoding]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0wCv-cPXkPd"
      },
      "source": [
        "Note that the vectorizer is not turning the text into a single vector, but is simply replacing the vocabulary words by their indices. If a word is not present in the dictionary it is replaced by the unknown token."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAeaJ6WvXkPd"
      },
      "source": [
        "Let's have a look at some actual examples from the dataset, printing out the first 6 tweets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4aghpfMAXkPd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "103c9bf1-22c1-4055-bc4f-b31a66db029a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tweet:      How about you just have a nice convo like a normal person instead of posting how u feel about 200 of your closest twitter friends \n",
            "Encoded:    [  82   65    4   27   15    6  123 3354   28    6 1037  430 1058   16\n",
            "    1   82   31  120   65 3634   16   25 1562  212  214]\n",
            "Recovered:  how about you just have a nice convo like a normal person instead of [UNK] how u feel about 200 of your closest twitter friends\n",
            "\n",
            "Tweet:      OKAY PLEAS EDOMNT FCK QIH MY FEELINGS SHXBS ENOUGH!!!!  #ZaynIsComingBackOnJuly26\n",
            "Encoded:    [ 197 2641    1 3185    1    8  853    1  267  452]\n",
            "Recovered:  okay pleas [UNK] fck [UNK] my feelings [UNK] enough zayniscomingbackonjuly26\n",
            "\n",
            "Tweet:      i want all of kylie jenners clothes \n",
            "Encoded:    [   2   49   30   16    1    1 1101]\n",
            "Recovered:  i want all of [UNK] [UNK] clothes\n",
            "\n",
            "Tweet:      Hi BAM ! @BarsAndMelody \n",
            "Can you follow my bestfriend @969Horan696 ? \n",
            "She loves you a lot  \n",
            "See you in Warsaw &lt \n",
            "Love you &lt x2\n",
            "Encoded:    [  69  349  368   44    4   32    8  269  370  127  278    4    6  171\n",
            "   50    4   12  354   97   35    4   97 4047]\n",
            "Recovered:  hi bam barsandmelody can you follow my bestfriend 969horan696 she loves you a lot see you in warsaw lt love you lt x2\n",
            "\n",
            "Tweet:      @lnnamnd hi! we made some changes in our design, hope you like it  https://t.co/EXt098Yq1b\n",
            "Encoded:    [   1   69   36  170   96 1106   12   80  518   76    4   28   11  760]\n",
            "Recovered:  [UNK] hi we made some changes in our design hope you like it httpstcoext098yq1b\n",
            "\n",
            "Tweet:      @SMARTCares it wasn't indicated on the SMS I received. \n",
            "Encoded:    [  1  11 422   1  20   5   1   2 909]\n",
            "Recovered:  [UNK] it wasnt [UNK] on the [UNK] i received\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for text in batch[0][:6].numpy():\n",
        "    encoding = vectorizer([text]).numpy()[0]\n",
        "    print('Tweet:     ', text.decode(\"utf-8\"))\n",
        "    print('Encoded:   ', encoding)\n",
        "    print('Recovered: ',' '.join([vocab[i] for i in encoding]))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeDyajurXkPd"
      },
      "source": [
        "### Defining the RNN model\n",
        "\n",
        "Now we can define the model, which contains four layers:\n",
        "- an input embedding layer which produces word embeddings of size 64\n",
        "- a bidirectional LSTM layer\n",
        "- 2 dense (aka fully connected) layers that maps the 2 embedding vectors (of size 64) produced by the bidirectional LSTM down to a single neuron   \n",
        "\n",
        "This constitutes a relatively standard basic RNN architecture. (The details of why these specific components are chosen is beyond the scope of this tutorial.)  \n",
        "\n",
        "Once the model has been defined it is compiled in the following step:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7Db-xGTXkPd"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    vectorizer,\n",
        "    tf.keras.layers.Embedding(input_dim=len(vectorizer.get_vocabulary()), output_dim=64, mask_zero=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=['accuracy'], optimizer=tf.keras.optimizers.Adam(1e-4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDcdvj3fXkPd"
      },
      "source": [
        "Fit the model by running it for 10 epochs (iterations over the training data).\n",
        "- Note that we provide it with both the training dataset and the validation dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNij_XUrXkPd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77ec584b-68d2-405e-9504-6f72e4483d83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 102ms/step - accuracy: 0.4966 - loss: 0.6920 - val_accuracy: 0.4859 - val_loss: 0.6849\n",
            "Epoch 2/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 37ms/step - accuracy: 0.5135 - loss: 0.6751 - val_accuracy: 0.6086 - val_loss: 0.6261\n",
            "Epoch 3/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6650 - loss: 0.5752 - val_accuracy: 0.6914 - val_loss: 0.5646\n",
            "Epoch 4/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.7462 - loss: 0.4863 - val_accuracy: 0.7156 - val_loss: 0.5354\n",
            "Epoch 5/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.8000 - loss: 0.4121 - val_accuracy: 0.7516 - val_loss: 0.5167\n",
            "Epoch 6/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.8380 - loss: 0.3610 - val_accuracy: 0.7641 - val_loss: 0.5280\n",
            "Epoch 7/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.8770 - loss: 0.3082 - val_accuracy: 0.7625 - val_loss: 0.5383\n",
            "Epoch 8/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.8881 - loss: 0.2898 - val_accuracy: 0.7664 - val_loss: 0.5781\n",
            "Epoch 9/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.9011 - loss: 0.2460 - val_accuracy: 0.7695 - val_loss: 0.6103\n",
            "Epoch 10/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9157 - loss: 0.2315 - val_accuracy: 0.7672 - val_loss: 0.6713\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7daf439bc750>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "model.fit(train_dataset, epochs=10, validation_data=valid_dataset, validation_steps=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chkFHzAjXkPd"
      },
      "source": [
        "Once we've trained the model we can check the final accuracy on the validation data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VGjzmPPXkPd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc1ddd8c-6fcd-45f4-bd26-125c822bf4b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7740 - loss: 0.6325\n",
            "Validation Loss: 0.6877305507659912\n",
            "Validation Accuracy:  0.7631250023841858\n"
          ]
        }
      ],
      "source": [
        "valid_loss, valid_acc = model.evaluate(valid_dataset)\n",
        "\n",
        "print('Validation Loss: {}'.format(valid_loss))\n",
        "print('Validation Accuracy: ',valid_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUFlKyZwXkPd"
      },
      "source": [
        "We can have a look at the predictions from the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n44pazsNXkPd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e453a8a2-acc1-4d23-ca55-22170664d690"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step\n",
            "tweet:  I can't believe how much fun I'm having learning to train a text classifier with a bidirectional LSTM!\n",
            "encoded as:  i cant believe how much fun im having [UNK] to train a text [UNK] with a [UNK] [UNK]\n",
            "predicted value:  0.59034604\n",
            "predicted label:  positive\n",
            "\n",
            "tweet:  I am really confused. I want my mommy.\n",
            "encoded as:  i am really confused i want my mommy\n",
            "predicted value:  -4.291154\n",
            "predicted label:  negative\n",
            "\n",
            "tweet:  The internet connection has been pretty annoying today!\n",
            "encoded as:  the internet connection has been pretty annoying today\n",
            "predicted value:  -3.43005\n",
            "predicted label:  negative\n",
            "\n",
            "tweet:  They just played my favourite song on the radio.\n",
            "encoded as:  they just played my favourite song on the radio\n",
            "predicted value:  0.34817833\n",
            "predicted label:  positive\n",
            "\n",
            "tweet:  I don't like going to the dentist.\n",
            "encoded as:  i dont like going to the [UNK]\n",
            "predicted value:  -0.3785656\n",
            "predicted label:  negative\n",
            "\n",
            "tweet:  I am so happy today!\n",
            "encoded as:  i am so happy today\n",
            "predicted value:  1.8977839\n",
            "predicted label:  positive\n",
            "\n",
            "tweet:  I am so unhappy today!\n",
            "encoded as:  i am so unhappy today\n",
            "predicted value:  -1.4091182\n",
            "predicted label:  negative\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tweets = []\n",
        "tweets.append('I can\\'t believe how much fun I\\'m having learning to train a text classifier with a bidirectional LSTM!')\n",
        "tweets.append('I am really confused. I want my mommy.')\n",
        "tweets.append('The internet connection has been pretty annoying today!')\n",
        "tweets.append('They just played my favourite song on the radio.')\n",
        "tweets.append(\"I don't like going to the dentist.\")\n",
        "tweets.append('I am so happy today!')\n",
        "tweets.append('I am so unhappy today!')\n",
        "\n",
        "predictions = model.predict(tf.convert_to_tensor(tweets))\n",
        "\n",
        "for i in range(len(tweets)):\n",
        "  print('tweet: ',tweets[i])\n",
        "  encoding = vectorizer([tweets[i]]).numpy()[0]\n",
        "  print('encoded as: ',' '.join([vocab[j] for j in encoding]))\n",
        "  print('predicted value: ', predictions[i][0])\n",
        "  print('predicted label: ', 'negative' if (predictions[i]<0) else 'positive')\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aV-2gZZtXkPd"
      },
      "source": [
        "And calculate the usual evaluation metrics:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "-dBXIPMEXkPd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "outputId": "00d791cf-9436-429b-ff4d-b9bbaf598049"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "accuracy: 0.766875\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7daf3c4f95d0>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "pred_y = [0 if (pred < 0) else 1 for pred in model.predict(tf.convert_to_tensor(valid_x))]\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "print('accuracy: '+ str(accuracy_score(pred_y, valid_y)))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "cmd = ConfusionMatrixDisplay(confusion_matrix(valid_y, pred_y,normalize='true'), display_labels=['negative', 'positive'])\n",
        "cmd.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-BKhc-eXkPd"
      },
      "source": [
        "Finally, let's print out the model summary to get an understanding of the number of parameters in the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3Flbj4zXkPd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "57b8e84b-fb25-4377-f075-3fc0dec86f56"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ text_vectorization                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mTextVectorization\u001b[0m)                  │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │         \u001b[38;5;34m320,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m66,048\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ text_vectorization                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>)                  │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">320,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,183,109\u001b[0m (4.51 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,183,109</span> (4.51 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m394,369\u001b[0m (1.50 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">394,369</span> (1.50 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m788,740\u001b[0m (3.01 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">788,740</span> (3.01 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdT7hq_rXkPe"
      },
      "source": [
        "Most of the parameters are used to define the embedding, then the LSTMs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRDCLcREXkPe"
      },
      "source": [
        "### Encoder-Decoder models\n",
        "\n",
        "The next step after using sequential models for labelling and classification is to move to encoder-decoder models.\n",
        "Even better, encoder-decoder models with attention, to align the sequence processed by the encoder and the sequence processed by the decoder.\n",
        "\n",
        "We warmly recommend to take a look at this tutorial: https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html (you can tun it in Google Colab).\n",
        "The tutorial shows how to build a translation model using recurrent neural networks and the attention mechanism.\n",
        "This was the last step before moving to the Transformer architectures (the current state-of-the-art).\n",
        "The tutorial is useful to get a better understanding of the attention mechanism and how it is used to learn the alignment between two sequences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJoTyiqOXkPe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OgRPEb6pdlv"
      },
      "source": [
        "## Installing spaCy and downloading models\n",
        "\n",
        "First we need to check whether the spaCy library is installed:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3083U81cpdlv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a7e6daa-df88-4795-f0f5-1cc3e04e713b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
            "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJ1xLIcHpdlw"
      },
      "source": [
        "Then we need to download pretrained models for use with spaCy. We will load models for both English and Italian:\n",
        "- The models are called 'en_core_web_sm' and 'it_core_news_sm', where the 'web'/'news' indicates what type of collection the model was trained on and the 'sm' at the end indicates that we are using the 'small' version of the models\n",
        "- Other models are available here: https://spacy.io/models\n",
        "- The following code calls the python executable instructing it to run the module 'spacy', which in turn download the models. See discussion here: https://stackoverflow.com/questions/46148033/unable-to-load-en-from-spacy-in-jupyter-notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyv-NpFbpdlw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da163398-7b66-4309-c545-c2a9c69dfd38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Collecting it-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/it_core_news_sm-3.8.0/it_core_news_sm-3.8.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('it_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "!{sys.executable} -m spacy download en_core_web_sm\n",
        "!{sys.executable} -m spacy download it_core_news_sm;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYRlbtvspdlx"
      },
      "source": [
        "We are now ready to import spacy and load a model. Let's start with the English model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KHrsza0pdlx"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import en_core_web_sm\n",
        "nlp_model = en_core_web_sm.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jy4K8dRApdlx"
      },
      "source": [
        "Consider the following piece of text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MGjLJU0pdlx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb6db651-678c-4cd6-cc9b-976c003ac196"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Melbourne is to re-enter Stage 3 lockdown after a record increase in cases. Victorian state premier Daniel Andrews said there was “simply no alternative” to reimposing stay at home restrictions in Australia’s second-biggest city.\n"
          ]
        }
      ],
      "source": [
        "text = 'Melbourne is to re-enter Stage 3 lockdown after a record increase in cases. Victorian state premier Daniel Andrews said there was “simply no alternative” to reimposing stay at home restrictions in Australia’s second-biggest city.'\n",
        "# text = \"Good evening, London. Allow me first to apologize for this interruption. I do, like many of you, appreciate the comforts of everyday routine, the security of the familiar, the tranquillity of repetition. I enjoy them as much as any bloke. But in the spirit of commemoration, whereby those important events of the past, usually associated with someone's death or the end of some awful bloody struggle, are celebrated with a nice holiday, I thought we could mark this November the fifth, a day that is sadly no longer remembered, by taking some time out of our daily lives to sit down and have a little chat.\"\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_rCI0Hbpdly"
      },
      "source": [
        "Parse the text using the NLP engine:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmpvXvjapdly",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4460a448-b323-4cd8-cd82-84c5e84704b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Melbourne is to re-enter Stage 3 lockdown after a record increase in cases. Victorian state premier Daniel Andrews said there was “simply no alternative” to reimposing stay at home restrictions in Australia’s second-biggest city.\n"
          ]
        }
      ],
      "source": [
        "parsed_text = nlp_model(text)\n",
        "print(parsed_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnXyGOx0pdlz"
      },
      "source": [
        "Did it do something? It looks like it has just output the same text.\n",
        "- Actually, yes. It has parsed the input and built its internal datastructure from it.\n",
        "- Note that the length of the parsed object is in words, not characters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbAOI2Mnpdlz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed11c137-3490-4dbb-a445-a5ef6ca51b24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of the original text is 229 chacacters\n",
            "The length of the parsed text is 43 words\n"
          ]
        }
      ],
      "source": [
        "print(f'The length of the original text is {len(text)} chacacters')\n",
        "print(f'The length of the parsed text is {len(parsed_text)} words')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xImJ-i_Lpdlz"
      },
      "source": [
        "## Part-of-Speech Tagging\n",
        "\n",
        "While parsing the text, spaCy performs part-of-speech (POS) tagging.\n",
        "- We can see the POS tag for each token as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ho4HEJTLpdlz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56e6d8dc-26ab-4b04-f2ac-4bce2e2eb6b2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(Melbourne, 'PROPN'),\n",
              " (is, 'AUX'),\n",
              " (to, 'PART'),\n",
              " (re, 'VERB'),\n",
              " (-, 'VERB'),\n",
              " (enter, 'VERB'),\n",
              " (Stage, 'PROPN'),\n",
              " (3, 'NUM'),\n",
              " (lockdown, 'NOUN'),\n",
              " (after, 'ADP'),\n",
              " (a, 'DET'),\n",
              " (record, 'ADJ'),\n",
              " (increase, 'NOUN'),\n",
              " (in, 'ADP'),\n",
              " (cases, 'NOUN'),\n",
              " (., 'PUNCT'),\n",
              " (Victorian, 'ADJ'),\n",
              " (state, 'NOUN'),\n",
              " (premier, 'NOUN'),\n",
              " (Daniel, 'PROPN'),\n",
              " (Andrews, 'PROPN'),\n",
              " (said, 'VERB'),\n",
              " (there, 'PRON'),\n",
              " (was, 'VERB'),\n",
              " (“, 'PUNCT'),\n",
              " (simply, 'ADV'),\n",
              " (no, 'DET'),\n",
              " (alternative, 'NOUN'),\n",
              " (”, 'PUNCT'),\n",
              " (to, 'ADP'),\n",
              " (reimposing, 'VERB'),\n",
              " (stay, 'NOUN'),\n",
              " (at, 'ADP'),\n",
              " (home, 'NOUN'),\n",
              " (restrictions, 'NOUN'),\n",
              " (in, 'ADP'),\n",
              " (Australia, 'PROPN'),\n",
              " (’s, 'PART'),\n",
              " (second, 'ADV'),\n",
              " (-, 'PUNCT'),\n",
              " (biggest, 'ADJ'),\n",
              " (city, 'NOUN'),\n",
              " (., 'PUNCT')]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "[(w,w.pos_) for w in parsed_text]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFEzvleepdlz"
      },
      "source": [
        "Who remembers their grammar from high school? What do all those POS symbols mean?\n",
        "- You can find an explanation of the POS tags on this website https://spacy.io/api/annotation in the section \"Universal Part-of-speech Tags\"\n",
        "\n",
        "What can we do with POS tags?\n",
        "- Well, we could select all terms that have a certain tag, such as all adjectives:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Kcjc28lpdl0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fd7f8ac-4d4a-494e-9088-f53c3f10909c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{record, Victorian, biggest}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "set(w for w in parsed_text if w.pos_=='ADJ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftw5HEYEpdl0"
      },
      "source": [
        "That was a little underwhelming.\n",
        "- Let's try it on Alice in Wonderland chapter 1 text. (You'll need to upload it again to Google Colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGRt3HF8pdl0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc8e1e34-6fd4-4525-da7e-7c71e86beb8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['afraid', 'best', 'brave', 'bright', 'certain', 'close', 'common', 'cool', 'curious', 'dark', 'deep', 'dreamy', 'dry', 'dull', 'empty', 'enough', 'fancy', 'few', 'first', 'fond', 'funny', 'glad', 'golden', 'good', 'grand', 'great', 'high', 'hot', 'hurt', 'ignorant', 'impossible', 'large', 'larger', 'late', 'legged', 'likely', 'little', 'long', 'loveliest', 'lovely', 'low', 'many', 'mixed', 'much', 'natural', 'nervous', 'nice', 'other', 'out', 'own', 'pine', 'pink', 'poor', 'red', 'remarkable', 'respectable', 'right', 'same', 'second', 'several', 'simple', 'sleepy', 'slippery', 'small', 'smaller', 'solid', 'stupid', 'such', 'sure', 'surprised', 'tart', 'tiny', 'tired', 'true', 'unpleasant', 'wild', 'wise', 'worth']\n"
          ]
        }
      ],
      "source": [
        "adjectives = sorted(set(w.text for w in nlp_model(open(\"docs/Alice_Chapter1.txt\", \"r\").read()) if w.pos_=='ADJ'))\n",
        "print(adjectives)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pct1jNdEpdl0"
      },
      "source": [
        "You can see how descriptive a writer Lewis Carroll was!\n",
        "\n",
        "This leads us to one explanation as to why we might want to extract POS tags from text:\n",
        "- They can sometimes be useful for **extracting features** (often handcrafted ones) for certain text classification tasks (such as authorship identification).\n",
        "- This is particularly the case if only a small amount of training data is available.  \n",
        "- For example, in this article (https://towardsdatascience.com/automatically-detect-covid-19-misinformation-f7ceca1dc1c7) hand-crafted features are extracted for classifying covid misinformation.\n",
        "\n",
        "Another reason why we might consider POS tagging is to **reduce ambiguity** in our bag-of-words representation by appending POS tags to word occurrences.\n",
        "- Consider the following two sentences:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2iO992Q-pdl0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7186fbd8-389a-415a-9c46-76e938d3f438"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I catch the train to and from work.      <-- 'train' is a NOUN\n",
            "I like to train at least 6 times a week. <-- 'train' is a VERB\n"
          ]
        }
      ],
      "source": [
        "ex1 = 'I catch the train to and from work.'       # This is Prof. Mark Carman speaking\n",
        "ex2 = 'I like to train at least 6 times a week.'  # This is Prof. Jacked Carman speaking\n",
        "\n",
        "print(ex1, '     <-- \\'train\\' is a', nlp_model(ex1)[3].pos_)\n",
        "print(ex2, '<-- \\'train\\' is a', nlp_model(ex2)[3].pos_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHlqof06pdl1"
      },
      "source": [
        "The second sentence has nothing to do with trains, despite containing the word 'train'!\n",
        "- We could deal with this issue by appending the POS tag to the observed literal to form vocabulary elements: train_NOUN, train_VERB\n",
        "\n",
        "A final reason why we might think about running POS tagging would be to extract proper nouns from the text, since they refer to real entities that are being discussed in it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kW4TbHffpdl1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c865f77c-c137-4007-b1ef-31779504e96a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Melbourne', 'Stage', 'Daniel', 'Andrews', 'Australia']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "[w.text for w in parsed_text if w.pos_=='PROPN']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDl1pPoSpdl1"
      },
      "source": [
        "Shortly though, we will talk about Entity-extraction, which is the task of identifying and categorising the entities discussed in the text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDh0iS65pdl1"
      },
      "source": [
        "## Lemmatization\n",
        "\n",
        "While parsing, spaCy also performs lemmatization.\n",
        "- Lemmatization is the process of extracting the 'lemma' for each token, which is the canonical form of the word that would be found in the dictionary, (see https://en.wikipedia.org/wiki/Lemma_(morphology))\n",
        "- Basically, verbs converted to their root form, e.g.: **went, going, goes, gone => go**\n",
        "- And nouns are retuned to singular form: **kittens => kitten**\n",
        "- Lemmatization is a more complicated POS-aware process than stemming (https://en.wikipedia.org/wiki/Stemming). Stemmers simply apply a set of language-specific syntax rules to recover the stem of the word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EevBrQRbpdl1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2080eb28-8fc2-441d-b480-9431ddc82bb2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(Melbourne, 'Melbourne'),\n",
              " (is, 'be'),\n",
              " (to, 'to'),\n",
              " (re, 're'),\n",
              " (-, '-'),\n",
              " (enter, 'enter'),\n",
              " (Stage, 'Stage'),\n",
              " (3, '3'),\n",
              " (lockdown, 'lockdown'),\n",
              " (after, 'after'),\n",
              " (a, 'a'),\n",
              " (record, 'record'),\n",
              " (increase, 'increase'),\n",
              " (in, 'in'),\n",
              " (cases, 'case'),\n",
              " (., '.'),\n",
              " (Victorian, 'victorian'),\n",
              " (state, 'state'),\n",
              " (premier, 'premier'),\n",
              " (Daniel, 'Daniel'),\n",
              " (Andrews, 'Andrews'),\n",
              " (said, 'say'),\n",
              " (there, 'there'),\n",
              " (was, 'be'),\n",
              " (“, '\"'),\n",
              " (simply, 'simply'),\n",
              " (no, 'no'),\n",
              " (alternative, 'alternative'),\n",
              " (”, '\"'),\n",
              " (to, 'to'),\n",
              " (reimposing, 'reimpose'),\n",
              " (stay, 'stay'),\n",
              " (at, 'at'),\n",
              " (home, 'home'),\n",
              " (restrictions, 'restriction'),\n",
              " (in, 'in'),\n",
              " (Australia, 'Australia'),\n",
              " (’s, '’s'),\n",
              " (second, 'second'),\n",
              " (-, '-'),\n",
              " (biggest, 'big'),\n",
              " (city, 'city'),\n",
              " (., '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "[(x, x.lemma_) for x in parsed_text]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEIoq1RFpdl1"
      },
      "source": [
        "Why would one want to perfom lemmatization? -- Or stemming for that matter?\n",
        "- to **reduce the vocabulary size** and thereby generalise the representation. -- This used to be very important for improving performance of search engine performance (better similarity measures between documents) and also classifiers on small datasets, (before word embeddings came along).\n",
        "- to **look-up information** about the word in a dictionary/ontology, such as WordNet (https://en.wikipedia.org/wiki/WordNet). This used to be an important way to compute semantic similarity between words, but again, word embeddngs probably do a better job."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vBQ7f0tpdl2"
      },
      "source": [
        "## Dependency Parsing\n",
        "\n",
        "Tradititonally in Natural Language Processing, text is processed in a pipeline that first tokenizes, then POS tags, lemmatizes and finaly dependency parses a piece of text.\n",
        "- The idea with dependency parsing is to determine what function each of the word instances is fulfilling in the sentence.\n",
        "- What is the subject and object of the sentence?\n",
        "- Which noun is each adjective referring to?\n",
        "\n",
        "So while parsing the text, the spaCy model also generates a **dependency parse tree**, which can be displayed using 'displacy':"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dbz57hc5pdl2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "outputId": "4ed55b42-b135-4281-aeab-1b7d22506ae4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"55182c8544c946c9ac5e4120713252f0-0\" class=\"displacy\" width=\"6525\" height=\"487.0\" direction=\"ltr\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Melbourne</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">to</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">PART</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">re-</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">enter</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">Stage</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">3</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NUM</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">lockdown</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">after</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">a</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">record</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">increase</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">in</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">cases.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2500\">Victorian</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2500\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2675\">state</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2675\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2850\">premier</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2850\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3025\">Daniel</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3025\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3200\">Andrews</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3200\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3375\">said</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3375\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3550\">there</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3550\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3725\">was “</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3725\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3900\">simply</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3900\">ADV</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4075\">no</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4075\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4250\">alternative”</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4250\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4425\">to</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4425\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4600\">reimposing</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4600\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4775\">stay</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4775\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4950\">at</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4950\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5125\">home</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5125\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5300\">restrictions</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5300\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5475\">in</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5475\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5650\">Australia</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5650\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5825\">’s</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5825\">PART</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"6000\">second-</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"6000\">ADV</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"6175\">biggest</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"6175\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"6350\">city.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"6350\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-55182c8544c946c9ac5e4120713252f0-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,264.5 210.0,264.5 210.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-55182c8544c946c9ac5e4120713252f0-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-55182c8544c946c9ac5e4120713252f0-0-1\" stroke-width=\"2px\" d=\"M420,352.0 C420,264.5 560.0,264.5 560.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-55182c8544c946c9ac5e4120713252f0-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M420,354.0 L412,342.0 428,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-55182c8544c946c9ac5e4120713252f0-0-2\" stroke-width=\"2px\" d=\"M245,352.0 C245,177.0 565.0,177.0 565.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-55182c8544c946c9ac5e4120713252f0-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M565.0,354.0 L573.0,342.0 557.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-55182c8544c946c9ac5e4120713252f0-0-3\" stroke-width=\"2px\" d=\"M245,352.0 C245,89.5 745.0,89.5 745.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-55182c8544c946c9ac5e4120713252f0-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M745.0,354.0 L753.0,342.0 737.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-55182c8544c946c9ac5e4120713252f0-0-4\" stroke-width=\"2px\" d=\"M770,352.0 C770,264.5 910.0,264.5 910.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-55182c8544c946c9ac5e4120713252f0-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M910.0,354.0 L918.0,342.0 902.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-55182c8544c946c9ac5e4120713252f0-0-5\" stroke-width=\"2px\" d=\"M1120,352.0 C1120,264.5 1260.0,264.5 1260.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-55182c8544c946c9ac5e4120713252f0-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nummod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1120,354.0 L1112,342.0 1128,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-55182c8544c946c9ac5e4120713252f0-0-6\" stroke-width=\"2px\" d=\"M1295,352.0 C1295,264.5 1435.0,264.5 1435.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-55182c8544c946c9ac5e4120713252f0-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">npadvmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1295,354.0 L1287,342.0 1303,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-55182c8544c946c9ac5e4120713252f0-0-7\" stroke-width=\"2px\" d=\"M245,352.0 C245,2.0 1450.0,2.0 1450.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-55182c8544c946c9ac5e4120713252f0-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1450.0,354.0 L1458.0,342.0 1442.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-55182c8544c946c9ac5e4120713252f0-0-8\" stroke-width=\"2px\" d=\"M1645,352.0 C1645,177.0 1965.0,177.0 1965.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-55182c8544c946c9ac5e4120713252f0-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1645,354.0 L1637,342.0 1653,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-55182c8544c946c9ac5e4120713252f0-0-9\" stroke-width=\"2px\" d=\"M1820,352.0 C1820,264.5 1960.0,264.5 1960.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-55182c8544c946c9ac5e4120713252f0-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1820,354.0 L1812,342.0 1828,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-55182c8544c946c9ac5e4120713252f0-0-10\" stroke-width=\"2px\" d=\"M1470,352.0 C1470,89.5 1970.0,89.5 1970.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-55182c8544c946c9ac5e4120713252f0-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1970.0,354.0 L1978.0,342.0 1962.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-55182c8544c946c9ac5e4120713252f0-0-11\" stroke-width=\"2px\" d=\"M1995,352.0 C1995,264.5 2135.0,264.5 2135.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-55182c8544c946c9ac5e4120713252f0-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2135.0,354.0 L2143.0,342.0 2127.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-55182c8544c946c9ac5e4120713252f0-0-12\" stroke-width=\"2px\" d=\"M2170,352.0 C2170,264.5 2310.0,264.5 2310.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-55182c8544c946c9ac5e4120713252f0-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2310.0,354.0 L2318.0,342.0 2302.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-55182c8544c946c9ac5e4120713252f0-0-13\" stroke-width=\"2px\" d=\"M2520,352.0 C2520,177.0 2840.0,177.0 2840.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-55182c8544c946c9ac5e4120713252f0-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2520,354.0 L2512,342.0 2528,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-55182c8544c946c9ac5e4120713252f0-0-14\" stroke-width=\"2px\" d=\"M2695,352.0 C2695,264.5 2835.0,264.5 2835.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-55182c8544c946c9ac5e4120713252f0-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2695,354.0 L2687,342.0 2703,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-55182c8544c946c9ac5e4120713252f0-0-15\" stroke-width=\"2px\" d=\"M2870,352.0 C2870,177.0 3190.0,177.0 3190.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-55182c8544c946c9ac5e4120713252f0-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2870,354.0 L2862,342.0 2878,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-55182c8544c946c9ac5e4120713252f0-0-16\" stroke-width=\"2px\" d=\"M3045,352.0 C3045,264.5 3185.0,264.5 3185.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-55182c8544c946c9ac5e4120713252f0-0-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3045,354.0 L3037,342.0 3053,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-55182c8544c946c9ac5e4120713252f0-0-17\" stroke-width=\"2px\" d=\"M3220,352.0 C3220,264.5 3360.0,264.5 3360.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-55182c8544c946c9ac5e4120713252f0-0-17\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3220,354.0 L3212,342.0 3228,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-55182c8544c946c9ac5e4120713252f0-0-18\" stroke-width=\"2px\" d=\"M3570,352.0 C3570,264.5 3710.0,264.5 3710.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-55182c8544c946c9ac5e4120713252f0-0-18\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">expl</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3570,354.0 L3562,342.0 3578,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-55182c8544c946c9ac5e4120713252f0-0-19\" stroke-width=\"2px\" d=\"M3395,352.0 C3395,177.0 3715.0,177.0 3715.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-55182c8544c946c9ac5e4120713252f0-0-19\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">ccomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3715.0,354.0 L3723.0,342.0 3707.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-55182c8544c946c9ac5e4120713252f0-0-20\" stroke-width=\"2px\" d=\"M3745,352.0 C3745,264.5 3885.0,264.5 3885.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-55182c8544c946c9ac5e4120713252f0-0-20\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3885.0,354.0 L3893.0,342.0 3877.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-55182c8544c946c9ac5e4120713252f0-0-21\" stroke-width=\"2px\" d=\"M4095,352.0 C4095,264.5 4235.0,264.5 4235.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-55182c8544c946c9ac5e4120713252f0-0-21\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4095,354.0 L4087,342.0 4103,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-55182c8544c946c9ac5e4120713252f0-0-22\" stroke-width=\"2px\" d=\"M3745,352.0 C3745,177.0 4240.0,177.0 4240.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-55182c8544c946c9ac5e4120713252f0-0-22\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4240.0,354.0 L4248.0,342.0 4232.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-55182c8544c946c9ac5e4120713252f0-0-23\" stroke-width=\"2px\" d=\"M4270,352.0 C4270,264.5 4410.0,264.5 4410.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-55182c8544c946c9ac5e4120713252f0-0-23\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4410.0,354.0 L4418.0,342.0 4402.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-55182c8544c946c9ac5e4120713252f0-0-24\" stroke-width=\"2px\" d=\"M4445,352.0 C4445,264.5 4585.0,264.5 4585.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-55182c8544c946c9ac5e4120713252f0-0-24\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pcomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4585.0,354.0 L4593.0,342.0 4577.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-55182c8544c946c9ac5e4120713252f0-0-25\" stroke-width=\"2px\" d=\"M4620,352.0 C4620,264.5 4760.0,264.5 4760.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-55182c8544c946c9ac5e4120713252f0-0-25\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4760.0,354.0 L4768.0,342.0 4752.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-55182c8544c946c9ac5e4120713252f0-0-26\" stroke-width=\"2px\" d=\"M4795,352.0 C4795,264.5 4935.0,264.5 4935.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-55182c8544c946c9ac5e4120713252f0-0-26\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4935.0,354.0 L4943.0,342.0 4927.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-55182c8544c946c9ac5e4120713252f0-0-27\" stroke-width=\"2px\" d=\"M5145,352.0 C5145,264.5 5285.0,264.5 5285.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-55182c8544c946c9ac5e4120713252f0-0-27\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M5145,354.0 L5137,342.0 5153,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-55182c8544c946c9ac5e4120713252f0-0-28\" stroke-width=\"2px\" d=\"M4970,352.0 C4970,177.0 5290.0,177.0 5290.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-55182c8544c946c9ac5e4120713252f0-0-28\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M5290.0,354.0 L5298.0,342.0 5282.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-55182c8544c946c9ac5e4120713252f0-0-29\" stroke-width=\"2px\" d=\"M5320,352.0 C5320,264.5 5460.0,264.5 5460.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-55182c8544c946c9ac5e4120713252f0-0-29\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M5460.0,354.0 L5468.0,342.0 5452.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-55182c8544c946c9ac5e4120713252f0-0-30\" stroke-width=\"2px\" d=\"M5670,352.0 C5670,177.0 6340.0,177.0 6340.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-55182c8544c946c9ac5e4120713252f0-0-30\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M5670,354.0 L5662,342.0 5678,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-55182c8544c946c9ac5e4120713252f0-0-31\" stroke-width=\"2px\" d=\"M5670,352.0 C5670,264.5 5810.0,264.5 5810.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-55182c8544c946c9ac5e4120713252f0-0-31\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M5810.0,354.0 L5818.0,342.0 5802.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-55182c8544c946c9ac5e4120713252f0-0-32\" stroke-width=\"2px\" d=\"M6020,352.0 C6020,264.5 6160.0,264.5 6160.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-55182c8544c946c9ac5e4120713252f0-0-32\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M6020,354.0 L6012,342.0 6028,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-55182c8544c946c9ac5e4120713252f0-0-33\" stroke-width=\"2px\" d=\"M6195,352.0 C6195,264.5 6335.0,264.5 6335.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-55182c8544c946c9ac5e4120713252f0-0-33\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M6195,354.0 L6187,342.0 6203,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-55182c8544c946c9ac5e4120713252f0-0-34\" stroke-width=\"2px\" d=\"M5495,352.0 C5495,89.5 6345.0,89.5 6345.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-55182c8544c946c9ac5e4120713252f0-0-34\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M6345.0,354.0 L6353.0,342.0 6337.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from spacy import displacy\n",
        "displacy.render(parsed_text, jupyter=True, style='dep')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quwWOjbOpdl3"
      },
      "source": [
        "Such dependency trees are interesting for understanding and visualising language (particularly for linguists) and could possibly be used for some downstream tasks (say checking ambiguity in legal documents).  \n",
        "\n",
        "Consider the sentences:\n",
        "- *The girl saw a man carrying a telescope.*\n",
        "- *The girl saw a man with a telescope.*\n",
        "\n",
        "Who had the telescope?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_AxJLNswpdl3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "b115785e-262f-420b-8725-bcb73d2d3bc3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"57cd5bb780eb4605a25d6c8df0e1113a-0\" class=\"displacy\" width=\"1450\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">girl</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">saw</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">a</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">man</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">carrying</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">a</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">telescope.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-57cd5bb780eb4605a25d6c8df0e1113a-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-57cd5bb780eb4605a25d6c8df0e1113a-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-57cd5bb780eb4605a25d6c8df0e1113a-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-57cd5bb780eb4605a25d6c8df0e1113a-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-57cd5bb780eb4605a25d6c8df0e1113a-0-2\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-57cd5bb780eb4605a25d6c8df0e1113a-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M595,179.0 L587,167.0 603,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-57cd5bb780eb4605a25d6c8df0e1113a-0-3\" stroke-width=\"2px\" d=\"M420,177.0 C420,2.0 750.0,2.0 750.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-57cd5bb780eb4605a25d6c8df0e1113a-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M750.0,179.0 L758.0,167.0 742.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-57cd5bb780eb4605a25d6c8df0e1113a-0-4\" stroke-width=\"2px\" d=\"M770,177.0 C770,89.5 920.0,89.5 920.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-57cd5bb780eb4605a25d6c8df0e1113a-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acl</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M920.0,179.0 L928.0,167.0 912.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-57cd5bb780eb4605a25d6c8df0e1113a-0-5\" stroke-width=\"2px\" d=\"M1120,177.0 C1120,89.5 1270.0,89.5 1270.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-57cd5bb780eb4605a25d6c8df0e1113a-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1120,179.0 L1112,167.0 1128,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-57cd5bb780eb4605a25d6c8df0e1113a-0-6\" stroke-width=\"2px\" d=\"M945,177.0 C945,2.0 1275.0,2.0 1275.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-57cd5bb780eb4605a25d6c8df0e1113a-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1275.0,179.0 L1283.0,167.0 1267.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "displacy.render(nlp_model('The girl saw a man carrying a telescope.'),jupyter=True,style='dep')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7abgGOdwpdl3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "1e7bcd76-41e0-49ed-a87c-6c95fa9aedea"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"4abb0e02a6994f339e97e626ccfd425b-0\" class=\"displacy\" width=\"1450\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">girl</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">saw</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">a</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">man</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">with</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">a</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">telescope.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-4abb0e02a6994f339e97e626ccfd425b-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-4abb0e02a6994f339e97e626ccfd425b-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-4abb0e02a6994f339e97e626ccfd425b-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-4abb0e02a6994f339e97e626ccfd425b-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-4abb0e02a6994f339e97e626ccfd425b-0-2\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-4abb0e02a6994f339e97e626ccfd425b-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M595,266.5 L587,254.5 603,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-4abb0e02a6994f339e97e626ccfd425b-0-3\" stroke-width=\"2px\" d=\"M420,264.5 C420,89.5 745.0,89.5 745.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-4abb0e02a6994f339e97e626ccfd425b-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M745.0,266.5 L753.0,254.5 737.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-4abb0e02a6994f339e97e626ccfd425b-0-4\" stroke-width=\"2px\" d=\"M420,264.5 C420,2.0 925.0,2.0 925.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-4abb0e02a6994f339e97e626ccfd425b-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M925.0,266.5 L933.0,254.5 917.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-4abb0e02a6994f339e97e626ccfd425b-0-5\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,177.0 1265.0,177.0 1265.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-4abb0e02a6994f339e97e626ccfd425b-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1120,266.5 L1112,254.5 1128,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-4abb0e02a6994f339e97e626ccfd425b-0-6\" stroke-width=\"2px\" d=\"M945,264.5 C945,89.5 1270.0,89.5 1270.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-4abb0e02a6994f339e97e626ccfd425b-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1270.0,266.5 L1278.0,254.5 1262.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "displacy.render(nlp_model('The girl saw a man with a telescope.'),jupyter=True,style='dep')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fIZq6zIhPbk"
      },
      "source": [
        "The second sentence is ambiguous: The girl may have made use of her telescope or the man may have been using the girl's telescope...\n",
        "- Language is full of such ambiguities which we as humans naturally deal with using our prior knowledge and abilty to construct mental models of the situations described.\n",
        "- This process is not without its biases:\n",
        "  - *The doctor went over to talk to the nurse. She told him that she had just given the patient 5mg of Vicodin and the child had started convulsing. He listened attentively as she explained what had happened. The doctor was worried that the patient should not be given any more painkillers. The nurse told the doctor not to worry, that the patient was in good hands, and that he would let her know immediately if the child's condition changed.*\n",
        "  - What gender are the doctor and the nurse?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uE1efbqpdl3"
      },
      "source": [
        "## Extracting Entities\n",
        "\n",
        "A more important output than the depency parse, from a text mining perspective, is the list of named-entities present in the text\n",
        "- **named entities** are objects in the real world, e.g. persons, products, organizations, locations, etc.\n",
        "  - see https://en.wikipedia.org/wiki/Named_entity\n",
        "- if spacy has found any named entities while parsing the text, we can access them as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irYwH5WVpdl3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6e1b673-71a0-4dbb-d26e-560d5a9da6f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Melbourne, 3, Victorian, Daniel Andrews, Australia, second)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "parsed_text.ents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rv6krbXmpdl3"
      },
      "source": [
        "Note that the entities are not single word tokens but short sequences of words: 'Stage 3' and 'Daniel Andrews'.\n",
        "\n",
        "Not only does spacy extract the entities, but also categorises them based on their type:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXA2FRzXpdl4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a74825f8-e712-4fbd-8e9c-88101b064b43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Melbourne', 'GPE'), ('3', 'CARDINAL'), ('Victorian', 'NORP'), ('Daniel Andrews', 'PERSON'), ('Australia', 'GPE'), ('second', 'ORDINAL')]\n"
          ]
        }
      ],
      "source": [
        "print([(ent.text, ent.label_) for ent in parsed_text.ents])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyp09Uelpdl4"
      },
      "source": [
        "The city and country locations have been labeled 'GPE' for 'geopolitical entity', while the Premier of Victoria has been correctly identified as a person.\n",
        "- Here is the list of all entity types that spaCy looks for: https://spacy.io/api/annotation#section-named-entities\n",
        "\n",
        "Internally, the output of the Named Entity Recogniser is a sequence annotated with entities using inside-outside-beginning encoding:\n",
        "- see https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)\n",
        "- We can print out this labeling as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-E1H-RM6pdl4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b9ac0c8-5f80-47ab-d356-994907984e63"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(Melbourne, 'B', 'GPE'),\n",
              " (is, 'O', ''),\n",
              " (to, 'O', ''),\n",
              " (re, 'O', ''),\n",
              " (-, 'O', ''),\n",
              " (enter, 'O', ''),\n",
              " (Stage, 'O', ''),\n",
              " (3, 'B', 'CARDINAL'),\n",
              " (lockdown, 'O', ''),\n",
              " (after, 'O', ''),\n",
              " (a, 'O', ''),\n",
              " (record, 'O', ''),\n",
              " (increase, 'O', ''),\n",
              " (in, 'O', ''),\n",
              " (cases, 'O', ''),\n",
              " (., 'O', ''),\n",
              " (Victorian, 'B', 'NORP'),\n",
              " (state, 'O', ''),\n",
              " (premier, 'O', ''),\n",
              " (Daniel, 'B', 'PERSON'),\n",
              " (Andrews, 'I', 'PERSON'),\n",
              " (said, 'O', ''),\n",
              " (there, 'O', ''),\n",
              " (was, 'O', ''),\n",
              " (“, 'O', ''),\n",
              " (simply, 'O', ''),\n",
              " (no, 'O', ''),\n",
              " (alternative, 'O', ''),\n",
              " (”, 'O', ''),\n",
              " (to, 'O', ''),\n",
              " (reimposing, 'O', ''),\n",
              " (stay, 'O', ''),\n",
              " (at, 'O', ''),\n",
              " (home, 'O', ''),\n",
              " (restrictions, 'O', ''),\n",
              " (in, 'O', ''),\n",
              " (Australia, 'B', 'GPE'),\n",
              " (’s, 'O', ''),\n",
              " (second, 'B', 'ORDINAL'),\n",
              " (-, 'O', ''),\n",
              " (biggest, 'O', ''),\n",
              " (city, 'O', ''),\n",
              " (., 'O', '')]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "[(X, X.ent_iob_, X.ent_type_) for X in parsed_text]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10tU8n44pdl4"
      },
      "source": [
        "The above format is a bit hard to read though, so spaCy also provides a far more natural visualisation of the tags:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PmUl2y5pdl4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "7cbb6baa-3d64-4035-cca4-00e8564c390e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Melbourne\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " is to re-enter Stage \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    3\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " lockdown after a record increase in cases. \n",
              "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Victorian\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
              "</mark>\n",
              " state premier \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Daniel Andrews\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " said there was “simply no alternative” to reimposing stay at home restrictions in \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Australia\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              "’s \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    second\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
              "</mark>\n",
              "-biggest city.</div></span>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "displacy.render(parsed_text, jupyter=True, style='ent')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VS1PK7ifpdl5"
      },
      "source": [
        "## Extracting entities from a web document\n",
        "\n",
        "Now that we know how to perform entity recognition on text, let's apply it to a full document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8pY-nN0Zpdl5"
      },
      "outputs": [],
      "source": [
        "url = 'https://www.bbc.com/news/world-latin-america-53319517'\n",
        "#url = 'https://en.wikipedia.org/wiki/Apple_(disambiguation)'\n",
        "\n",
        "import requests\n",
        "html_doc = requests.get(url).text\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "parsed_doc = BeautifulSoup(html_doc, 'lxml')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRe5AUvCpdl5"
      },
      "source": [
        "Now lets extract the title and paragraph text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5YGoQISpdl5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efe1e337-54dd-49b3-9d67-5187e3f29c32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coronavirus: Brazil's President Bolsonaro tests positive\n",
            "\n",
            "Brazil's President Jair Bolsonaro has tested positive for coronavirus.\n",
            "He took the test, his fourth, on Monday after developing symptoms, including a high temperature.\n",
            "Mr Bolsonaro has repeatedly played down risks of what he has called the \"little flu\", saying he would not be seriously affected. He has opposed lockdowns, which he says hurt the economy.\n",
            "Brazil has the second-highest number of Covid-19 cases and deaths in the world, after the US. \n",
            "He made the announcement in a TV interview on Tuesday, saying the fever he had been experiencing had gone down and that he felt \"very well\".\n",
            "Mr Bolsonaro said that he had started experiencing symptoms on Sunday. He said he had had a high temperature, a cough and had felt unwell. \n",
            "He added that on Monday he had felt worse, which prompted him to take the coronavirus test.\n",
            "Mr Bolsonaro is in a higher-risk group because of his age, 65.\n",
            "He said he was taking hydroxychloroquine - championed by US President Donald Trump - and azithromycin, an antibiotic, to treat the illness. Neither has been proven to be effective against the virus.\n",
            "Contact tracing and tests will be carried out for the people Mr Bolsonaro has met recently.\n",
            "His previous three tests for the virus all came back negative.\n",
            "The executive director of the World Health Organization, Dr Mike Ryan, wished President Bolsonaro \"a speedy and full recovery from this disease\", adding: \"I think the message to us all is: we are vulnerable to this virus.\"\n",
            "Back in April, Mr Bolsonaro said that even if infected, he would \"not have to worry as I wouldn't feel anything, at most it would be like a little flu or a little cold\".\n",
            "The number of Covid-19-related deaths and infections - at that time under 3,000 and 40,000 - has since soared.\n",
            "Despite this, President Bolsonaro has argued that regional lockdowns are having a more damaging effect than the virus itself, and accused the media of spreading panic and paranoia.\n",
            "His other comments on the virus include:\n",
            "He has since continued to rail against measures that he deems \"dictatorial\" such as the closing beaches or requirements to wear face coverings. \n",
            "On Monday, he made further changes to a law that would require Brazilians to wear masks in public.\n",
            "He has attended a number of public events without a mask, even when local rules required him to wear one.\n",
            "On Sunday, Foreign Minister Ernesto Araújo posted a photo on social media showing himself with President Bolsonaro and others attending an Independence Day celebration at the US embassy in Brasilia. \n",
            "None of those in the photo is wearing a mask or observing social distancing.\n",
            "The US embassy said that the ambassador had had lunch with Mr Bolsonaro and others on 4 July. It added that the ambassador had no symptoms but that he would undergo testing.\n",
            "The ambassador had earlier tweeted a picture of himself with President Bolsonaro.\n",
            "For so long, Jair Bolsonaro has tried to brush off this virus - the irony that he has now caught it has not been missed in Brazil. \n",
            "His detractors - of which he has many - have weighed in, calling this karma - that Jair Bolsonaro invited this to happen. \n",
            "There was even a column in one of the biggest newspapers, Folha de São Paulo, entitled \"Why I'm Cheering for Bolsonaro to Die\" - this is how divided, how toxic  the political picture is here in Brazil as the pandemic takes hold. \n",
            "But the fact is, Bolsonaro joins the nearly 1.7 million Brazilians who've contracted Covid-19. They're scary numbers and Brazil is a country in trouble, where coronavirus is spreading fast. \n",
            "Will Jair Bolsonaro get away with mild symptoms and carry on downplaying it? Or change tack now the virus has hit home? Whatever happens, with the man at the top suffering from Covid-19, it symbolises the crisis this country is in. \n",
            "Infections in Brazil and Latin America as a whole took a while to take hold but then started to rise, initially for Brazil in its Amazonas region but then more starkly in Rio de Janeiro and São Paulo.\n",
            "Brazil became only the second country to pass one million cases on 20 June and has continued to rise, passing 1.5 million. Many experts believe deficiencies in testing mean the overall figures for cases and deaths could be considerably higher.\n",
            "Nevertheless lockdowns began to be lifted in many areas even as the cases surged. Both Rio and São Paulo have reopened bars and restaurants in the past week.\n",
            "Two health ministers - both doctors - have left their posts after disagreements with the president.\n",
            "One ray of hope though is Brazil's renowned expertise in vaccines. Two major vaccine tests, in partnership with AstraZeneca and Sinovac, are to begin final phase testing on thousands of Brazilian volunteers.\n",
            "Copyright 2025 BBC. All rights reserved.  The BBC is not responsible for the content of external sites. Read about our approach to external linking.\n",
            " \n"
          ]
        }
      ],
      "source": [
        "title = parsed_doc.find('title').text\n",
        "paragraphs = [p.text for p in parsed_doc.find_all('p')]\n",
        "\n",
        "# Combine the title and paragraphs into a single text:\n",
        "article_text = title + '\\n\\n' + '\\n'.join(paragraphs)\n",
        "print(article_text)\n",
        "\n",
        "#article_text = parsed_doc.get_text()\n",
        "#print(article_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_dqist0pdl5"
      },
      "source": [
        "Parse the article to identify the entities and display them:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMTsfAhYpdl6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "54830406-13fc-47b1-e405-4810f30cd4ba"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Coronavirus: \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brazil\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              "'s President \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " tests positive<br><br>\n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brazil\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              "'s President \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Jair Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " has tested positive for coronavirus.<br>He took the test, his \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    fourth\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
              "</mark>\n",
              ", on \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Monday\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " after developing symptoms, including a high temperature.<br>Mr \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " has repeatedly played down risks of what he has called the &quot;little flu&quot;, saying he would not be seriously affected. He has opposed lockdowns, which he says hurt the economy.<br>\n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brazil\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " has the \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    second\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
              "</mark>\n",
              "-highest number of Covid-19 cases and deaths in the world, after the \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    US\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              ". <br>He made the announcement in a TV interview on \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Tuesday\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ", saying the fever he had been experiencing had gone down and that he felt &quot;very well&quot;.<br>Mr \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " said that he had started experiencing symptoms on \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Sunday\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ". He said he had had a high temperature, a cough and had felt unwell. <br>He added that on \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Monday\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " he had felt worse, which prompted him to take the coronavirus test.<br>Mr \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " is in a higher-risk group because of \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    his age, 65\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ".<br>He said he was taking hydroxychloroquine - championed by \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    US\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " President \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Donald Trump\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " - and azithromycin, an antibiotic, to treat the illness. Neither has been proven to be effective against the virus.<br>Contact tracing and tests will be carried out for the people Mr \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " has met recently.<br>His previous \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    three\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " tests for the virus all came back negative.<br>The executive director of \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    the World Health Organization\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ", Dr \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Mike Ryan\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", wished President \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " &quot;a speedy and full recovery from this disease&quot;, adding: &quot;I think the message to us all is: we are vulnerable to this virus.&quot;<br>Back in \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    April\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ", Mr \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " said that even if infected, he would &quot;not have to worry as I wouldn't feel anything, at most it would be like a little flu or a little cold&quot;.<br>The number of Covid-19-related deaths and infections - at that time \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    under 3,000 and 40,000 -\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">QUANTITY</span>\n",
              "</mark>\n",
              " has since soared.<br>Despite this, President \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " has argued that regional lockdowns are having a more damaging effect than the virus itself, and accused the media of spreading panic and paranoia.<br>His other comments on the virus include:<br>He has since continued to rail against measures that he deems &quot;dictatorial&quot; such as the closing beaches or requirements to wear face coverings. <br>On \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Monday\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ", he made further changes to a law that would require \n",
              "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brazilians\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
              "</mark>\n",
              " to wear masks in public.<br>He has attended a number of public events without a mask, even when local rules required him to wear one.<br>On \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Sunday\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ", Foreign Minister \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Ernesto Araújo\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " posted a photo on social media showing himself with President \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " and others attending an \n",
              "<mark class=\"entity\" style=\"background: #ffeb80; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Independence Day\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EVENT</span>\n",
              "</mark>\n",
              " celebration at the \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    US\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " embassy in \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brasilia\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              ". <br>None of those in the photo is wearing a mask or observing social distancing.<br>The \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    US\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " embassy said that the ambassador had had lunch with Mr \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " and others on \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    4 July\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ". It added that the ambassador had no symptoms but that he would undergo testing.<br>The ambassador had earlier tweeted a picture of himself with President \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ".<br>For so long, \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Jair Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " has tried to brush off this virus - the irony that he has now caught it has not been missed in \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brazil\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              ". <br>His detractors - of which he has many - have weighed in, calling this karma - that \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Jair Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " invited this to happen. <br>There was even a column in one of the biggest newspapers, \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Folha de São Paulo\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ", entitled &quot;Why I'm Cheering for Bolsonaro to Die&quot; - this is how divided, how toxic  the political picture is here in \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brazil\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " as the pandemic takes hold. <br>But the fact is, \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " joins the \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    nearly 1.7 million\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brazilians\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
              "</mark>\n",
              " who've contracted Covid-19. They're scary numbers and \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brazil\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " is a country in trouble, where coronavirus is spreading fast. <br>\n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Will Jair Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " get away with mild symptoms and carry on downplaying it? Or change tack now the virus has hit home? Whatever happens, with the man at the top suffering from Covid-19, it symbolises the crisis this country is in. <br>Infections in \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brazil\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " and \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Latin America\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " as a whole took a while to take hold but then started to rise, initially for \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brazil\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " in its \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Amazonas\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " region but then more starkly in \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Rio de Janeiro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " and \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    São Paulo\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ".<br>\n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brazil\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " became only the \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    second\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
              "</mark>\n",
              " country to pass \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    one million\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " cases on \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    20 June\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " and has continued to rise, passing \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    1.5 million\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              ". Many experts believe deficiencies in testing mean the overall figures for cases and deaths could be considerably higher.<br>Nevertheless lockdowns began to be lifted in many areas even as the cases surged. Both Rio and \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    São Paulo\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " have reopened bars and restaurants in \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    the past week\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ".<br>\n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Two\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " health ministers - both doctors - have left their posts after disagreements with the president.<br>\n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    One\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " ray of hope though is \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brazil\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              "'s renowned expertise in vaccines. \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Two\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " major vaccine tests, in partnership with \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    AstraZeneca and Sinovac\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ", are to begin final phase testing on \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    thousands\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " of \n",
              "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brazilian\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
              "</mark>\n",
              " volunteers.<br>Copyright \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2025\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    BBC\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ". All rights reserved.  The \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    BBC\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " is not responsible for the content of external sites. Read about our approach to external linking.<br> </div></span>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "parsed_article = nlp_model(article_text)\n",
        "displacy.render(parsed_article,jupyter=True,style='ent')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6I8_zJQrpdl6"
      },
      "source": [
        "What do you think? Did it work?\n",
        "\n",
        "Let's have a bit of a better look at the entities found\n",
        "- List all the distinct entities found in the article, sorted alphabetically:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SakcaXuypdl6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ede1a33d-f574-437d-a31f-b46ef6849287"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1.5 million',\n",
              " '20 June',\n",
              " '2025',\n",
              " '4 July',\n",
              " 'Amazonas',\n",
              " 'April',\n",
              " 'AstraZeneca and Sinovac',\n",
              " 'BBC',\n",
              " 'Bolsonaro',\n",
              " 'Brasilia',\n",
              " 'Brazil',\n",
              " 'Brazilian',\n",
              " 'Brazilians',\n",
              " 'Donald Trump',\n",
              " 'Ernesto Araújo',\n",
              " 'Folha de São Paulo',\n",
              " 'Independence Day',\n",
              " 'Jair Bolsonaro',\n",
              " 'Latin America',\n",
              " 'Mike Ryan',\n",
              " 'Monday',\n",
              " 'One',\n",
              " 'Rio de Janeiro',\n",
              " 'Sunday',\n",
              " 'São Paulo',\n",
              " 'Tuesday',\n",
              " 'Two',\n",
              " 'US',\n",
              " 'Will Jair Bolsonaro',\n",
              " 'fourth',\n",
              " 'his age, 65',\n",
              " 'nearly 1.7 million',\n",
              " 'one million',\n",
              " 'second',\n",
              " 'the World Health Organization',\n",
              " 'the past week',\n",
              " 'thousands',\n",
              " 'three',\n",
              " 'under 3,000 and 40,000 -']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "sorted(set(x.text for x in parsed_article.ents))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyGeLXs8pdl6"
      },
      "source": [
        "We can count the number of times each **entity type** occurs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcmsbiUkpdl6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6657154-1ac6-488c-e7b7-2df359e0e29f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'GPE': 16,\n",
              "         'PERSON': 21,\n",
              "         'ORDINAL': 3,\n",
              "         'DATE': 12,\n",
              "         'CARDINAL': 8,\n",
              "         'ORG': 6,\n",
              "         'QUANTITY': 1,\n",
              "         'NORP': 3,\n",
              "         'EVENT': 1,\n",
              "         'LOC': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "labels = [x.label_ for x in parsed_article.ents]\n",
        "Counter(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tb3g9y5Kpdl6"
      },
      "source": [
        "We can also count the number of times each **entity name** occurs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPdOsoiApdl6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd24e6a6-7064-4811-c997-2fbe2adc34c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Bolsonaro', 12),\n",
              " ('Brazil', 10),\n",
              " ('US', 4),\n",
              " ('Jair Bolsonaro', 3),\n",
              " ('Monday', 3),\n",
              " ('second', 2),\n",
              " ('Sunday', 2),\n",
              " ('Brazilians', 2),\n",
              " ('São Paulo', 2),\n",
              " ('Two', 2),\n",
              " ('BBC', 2),\n",
              " ('fourth', 1),\n",
              " ('Tuesday', 1),\n",
              " ('his age, 65', 1),\n",
              " ('Donald Trump', 1),\n",
              " ('three', 1),\n",
              " ('the World Health Organization', 1),\n",
              " ('Mike Ryan', 1),\n",
              " ('April', 1),\n",
              " ('under 3,000 and 40,000 -', 1),\n",
              " ('Ernesto Araújo', 1),\n",
              " ('Independence Day', 1),\n",
              " ('Brasilia', 1),\n",
              " ('4 July', 1),\n",
              " ('Folha de São Paulo', 1),\n",
              " ('nearly 1.7 million', 1),\n",
              " ('Will Jair Bolsonaro', 1),\n",
              " ('Latin America', 1),\n",
              " ('Amazonas', 1),\n",
              " ('Rio de Janeiro', 1),\n",
              " ('one million', 1),\n",
              " ('20 June', 1),\n",
              " ('1.5 million', 1),\n",
              " ('the past week', 1),\n",
              " ('One', 1),\n",
              " ('AstraZeneca and Sinovac', 1),\n",
              " ('thousands', 1),\n",
              " ('Brazilian', 1),\n",
              " ('2025', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "items = [x.text for x in parsed_article.ents]\n",
        "Counter(items).most_common()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEV2BJCTpdl7"
      },
      "source": [
        "Note that some of the phrases refer to the same entity, e.g. 'Mr Bolsonaro' and just 'Bolsonaro'.\n",
        "- Entity Linking and Reference Resolution are the NLP problems that deal with resolving the different references to the same entity in the text.\n",
        "\n",
        "If we were only interested in what was being said about Bolsonaro,\n",
        "- we could select only sentences refering to him:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNXjt46Jpdl7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 787
        },
        "outputId": "bf975511-1182-4103-d5d4-d815caf3e87c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Coronavirus: \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brazil\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              "'s President \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " tests positive<br><br>\n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brazil\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              "'s President \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Jair Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " has tested positive for coronavirus.<br></div>\n",
              "\n",
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Mr \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " has repeatedly played down risks of what he has called the &quot;little flu&quot;, saying he would not be seriously affected. </div>\n",
              "\n",
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Mr \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " said that he had started experiencing symptoms on \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Sunday\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ". </div>\n",
              "\n",
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Mr \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " is in a higher-risk group because of \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    his age, 65\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ".<br></div>\n",
              "\n",
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Contact tracing and tests will be carried out for the people Mr \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " has met recently.<br></div>\n",
              "\n",
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The executive director of \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    the World Health Organization\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ", Dr \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Mike Ryan\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", wished President \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " &quot;a speedy and full recovery from this disease&quot;, adding: &quot;I think the message to us all is: we are vulnerable to this virus.</div>\n",
              "\n",
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">&quot;<br>Back in \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    April\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ", Mr \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " said that even if infected, he would &quot;not have to worry as I wouldn't feel anything, at most it would be like a little flu or a little cold&quot;.<br></div>\n",
              "\n",
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Despite this, President \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " has argued that regional lockdowns are having a more damaging effect than the virus itself, and accused the media of spreading panic and paranoia.<br></div>\n",
              "\n",
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">On \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Sunday\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ", Foreign Minister \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Ernesto Araújo\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " posted a photo on social media showing himself with President \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " and others attending an \n",
              "<mark class=\"entity\" style=\"background: #ffeb80; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Independence Day\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EVENT</span>\n",
              "</mark>\n",
              " celebration at the \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    US\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " embassy in \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brasilia\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              ". <br></div>\n",
              "\n",
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    US\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " embassy said that the ambassador had had lunch with Mr \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " and others on \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    4 July\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ". </div>\n",
              "\n",
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The ambassador had earlier tweeted a picture of himself with President \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ".<br></div>\n",
              "\n",
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">For so long, \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Jair Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " has tried to brush off this virus - the irony that he has now caught it has not been missed in \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brazil\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              ". <br></div>\n",
              "\n",
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">His detractors - of which he has many - have weighed in, calling this karma - that \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Jair Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " invited this to happen. <br></div>\n",
              "\n",
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">There was even a column in one of the biggest newspapers, \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Folha de São Paulo\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ", entitled &quot;Why I'm Cheering for Bolsonaro to Die&quot; - this is how divided, how toxic  the political picture is here in \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brazil\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " as the pandemic takes hold. <br></div>\n",
              "\n",
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">But the fact is, \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " joins the \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    nearly 1.7 million\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brazilians\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
              "</mark>\n",
              " who've contracted Covid-19. </div>\n",
              "\n",
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Will Jair Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " get away with mild symptoms and carry on downplaying it? </div></span>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "sentences_containing_Bolsonaro = [x for x in parsed_article.sents if 'Bolsonaro' in x.text]\n",
        "displacy.render(sentences_containing_Bolsonaro,jupyter=True,style='ent')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkJvASO9pdl7"
      },
      "source": [
        "## Named Entity Extraction in Italian\n",
        "\n",
        "But wait, SpaCy can speak Italian too!\n",
        "- Let's make use of the pretrained italian model that we downloaded earlier: https://spacy.io/models/it\n",
        "- to recognise entities in an article from 'Il Corriere'\n",
        "\n",
        "First download the article:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCTkJTsopdl7"
      },
      "outputs": [],
      "source": [
        "url = 'https://www.ansa.it/sito/notizie/mondo/2020/07/07/bolsonaro-ha-i-sintomi-del-coronavirus_40d26967-e377-4455-9b42-83c2756cf5f1.html'\n",
        "html_doc = requests.get(url).text\n",
        "parsed_doc = BeautifulSoup(html_doc, 'lxml')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrnqQcMOpdl7"
      },
      "source": [
        "Now let's extract the title and paragraph text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIyIysghpdl7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3149ff1c-c7d4-402c-c8e8-8628e3351214"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bolsonaro positivo al test del coronavirus - Mondo - ANSA\n",
            "\n",
            "Se hai scelto di non accettare i cookie di  profilazione e tracciamento, puoi aderire all’abbonamento \"Consentless\" a un  costo molto accessibile, oppure scegliere un altro abbonamento per accedere ad ANSA.it.\n",
            "Ti invitiamo a leggere le Condizioni  Generali di Servizio, la Cookie Policy e l'Informativa Privacy. \n",
            "Puoi leggere tutti i titoli di ANSA.it e 10  contenuti ogni 30 giornia €16,99/anno\n",
            "Per accedere senza limiti a tutti i contenuti di ANSA.it\n",
            "Scegli il piano di  abbonamento più adatto alle tue esigenze.\n",
            "Se hai cambiato idea e non ti vuoi abbonare, puoi sempre esprimere il tuo consenso ai cookie di profilazione e tracciamento per leggere tutti i titoli di ANSA.it e 10 contenuti ogni 30 giorni (servizio base):\n",
            "Se accetti tutti i cookie di profilazione pubblicitaria e di tracciamento, noi e terze  parti selezionate utilizzeremo cookie e tecnologie simili per raccogliere ed  elaborare i tuoi dati personali e fornirti annunci e contenuti personalizzati,  valutare l’interazione con annunci e contenuti, effettuare ricerche di mercato,  migliorare i prodotti e i servizi.Per maggiori  informazioni accedi alla Cookie Policy e all'Informativa Privacy. \n",
            "Per maggiori informazioni sui servizi di ANSA.it, puoi consultare le nostre risposte alle domande più frequenti, oppure contattarci inviando una mail a register@ansa.it o telefonando al numero verde 800 938 881. Il servizio di assistenza clienti è attivo dal lunedì al venerdì dalle ore 09.00 alle ore 18:30, il sabato dalle ore 09:00 alle ore 14:00.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "    Il presidente brasiliano, Jair Bolsonaro, è risultato positivo al test sul Covid-19: lo ha reso noto lui stesso parlando in diretta a Tv Brasil dal Palacio da Alvorada, sua residenza ufficiale a Brasilia.    Ieri Bolsonaro aveva detto di sentirsi \"molto meglio, anche la febbre è scesa\". Bolsonaro - che ha già cancellato tutti gli impegni di lavoro previsti per questa settimana - aveva anche precisato che, non appena si è sentito male, ha iniziato ad assumere compresse di idrossiclorochina, seguendo l'esempio del suo omologo americano, Donald Trump, anche lui favorevole alla cura con il farmaco, spesso indicato per i casi di malaria.    Intanto, si è scatenato scatenato l'odio sul web contro il presidente brasiliano, accusato da più parti di aver sempre minimizzato la pandemia da coronavirus nel suo Paese.    In vetta ai 'trending topic' su Twitter in Brasile c'è infatti l'hashtag \"forca covid\" (forza covid). Una tendenza simile si era registrata anche all'epoca della positività di Boris Johnson, pure lui inizialmente scettico sulla gravità della malattia. Il premier britannico poi guarì dopo essere stato ricoverato in gravi condizioni.    Nel caso di Bolsonaro, il tenore della maggioranza dei tweet è forse ancora più violento, con migliaia di utenti che augurano apertamente la morte al capo di Stato verdeoro.    Prima di sottoporsi al test, Bolsonaro ha effettuato anche un esame dei polmoni. \"Vengo dall'ospedale, ho fatto una risonanza dei polmoni, sono puliti, tra un pò farò anche l'esame per il Covid, ma va tutto bene\", aveva spiegato lunedì sera il presidente della Repubblica a un gruppo di simpatizzanti che lo attendevano davanti al Palacio da Alvorada, la sua residenza ufficiale a Brasilia.   Bolsonaro si era già sottposto a due tamponi, poi risultati negativi, a marzo, dopo una visita negli Stati Uniti, al cui ritorno oltre 20 membri del suo staff erano risultati positivi. La scorsa settimana il presidente aveva detto che potrebbe avere contratto la malattia, pur senza manifestarne i sintomi, ma aveva ribadito la sua contrarietà al lockdown e ad altre misure restrittive imposte dalle autorità sanitarie per contenere la diffusione del coronavirus, difendendo la ripresa dell'economia.\n",
            "22:17\n",
            "20:59\n",
            "20:14\n",
            "19:42\n",
            "18:07\n",
            "18:07\n",
            "18:06\n",
            "17:39\n"
          ]
        }
      ],
      "source": [
        "title = parsed_doc.find('title').text\n",
        "paragraphs = [p.text for p in parsed_doc.find_all('p')]\n",
        "\n",
        "# Combine the title and paragraphs into a single text:\n",
        "article_text = title + '\\n\\n' + '\\n'.join(paragraphs)\n",
        "print(article_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eluDQCqxpdl7"
      },
      "source": [
        "Now we'll parse the text of the article with an Italian NLP engine to extract Named Entities.\n",
        "- First load the italian model 'it_core_news_sm' that we downloaded earlier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qj0IIHlVpdl7"
      },
      "outputs": [],
      "source": [
        "import it_core_news_sm\n",
        "nlp_it = it_core_news_sm.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcWwDGlypdl8"
      },
      "source": [
        "Parse article and extract the entities:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1X-Kuw6lpdl8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "daab419f-a9d0-494f-cffa-18090677e3fc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " positivo al test del coronavirus - Mondo - \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ANSA\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              "<br><br>Se hai scelto di non accettare i cookie di  profilazione e tracciamento, puoi aderire all’abbonamento &quot;\n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Consentless\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              "&quot; a un  costo molto accessibile, oppure scegliere un altro abbonamento per accedere ad \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ANSA.it\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
              "</mark>\n",
              ".<br>\n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Ti\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " invitiamo a leggere le \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Condizioni  Generali\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
              "</mark>\n",
              " di \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Servizio\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              ", la \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Cookie Policy\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " e l'\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Informativa Privacy\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              ". <br>Puoi leggere tutti i titoli di \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ANSA.it\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
              "</mark>\n",
              " e 10  contenuti ogni 30 giornia €16,99/anno<br>Per accedere senza limiti a tutti i contenuti di \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ANSA.it\n",
              "Scegli\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " il piano di  abbonamento più adatto alle tue esigenze.<br>Se hai cambiato idea e non ti vuoi abbonare, puoi sempre esprimere il tuo consenso ai cookie di profilazione e tracciamento per leggere tutti i titoli di \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ANSA.it\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
              "</mark>\n",
              " e 10 contenuti ogni 30 giorni (servizio base):<br>Se accetti tutti i cookie di profilazione pubblicitaria e di tracciamento, noi e terze  parti selezionate utilizzeremo cookie e tecnologie simili per raccogliere ed  elaborare i tuoi dati personali e fornirti annunci e contenuti personalizzati,  valutare l’interazione con annunci e contenuti, effettuare ricerche di mercato,  migliorare i prodotti e i servizi.Per maggiori  informazioni accedi alla \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Cookie Policy\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " e all'\n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Informativa Privacy\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              ". <br>Per maggiori informazioni sui servizi di \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ANSA.it\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
              "</mark>\n",
              ", puoi consultare le nostre risposte alle domande più frequenti, oppure contattarci inviando una mail a \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    register@ansa.it\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " o telefonando al numero verde 800 938 881. Il servizio di assistenza clienti è attivo dal lunedì al venerdì dalle ore 09.00 alle ore 18:30, il sabato dalle ore 09:00 alle ore 14:00.<br><br><br><br><br><br><br>    Il presidente brasiliano, \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Jair Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              ", è risultato positivo al test sul Covid-19: lo ha reso noto lui stesso parlando in diretta a \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Tv Brasil dal Palacio da Alvorada\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
              "</mark>\n",
              ", sua residenza ufficiale a \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brasilia\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              ".    \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Ieri Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              " aveva detto di sentirsi &quot;molto meglio, anche la febbre è scesa&quot;. \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro -\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
              "</mark>\n",
              " che ha già cancellato tutti gli impegni di lavoro previsti per questa settimana - aveva anche precisato che, non appena si è sentito male, ha iniziato ad assumere compresse di idrossiclorochina, seguendo l'esempio del suo omologo americano, \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Donald Trump\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              ", anche lui favorevole alla cura con il farmaco, spesso indicato per i casi di malaria.    Intanto, si è scatenato scatenato l'odio sul web contro il presidente brasiliano, accusato da più parti di aver sempre minimizzato la pandemia da coronavirus nel suo \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Paese\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              ".    In vetta ai 'trending topic' su \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Twitter\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " in \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brasile\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " c'è infatti l'\n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    hashtag\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " &quot;forca covid&quot; (forza covid). Una tendenza simile si era registrata anche all'epoca della positività di \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Boris Johnson\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              ", pure lui inizialmente scettico sulla gravità della malattia. Il premier britannico poi guarì dopo essere stato ricoverato in gravi condizioni.    Nel caso di \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              ", il tenore della maggioranza dei tweet è forse ancora più violento, con migliaia di utenti che augurano apertamente la morte al capo di \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Stato\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " verdeoro.    Prima di sottoporsi al test, \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " ha effettuato anche un esame dei polmoni. &quot;\n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Vengo\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " dall'ospedale, ho fatto una risonanza dei polmoni, sono puliti, tra un pò farò anche l'esame per il \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Covid\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
              "</mark>\n",
              ", ma va tutto bene&quot;, aveva spiegato lunedì sera il presidente della \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Repubblica\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " a un gruppo di simpatizzanti che lo attendevano davanti al \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Palacio da Alvorada\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              ", la sua residenza ufficiale a \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brasilia\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              ".   \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " si era già sottposto a due tamponi, poi risultati negativi, a marzo, dopo una visita negli \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Stati Uniti\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              ", al cui ritorno oltre 20 membri del suo staff erano risultati positivi. La scorsa settimana il presidente aveva detto che potrebbe avere contratto la malattia, pur senza manifestarne i sintomi, ma aveva ribadito la sua contrarietà al lockdown e ad altre misure restrittive imposte dalle autorità sanitarie per contenere la diffusione del coronavirus, difendendo la ripresa dell'economia.<br>22:17<br>20:59<br>20:14<br>19:42<br>18:07<br>18:07<br>18:06<br>17:39</div></span>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "parsed_article = nlp_it(article_text)\n",
        "displacy.render(parsed_article, jupyter=True, style='ent')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08h69wcxpdl8"
      },
      "source": [
        "That looks not great.\n",
        "- Here are the entities found in the news article:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKefi_fspdl8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1676ded-8278-4804-96a0-4fe07a3cd089"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ANSA',\n",
              " 'ANSA.it',\n",
              " 'ANSA.it\\nScegli',\n",
              " 'Bolsonaro',\n",
              " 'Bolsonaro -',\n",
              " 'Boris Johnson',\n",
              " 'Brasile',\n",
              " 'Brasilia',\n",
              " 'Condizioni  Generali',\n",
              " 'Consentless',\n",
              " 'Cookie Policy',\n",
              " 'Covid',\n",
              " 'Donald Trump',\n",
              " 'Ieri Bolsonaro',\n",
              " 'Informativa Privacy',\n",
              " 'Jair Bolsonaro',\n",
              " 'Paese',\n",
              " 'Palacio da Alvorada',\n",
              " 'Repubblica',\n",
              " 'Servizio',\n",
              " 'Stati Uniti',\n",
              " 'Stato',\n",
              " 'Ti',\n",
              " 'Tv Brasil dal Palacio da Alvorada',\n",
              " 'Twitter',\n",
              " 'Vengo',\n",
              " 'hashtag',\n",
              " 'register@ansa.it']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "sorted(set(x.text for x in parsed_article.ents))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GNZaLqN4Dx-"
      },
      "source": [
        "Alterantively you can use Stanza (https://stanfordnlp.github.io/stanza/). It's very similar to spaCy:\n",
        "- Python package\n",
        "- Supports multiple languages\n",
        "- Uses deep neural network modules\n",
        "\n",
        "Let's start installing the library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6JmKZ3xLPwI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd6b18e5-5452-426c-a699-1f4d88a2519a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: stanza in /usr/local/lib/python3.11/dist-packages (1.10.1)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.11/dist-packages (from stanza) (2.14.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from stanza) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=3.15.0 in /usr/local/lib/python3.11/dist-packages (from stanza) (4.25.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from stanza) (2.32.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from stanza) (3.4.2)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from stanza) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from stanza) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (4.12.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.3.0->stanza) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->stanza) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->stanza) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->stanza) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->stanza) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.3.0->stanza) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "import locale\n",
        "\n",
        "def get_pref_encoding(*args, **kwargs):\n",
        "    return \"UTF-8\"\n",
        "\n",
        "\n",
        "locale.getpreferredencoding = get_pref_encoding\n",
        "!pip install stanza"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NazOsrqKLgtW"
      },
      "source": [
        "Now we can import Stanza and create a pipeline for Italian"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2vbIhiQLfhH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364,
          "referenced_widgets": [
            "73b14e84e45e4cfc9c251c1b07385a33",
            "c91068862a6742b6955f99801598a785",
            "5ea397e611e74f42bd078bdac7c4bbd1",
            "dc5e6bdaaa804d09873ae781c00a69da",
            "c8f7a7d87fee479cbbafc7d03ec44aba",
            "9bc354e617a8453daf0a3ba3782a8498",
            "26677e9072a64d16a6f4059e769cae5e",
            "49ea17ee73084fbbb8db7c6bc8e4da97",
            "c2a51ebcde1b46b38e36f6ac6b52422f",
            "3ec31dad4b344b2590aff92734f5a720",
            "f15a6508f63e43079bacafb2cf90855c"
          ]
        },
        "outputId": "5d10ce16-8099-4824-b63c-fa24854dcffe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:stanza:Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "73b14e84e45e4cfc9c251c1b07385a33"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:stanza:Downloaded file to /root/stanza_resources/resources.json\n",
            "WARNING:stanza:Language it package default expects mwt, which has been added\n",
            "INFO:stanza:Loading these models for language: it (Italian):\n",
            "========================\n",
            "| Processor | Package  |\n",
            "------------------------\n",
            "| tokenize  | combined |\n",
            "| mwt       | combined |\n",
            "| ner       | fbk      |\n",
            "========================\n",
            "\n",
            "INFO:stanza:Using device: cuda\n",
            "INFO:stanza:Loading: tokenize\n",
            "INFO:stanza:Loading: mwt\n",
            "INFO:stanza:Loading: ner\n",
            "INFO:stanza:Done loading processors!\n"
          ]
        }
      ],
      "source": [
        "import stanza\n",
        "\n",
        "stanza_nlp_model = stanza.Pipeline(lang='it', processors='tokenize,ner')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aN8vExE_MWGK"
      },
      "source": [
        "As before we need to parse the document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHqxZTBALfm7"
      },
      "outputs": [],
      "source": [
        "stanza_parsed_article = stanza_nlp_model(article_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHx67HKdMtNi"
      },
      "source": [
        "Given a document, Stanza breaks it into sentences and then tokens.\n",
        "For each token adds the tags using the sleected processors (here we are using only the NER processors).\n",
        "\n",
        "Let's give a look at the identified entities:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cw98dV1yLfsu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9802051e-2315-4518-f1e1-9fe8f997a06e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANSA.it: ORG\n",
            "ANSA.it: ORG\n",
            "ANSA.it: ORG\n",
            "ANSA.it: ORG\n",
            "ANSA.it: ORG\n",
            "register@ansa.it: ORG\n",
            "Jair Bolsonaro: PER\n",
            "Tv Brasil: LOC\n",
            "Palacio: LOC\n",
            "Alvorada: LOC\n",
            "Brasilia: LOC\n",
            "Bolsonaro: PER\n",
            "Bolsonaro: PER\n",
            "Donald Trump: PER\n",
            "Brasile: LOC\n",
            "Boris Johnson: PER\n",
            "Bolsonaro: PER\n",
            "Bolsonaro: PER\n",
            "Repubblica: ORG\n",
            "Palacio: PER\n",
            "Alvorada: LOC\n",
            "Brasilia: LOC\n",
            "Bolsonaro: PER\n",
            "Stati Uniti: LOC\n"
          ]
        }
      ],
      "source": [
        "for sentence in stanza_parsed_article.sentences:\n",
        "    for entity in sentence.ents:  # Hello, Treebeard!\n",
        "        print(f\"{entity.text}: {entity.type}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LDtG1YcN__S"
      },
      "source": [
        "That's a bit better than before, don't you think?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzFM8cAUpdl8"
      },
      "source": [
        "## Fine-tuning your own NER Model\n",
        "\n",
        "What if you want to update the Named Entity Extraction model yourself in order to customize it to your set of entities? We'll have a look at that now based on:\n",
        "- this instructions page: https://spacy.io/usage/training#ner\n",
        "- and this blog post: https://towardsdatascience.com/custom-named-entity-recognition-using-spacy-7140ebbb3718\n",
        "\n",
        "In order to fine-tune the model, we need to prepare data in the following format:\n",
        "- a piece of text,\n",
        "- plus a list of entity types that occur it along with their positions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8aaj2uepdl8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69394691-8034-4a69-cc40-9a811b20b13b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Have you heard of an associate professor from the Politecnico di Milano called Mark Carman?',\n",
              "  {'entities': [(50, 71, 'ORG'), (79, 90, 'PERSON')]}),\n",
              " (\"No, I haven't, but I don't know many people at the Politecnico. What does he work on?\",\n",
              "  {'entities': [(51, 62, 'ORG')]}),\n",
              " ('Mainly machine learning and text mining. I met him a couple of years ago at SIGIR in Tokyo.',\n",
              "  {'entities': [(76, 81, 'EVENT'), (85, 90, 'GPE')]})]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "my_data = [\n",
        "    (\"Have you heard of an associate professor from the Politecnico di Milano called Mark Carman?\", {\"entities\": [(50, 71, \"ORG\"),(79, 90, \"PERSON\")]}),\n",
        "    (\"No, I haven't, but I don't know many people at the Politecnico. What does he work on?\", {\"entities\": [(51, 62, \"ORG\")]}),\n",
        "    (\"Mainly machine learning and text mining. I met him a couple of years ago at SIGIR in Tokyo.\", {\"entities\": [(76, 81, \"EVENT\"),(85, 90, \"GPE\")]}),\n",
        "]\n",
        "my_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnVIriSEpdl9"
      },
      "source": [
        "Where would this data come from?\n",
        "- either created manually, perhaps by searching for known individuals in a text collection,\n",
        "- or by using an annotation tool such as https://doccano.herokuapp.com/, see for example: https://medium.com/@justindavies/training-spacy-ner-models-with-doccano-8d8203e29bfa\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1s9T3Whe5lZJ"
      },
      "source": [
        "The following code comes from here: https://github.com/explosion/spaCy/blob/master/examples/training/train_ner.py\n",
        "- The only change made was to remove the training data\n",
        "\n",
        "Before starting we need to install the plac package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P057B5jUQjqM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "391a679a-ad0a-4dcc-aa1f-fd0d5bd4adfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting plac\n",
            "  Downloading plac-1.4.3-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Downloading plac-1.4.3-py2.py3-none-any.whl (22 kB)\n",
            "Installing collected packages: plac\n",
            "Successfully installed plac-1.4.3\n"
          ]
        }
      ],
      "source": [
        "!pip install plac"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-oMt4jRQj2k"
      },
      "source": [
        "Now we define function with the training loop:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVjhWJ1Zpdl9"
      },
      "outputs": [],
      "source": [
        "from __future__ import unicode_literals, print_function\n",
        "\n",
        "import plac\n",
        "import random\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "import spacy\n",
        "from spacy.util import minibatch, compounding\n",
        "from spacy.training.example import Example\n",
        "\n",
        "\n",
        "@plac.annotations(\n",
        "    model=(\"Model name. Defaults to blank 'en' model.\", \"option\", \"m\", str),\n",
        "    output_dir=(\"Optional output directory\", \"option\", \"o\", Path),\n",
        "    n_iter=(\"Number of training iterations\", \"option\", \"n\", int),\n",
        ")\n",
        "def main(model=None, output_dir=None, n_iter=100):\n",
        "    \"\"\"Load the model, set up the pipeline and train the entity recognizer.\"\"\"\n",
        "    if model is not None:\n",
        "        nlp = spacy.load(model)  # load existing spaCy model\n",
        "        print(\"Loaded model '%s'\" % model)\n",
        "    else:\n",
        "        nlp = spacy.blank(\"en\")  # create blank Language class\n",
        "        print(\"Created blank 'en' model\")\n",
        "\n",
        "    # create the built-in pipeline components and add them to the pipeline\n",
        "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
        "    if \"ner\" not in nlp.pipe_names:\n",
        "        ner = nlp.create_pipe(\"ner\")\n",
        "        nlp.add_pipe(ner, last=True)\n",
        "    # otherwise, get it so we can add labels\n",
        "    else:\n",
        "        ner = nlp.get_pipe(\"ner\")\n",
        "\n",
        "    # add labels\n",
        "    for _, annotations in TRAIN_DATA:\n",
        "        for ent in annotations.get(\"entities\"):\n",
        "            ner.add_label(ent[2])\n",
        "\n",
        "    # get names of other pipes to disable them during training\n",
        "    pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
        "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
        "    # only train NER\n",
        "    with nlp.disable_pipes(*other_pipes), warnings.catch_warnings():\n",
        "        # show warnings for misaligned entity spans once\n",
        "        warnings.filterwarnings(\"once\", category=UserWarning, module='spacy')\n",
        "\n",
        "        # reset and initialize the weights randomly – but only if we're\n",
        "        # training a new model\n",
        "        if model is None:\n",
        "            nlp.begin_training()\n",
        "        for itn in range(n_iter):\n",
        "            random.shuffle(TRAIN_DATA)\n",
        "            losses = {}\n",
        "            # batch up the examples using spaCy's minibatch\n",
        "            batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))\n",
        "            for batch in batches:\n",
        "                # Create example\n",
        "                examples = [\n",
        "                    Example.from_dict(nlp.make_doc(text), annotation)\n",
        "                    for text, annotation in batch\n",
        "                ]\n",
        "                # Update the model\n",
        "                nlp.update(\n",
        "                    examples,   # batch of texts and annotations\n",
        "                    drop=0.5,  # dropout - make it harder to memorise data\n",
        "                    losses=losses,\n",
        "                )\n",
        "            print(\"Losses\", losses)\n",
        "\n",
        "    # test the trained model\n",
        "    for text, _ in TRAIN_DATA:\n",
        "        doc = nlp(text)\n",
        "        print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n",
        "        print(\"Tokens\", [(t.text, t.ent_type_, t.ent_iob) for t in doc])\n",
        "\n",
        "    # save model to output directory\n",
        "    if output_dir is not None:\n",
        "        output_dir = Path(output_dir)\n",
        "        if not output_dir.exists():\n",
        "            output_dir.mkdir()\n",
        "        nlp.to_disk(output_dir)\n",
        "        print(\"Saved model to\", output_dir)\n",
        "\n",
        "        # test the saved model\n",
        "        print(\"Loading from\", output_dir)\n",
        "        nlp2 = spacy.load(output_dir)\n",
        "        for text, _ in TRAIN_DATA:\n",
        "            doc = nlp2(text)\n",
        "            print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n",
        "            print(\"Tokens\", [(t.text, t.ent_type_, t.ent_iob) for t in doc])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1pM_VOIpdl9"
      },
      "source": [
        "Once the above model has been defined, we can update and save the model\n",
        "- Note that this code doesn't currently run in Google colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1cpkZGWpdl9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "679aced6-7076-4b77-baa6-b18e92cdbee1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded model 'en_core_web_sm'\n",
            "Losses {'ner': np.float32(6.606235)}\n",
            "Losses {'ner': np.float32(4.7534437)}\n",
            "Losses {'ner': np.float32(6.5325933)}\n",
            "Losses {'ner': np.float32(5.186345)}\n",
            "Losses {'ner': np.float32(4.85298)}\n",
            "Entities [('Mark Carman', 'PERSON')]\n",
            "Tokens [('Have', '', 2), ('you', '', 2), ('heard', '', 2), ('of', '', 2), ('an', '', 2), ('associate', '', 2), ('professor', '', 2), ('from', '', 2), ('the', '', 2), ('Politecnico', '', 2), ('di', '', 2), ('Milano', '', 2), ('called', '', 2), ('Mark', 'PERSON', 3), ('Carman', 'PERSON', 1), ('?', '', 2)]\n",
            "Entities [('a couple of years ago', 'DATE'), ('Tokyo', 'GPE')]\n",
            "Tokens [('Mainly', '', 2), ('machine', '', 2), ('learning', '', 2), ('and', '', 2), ('text', '', 2), ('mining', '', 2), ('.', '', 2), ('I', '', 2), ('met', '', 2), ('him', '', 2), ('a', 'DATE', 3), ('couple', 'DATE', 1), ('of', 'DATE', 1), ('years', 'DATE', 1), ('ago', 'DATE', 1), ('at', '', 2), ('SIGIR', '', 2), ('in', '', 2), ('Tokyo', 'GPE', 3), ('.', '', 2)]\n",
            "Entities [('Politecnico', 'ORG')]\n",
            "Tokens [('No', '', 2), (',', '', 2), ('I', '', 2), ('have', '', 2), (\"n't\", '', 2), (',', '', 2), ('but', '', 2), ('I', '', 2), ('do', '', 2), (\"n't\", '', 2), ('know', '', 2), ('many', '', 2), ('people', '', 2), ('at', '', 2), ('the', '', 2), ('Politecnico', 'ORG', 3), ('.', '', 2), ('What', '', 2), ('does', '', 2), ('he', '', 2), ('work', '', 2), ('on', '', 2), ('?', '', 2)]\n",
            "Saved model to spacy_model\n",
            "Loading from spacy_model\n",
            "Entities [('Mark Carman', 'PERSON')]\n",
            "Tokens [('Have', '', 2), ('you', '', 2), ('heard', '', 2), ('of', '', 2), ('an', '', 2), ('associate', '', 2), ('professor', '', 2), ('from', '', 2), ('the', '', 2), ('Politecnico', '', 2), ('di', '', 2), ('Milano', '', 2), ('called', '', 2), ('Mark', 'PERSON', 3), ('Carman', 'PERSON', 1), ('?', '', 2)]\n",
            "Entities [('a couple of years ago', 'DATE'), ('Tokyo', 'GPE')]\n",
            "Tokens [('Mainly', '', 2), ('machine', '', 2), ('learning', '', 2), ('and', '', 2), ('text', '', 2), ('mining', '', 2), ('.', '', 2), ('I', '', 2), ('met', '', 2), ('him', '', 2), ('a', 'DATE', 3), ('couple', 'DATE', 1), ('of', 'DATE', 1), ('years', 'DATE', 1), ('ago', 'DATE', 1), ('at', '', 2), ('SIGIR', '', 2), ('in', '', 2), ('Tokyo', 'GPE', 3), ('.', '', 2)]\n",
            "Entities [('Politecnico', 'ORG')]\n",
            "Tokens [('No', '', 2), (',', '', 2), ('I', '', 2), ('have', '', 2), (\"n't\", '', 2), (',', '', 2), ('but', '', 2), ('I', '', 2), ('do', '', 2), (\"n't\", '', 2), ('know', '', 2), ('many', '', 2), ('people', '', 2), ('at', '', 2), ('the', '', 2), ('Politecnico', 'ORG', 3), ('.', '', 2), ('What', '', 2), ('does', '', 2), ('he', '', 2), ('work', '', 2), ('on', '', 2), ('?', '', 2)]\n"
          ]
        }
      ],
      "source": [
        "TRAIN_DATA=my_data  # The method expects the training data to have this name\n",
        "main(model='en_core_web_sm',output_dir='spacy_model',n_iter=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlicBTgepdl-"
      },
      "source": [
        "## Entity Linking in spaCy\n",
        "\n",
        "We don't want to just find entity mentions in a document but link them to a known entity in a knowledge base.\n",
        "- The task of linking the entity mentions to the corresponding entity in the knowledge base is called 'Entity Linking'.\n",
        "- Watch this video to learn more:\n",
        "https://spacy.io/universe/project/video-spacy-irl-entity-linking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BKB-yMKpdl-"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "73b14e84e45e4cfc9c251c1b07385a33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c91068862a6742b6955f99801598a785",
              "IPY_MODEL_5ea397e611e74f42bd078bdac7c4bbd1",
              "IPY_MODEL_dc5e6bdaaa804d09873ae781c00a69da"
            ],
            "layout": "IPY_MODEL_c8f7a7d87fee479cbbafc7d03ec44aba"
          }
        },
        "c91068862a6742b6955f99801598a785": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9bc354e617a8453daf0a3ba3782a8498",
            "placeholder": "​",
            "style": "IPY_MODEL_26677e9072a64d16a6f4059e769cae5e",
            "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json: "
          }
        },
        "5ea397e611e74f42bd078bdac7c4bbd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49ea17ee73084fbbb8db7c6bc8e4da97",
            "max": 52557,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c2a51ebcde1b46b38e36f6ac6b52422f",
            "value": 52557
          }
        },
        "dc5e6bdaaa804d09873ae781c00a69da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ec31dad4b344b2590aff92734f5a720",
            "placeholder": "​",
            "style": "IPY_MODEL_f15a6508f63e43079bacafb2cf90855c",
            "value": " 424k/? [00:00&lt;00:00, 29.3MB/s]"
          }
        },
        "c8f7a7d87fee479cbbafc7d03ec44aba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bc354e617a8453daf0a3ba3782a8498": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26677e9072a64d16a6f4059e769cae5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49ea17ee73084fbbb8db7c6bc8e4da97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2a51ebcde1b46b38e36f6ac6b52422f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ec31dad4b344b2590aff92734f5a720": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f15a6508f63e43079bacafb2cf90855c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}