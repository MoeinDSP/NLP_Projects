{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MoeinDSP/NLP_Projects/blob/main/Word%20Embeddings/05_Word_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auM3jLkGYHk5"
      },
      "source": [
        "# Word Embeddings\n",
        "\n",
        "In this session we will make use of Word2Vec to learn distributed representations of words based on the context within which they appear in sentences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHv1LsPley3G"
      },
      "source": [
        "**Optional for Colab users**\n",
        "\n",
        "Before starting, we can set up the connection with the Google Dive storage, to keep there our documents.\n",
        "Just execute the following passages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "UIa6j0dXey3H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "447480bd-7a3f-401a-94eb-ae73301b1202"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6nd2Gsmey3I"
      },
      "source": [
        "Make sure that the variable path contains the correct sequence of folders separate by a `'/'` to get to your lecture files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PqaF2l7ey3J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "af119eda-26c3-46e0-827b-cc2bd591d46f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Practical_05__Word-Embeddings'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "path = '/content/drive/MyDrive/Practical_05__Word-Embeddings'\n",
        "\n",
        "os.chdir(f'{path}')\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPtKB1FNYHlH"
      },
      "source": [
        "## Learning word embeddings\n",
        "\n",
        "We'll first try to learn word embeddings using the Word2Vec implementation provided by the gensim package.\n",
        "- Information on gensim's word2vec implementation is available here: https://radimrehurek.com/gensim/models/word2vec.html\n",
        "- First install the package using pip:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmJqt2NRYHlH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ab36b3e-518a-4231-f343-e3823fa334a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scipy, gensim\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.14.1\n",
            "    Uninstalling scipy-1.14.1:\n",
            "      Successfully uninstalled scipy-1.14.1\n",
            "Successfully installed gensim-4.3.3 scipy-1.13.1\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade gensim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdrV0qU6YHlH"
      },
      "source": [
        "We will build a Word2Vec embedding using the 20 Newsgroup data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_erNR7XIrDh"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "dataset_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
        "dataset_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTTluJ3TYHlH"
      },
      "source": [
        "In order to train Word2Vec on the data we first need to convert it to the right format.\n",
        "- For training Word2Vec, it is usual to **separate data into individual sentences** and then tokenize those sentences separately\n",
        "- So let's use regular expressions to remove the end-of-line characters from each document and then split the documents into sentences using a regular expression that looks for question marks, exclamation marks, and periods, followed by a space:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jCPB46UYHlH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65f713c7-b095-450c-8273-742fc19ba193"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['I was wondering if anyone out there could enlighten me on this car I saw the other day',\n",
              "  'It was a 2-door sports car, looked to be from the late 60s/ early 70s',\n",
              "  'It was called a Bricklin',\n",
              "  'The doors were really small',\n",
              "  'In addition, the front bumper was separate from the rest of the body',\n",
              "  'This is  all I know',\n",
              "  'If anyone can tellme a model name, engine specs, years of production, where this car is made, history, or whatever info you have on this funky looking car, please e-mail.'],\n",
              " ['A fair number of brave souls who upgraded their SI clock oscillator have shared their experiences for this poll',\n",
              "  'Please send a brief message detailing your experiences with the procedure',\n",
              "  'Top speed attained, CPU rated speed, add on cards and adapters, heat sinks, hour of usage per day, floppy disk functionality with 800 and 1.4 m floppies are especially requested',\n",
              "  \" I will be summarizing in the next two days, so please add to the network knowledge base if you have done the clock upgrade and haven't answered this poll\",\n",
              "  'Thanks.'],\n",
              " ['well folks, my mac plus finally gave up the ghost this weekend after starting life as a 512k way back in 1985',\n",
              "  \" sooo, i'm in the market for a new machine a bit sooner than i intended to be..\",\n",
              "  \" i'm looking into picking up a powerbook 160 or maybe 180 and have a bunch of questions that (hopefully) somebody can answer:  * does anybody know any dirt on when the next round of powerbook introductions are expected\",\n",
              "  ' i\\'d heard the 185c was supposed to make an appearence \"this summer\" but haven\\'t heard anymore on it - and since i don\\'t have access to macleak, i was wondering if anybody out there had more info..',\n",
              "  \" * has anybody heard rumors about price drops to the powerbook line like the ones the duo's just went through recently\",\n",
              "  \" * what's the impression of the display on the 180\",\n",
              "  ' i could probably swing a 180 if i got the 80Mb disk rather than the 120, but i don\\'t really have a feel for how much \"better\" the display is (yea, it looks great in the store, but is that all \"wow\" or is it really that good?)',\n",
              "  ' could i solicit some opinions of people who use the 160 and 180 day-to-day on if its worth taking the disk size and money hit to get the active display',\n",
              "  \" (i realize this is a real subjective question, but i've only played around with the machines in a computer store breifly and figured the opinions of somebody who actually uses the machine daily might prove helpful)\",\n",
              "  ' * how well does hellcats perform',\n",
              "  \" ;)  thanks a bunch in advance for any info - if you could email, i'll post a summary (news reading time is at a premium with finals just around the corner..\",\n",
              "  ':( ) -- Tom Willis  \\\\      \\\\    Purdue Electrical Engineering']]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "# remove newline characters\n",
        "docs = [re.sub('\\n', ' ', doc) for doc in dataset_train.data]\n",
        "# remove email addresses\n",
        "docs = [re.sub('[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}', '', doc) for doc in docs]\n",
        "# split sentences\n",
        "sentences = [re.split('[?!.]\\s', doc) for doc in docs]\n",
        "sentences[:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIucFhmVYHlI"
      },
      "source": [
        "Above, we've printed out the first two documents, which have been split into arrays of sentences.\n",
        "- We'll need to flatten the structure into one big array of sentences (remove the distinction between documents) before providing it to Word2Vec.\n",
        "- We can do that using the flatten command from the pandas library:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HB2YTCX1YHlI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53913b83-fd26-478c-9035-d82daf6c34fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I was wondering if anyone out there could enlighten me on this car I saw the other day',\n",
              " 'It was a 2-door sports car, looked to be from the late 60s/ early 70s',\n",
              " 'It was called a Bricklin',\n",
              " 'The doors were really small',\n",
              " 'In addition, the front bumper was separate from the rest of the body',\n",
              " 'This is  all I know',\n",
              " 'If anyone can tellme a model name, engine specs, years of production, where this car is made, history, or whatever info you have on this funky looking car, please e-mail.',\n",
              " 'A fair number of brave souls who upgraded their SI clock oscillator have shared their experiences for this poll',\n",
              " 'Please send a brief message detailing your experiences with the procedure',\n",
              " 'Top speed attained, CPU rated speed, add on cards and adapters, heat sinks, hour of usage per day, floppy disk functionality with 800 and 1.4 m floppies are especially requested',\n",
              " \" I will be summarizing in the next two days, so please add to the network knowledge base if you have done the clock upgrade and haven't answered this poll\",\n",
              " 'Thanks.',\n",
              " 'well folks, my mac plus finally gave up the ghost this weekend after starting life as a 512k way back in 1985',\n",
              " \" sooo, i'm in the market for a new machine a bit sooner than i intended to be..\",\n",
              " \" i'm looking into picking up a powerbook 160 or maybe 180 and have a bunch of questions that (hopefully) somebody can answer:  * does anybody know any dirt on when the next round of powerbook introductions are expected\",\n",
              " ' i\\'d heard the 185c was supposed to make an appearence \"this summer\" but haven\\'t heard anymore on it - and since i don\\'t have access to macleak, i was wondering if anybody out there had more info..',\n",
              " \" * has anybody heard rumors about price drops to the powerbook line like the ones the duo's just went through recently\",\n",
              " \" * what's the impression of the display on the 180\",\n",
              " ' i could probably swing a 180 if i got the 80Mb disk rather than the 120, but i don\\'t really have a feel for how much \"better\" the display is (yea, it looks great in the store, but is that all \"wow\" or is it really that good?)',\n",
              " ' could i solicit some opinions of people who use the 160 and 180 day-to-day on if its worth taking the disk size and money hit to get the active display']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "from pandas.core.common import flatten\n",
        "\n",
        "sentences = list(flatten(sentences))\n",
        "sentences[:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAQ0LlmEYHlI"
      },
      "source": [
        "Now we can proceed to do some cleaning of the data:\n",
        "- remove non-letter characters from each sentence\n",
        "- lowercase\n",
        "- tokenize the sentences based on whitespace\n",
        "- remove any sentence with length less than 2 since it won't be useful for training Word2Vec."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgpm3IvQYHlI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75463782-b6e6-4b4c-a565-3fae3cdcf761"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'was', 'wondering', 'if', 'anyone', 'out', 'there', 'could', 'enlighten', 'me', 'on', 'this', 'car', 'i', 'saw', 'the', 'other', 'day']\n",
            "['it', 'was', 'a', '2', 'door', 'sports', 'car', 'looked', 'to', 'be', 'from', 'the', 'late', '60s', 'early', '70s']\n",
            "['it', 'was', 'called', 'a', 'bricklin']\n",
            "['the', 'doors', 'were', 'really', 'small']\n",
            "['in', 'addition', 'the', 'front', 'bumper', 'was', 'separate', 'from', 'the', 'rest', 'of', 'the', 'body']\n",
            "['this', 'is', 'all', 'i', 'know']\n",
            "['if', 'anyone', 'can', 'tellme', 'a', 'model', 'name', 'engine', 'specs', 'years', 'of', 'production', 'where', 'this', 'car', 'is', 'made', 'history', 'or', 'whatever', 'info', 'you', 'have', 'on', 'this', 'funky', 'looking', 'car', 'please', 'e', 'mail']\n",
            "['a', 'fair', 'number', 'of', 'brave', 'souls', 'who', 'upgraded', 'their', 'si', 'clock', 'oscillator', 'have', 'shared', 'their', 'experiences', 'for', 'this', 'poll']\n",
            "['please', 'send', 'a', 'brief', 'message', 'detailing', 'your', 'experiences', 'with', 'the', 'procedure']\n",
            "['top', 'speed', 'attained', 'cpu', 'rated', 'speed', 'add', 'on', 'cards', 'and', 'adapters', 'heat', 'sinks', 'hour', 'of', 'usage', 'per', 'day', 'floppy', 'disk', 'functionality', 'with', '800', 'and', '1', '4', 'm', 'floppies', 'are', 'especially', 'requested']\n"
          ]
        }
      ],
      "source": [
        "tokenized_sentences = [re.sub('\\W', ' ', sentence).lower().split() for sentence in sentences]\n",
        "# remove sentences that are only 1 word long\n",
        "tokenized_sentences = [sentence for sentence in tokenized_sentences if len(sentence) > 1]\n",
        "\n",
        "for sentence in tokenized_sentences[:10]:\n",
        "    print(sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xYG3RKRYHlI"
      },
      "source": [
        "Finally we have the data in the right format for training Word2Vec, so we can provide it to the model. For parameters, we set:\n",
        "- the embedding size to be 30,\n",
        "- the minimum count for any vocabulary term to be 5\n",
        "- the size of the context window to 10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXolbjAXYHlJ"
      },
      "outputs": [],
      "source": [
        "from gensim.models.word2vec import Word2Vec\n",
        "\n",
        "model = Word2Vec(tokenized_sentences, vector_size=30, min_count=5, window=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BP16EM3YHlJ"
      },
      "source": [
        "Let's see how big the vocabulary is that Word2Vec ended up using, i.e. how many word vectors did it learn:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Z7ZYKyxcYHlJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96dfdc5b-d755-4960-9216-4ff579585469"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22069"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "len(model.wv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHRbIkEYYHlJ"
      },
      "source": [
        "## Inspecting embeddings and finding similar words\n",
        "\n",
        "Now that we have a word2vec model trained, what can we do with it?\n",
        "- Let's print out one of the vectors to see what it looks like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "1XJtGX3YYHlJ",
        "outputId": "2a202ad2-49ad-4f5d-8ffc-b64f72a06128",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.7559625 ,  0.6472946 ,  2.1280231 , -2.4135783 ,  0.18323535,\n",
              "       -0.01846329,  0.1828807 , -1.0578258 , -0.4933687 ,  0.16063736,\n",
              "        1.9403836 ,  1.1408741 ,  2.1406827 ,  1.3721251 ,  1.1260915 ,\n",
              "       -0.26965767,  3.4714174 , -0.2595292 ,  1.9821072 ,  0.6344573 ,\n",
              "       -2.9201436 , -0.8415183 , -1.1564403 ,  1.0165981 , -2.1505692 ,\n",
              "       -0.9173762 ,  2.6843123 , -0.4237848 ,  4.656776  ,  1.2577894 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "term = 'car'\n",
        "model.wv[term]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAcJZJmyYHlJ"
      },
      "source": [
        "Unlike LDA's document topic vector, this one has both positive and negative values.\n",
        "\n",
        "We could now use the model to compute similarities between terms based on their cosine distance in the embedding space.\n",
        "- Try modifying the terms below to see what their closest neighbouring terms are:\n",
        "  - Some good terms to try are: hockey, mouse, god, microsoft, clinton, bush, etc.\n",
        "  - (If yuo see an error, that is because the term you chose is not in the dictionary.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ej6ij-9-YHlK"
      },
      "outputs": [],
      "source": [
        "# term = 'gun'\n",
        "# term = 'microsoft'\n",
        "# term ='clinton'\n",
        "\n",
        "model.wv.most_similar(term)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldnMBi7qYHlK"
      },
      "source": [
        "Do the similar terms agree with your intuition?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4Su5jmKYHlK"
      },
      "source": [
        "## Visualising the embedding vectors using t-SNE\n",
        "\n",
        "We'll now visualise some of the word vectors in a 3 dimensional space using t-SNE.\n",
        "\n",
        "The vocabulary of word vectors is quite large (around 25,000). Giving them all to t-SNE will cause it to take far too long to converge.\n",
        "- So let's first choose a random subset of 500 terms to show:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3GC2wXgYHlK"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "sample = random.sample(list(model.wv.key_to_index), 500)\n",
        "print(sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tb51ZnSpYHlK"
      },
      "source": [
        "Now we'll get the word vectors for the sampled terms:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdIlwUjaYHlK"
      },
      "outputs": [],
      "source": [
        "word_vectors = model.wv[sample]\n",
        "word_vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPKDpTt9YHlK"
      },
      "source": [
        "And we'll provide the vectors to TSNE to fit a model and transform the data to 3 dimensions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdSwKpggYHlK"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "tsne = TSNE(n_components=3, n_iter=2000)\n",
        "tsne_embedding = tsne.fit_transform(word_vectors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWDA5VAFYHlL"
      },
      "source": [
        "Now transform the data into 3 columns (for x, y, and z):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-ubEgoDYHlL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "x, y, z = np.transpose(tsne_embedding)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RQtluK0YHlL"
      },
      "source": [
        "And generate the 3d plot:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWS77SLJey3Q"
      },
      "outputs": [],
      "source": [
        "!pip install plotly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Addk422Dt_IW"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "\n",
        "fig = px.scatter_3d(x=x, y=y, z=z)\n",
        "fig.update_traces(marker=dict(size=3,line=dict(width=2)))\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4AIuIruYHlL"
      },
      "source": [
        "Well that's a not a particularly interesting 3d plot!\n",
        "- How about we label some of the points on the graph to see what words they correspond to:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwF1aJAQy9YY"
      },
      "outputs": [],
      "source": [
        "fig = px.scatter_3d(x=x[:200],y=y[:200],z=z[:200],text=sample[:200])\n",
        "fig.update_traces(marker=dict(size=3,line=dict(width=2)),textfont_size=10)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pr1QqmH9YHlL"
      },
      "source": [
        "Let's extend the random set of terms with a set of colours to see if they cluster:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_z7NLqgYHlL"
      },
      "outputs": [],
      "source": [
        "# Add some specific terms to sample:\n",
        "colours = ['red','green','blue','orange','yellow','purple','pink','cream','brown','black','white','gray']\n",
        "\n",
        "word_vectors = model.wv[colours+sample]\n",
        "\n",
        "tsne = TSNE(n_components=3)\n",
        "tsne_embedding = tsne.fit_transform(word_vectors)\n",
        "\n",
        "x, y, z = np.transpose(tsne_embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOBvqtDE-HZL"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "\n",
        "r = (-200,200)\n",
        "fig = px.scatter_3d(x=x, y=y, z=z, range_x=r, range_y=r, range_z=r, text=colours + [None] * 500)\n",
        "fig.update_traces(marker=dict(size=3,line=dict(width=2)),textfont_size=10)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xBPW2vnYHlM"
      },
      "source": [
        "Note: t-SNE is a stochastic algorithm, so run it a couple of times to see how the visualisation changes.\n",
        "\n",
        "Have a play around with the visualisation to see whether other sets of terms cluster together."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UxQIRBLYHlM"
      },
      "source": [
        "## Loading Pre-trained Embedding\n",
        "\n",
        "Instead of learning your own word embeddings from a dataset, it is common to download and make use of pre-trained embeddings that have been learnt on very large corpora.\n",
        "- See this list of models available in gensim: https://github.com/RaRe-Technologies/gensim-data\n",
        "- Note how big some of the models are. A 300 dimensional Word2Vec model trained on Google News (word2vec-google-news-300) is almost 1.7GB!\n",
        "\n",
        "Let's downlaod a couple of the smaller models and have a look at them:\n",
        "- We'll download two GloVe (similar to Word2Vec) based models\n",
        "- each has dimension of 50, but the first has been trained on data from Twitter and the second on data from Wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80lgMVCNYHlM"
      },
      "outputs": [],
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "model_twitter = api.load(\"glove-twitter-50\")\n",
        "model_wiki = api.load(\"glove-wiki-gigaword-50\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6Bg80kKYHlM"
      },
      "source": [
        "How big are their vocabularies?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0CcjNmIYHlM"
      },
      "outputs": [],
      "source": [
        "print(f\"Vocabulary size twitter model:   {len(model_twitter)}\")\n",
        "print(f\"Vocabulary size wikipedia model: {len(model_wiki)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zSEKFVjYHlM"
      },
      "source": [
        "Woah, they are big vocabularies!\n",
        "- The twitter one has over a million tokens!\n",
        "\n",
        "Let's have a look at the most similar terms to the word 'puppy' in Twitter embedding:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czJartaDYHlM"
      },
      "outputs": [],
      "source": [
        "term = 'puppy'\n",
        "print(f'Twitter embedding, most similar words to: {term}')\n",
        "model_twitter.most_similar(term)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2Wb68G5RWpj"
      },
      "source": [
        "And in the Wikipedia embedding:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5srhaTuYHlM"
      },
      "outputs": [],
      "source": [
        "print(f'Wikipedia embedding, most similar words to: {term}')\n",
        "model_wiki.most_similar(term)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ez-9f7DLQpDw"
      },
      "source": [
        "Which embedding is better?\n",
        "\n",
        "Try some other words:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmwYaVSiYHlN"
      },
      "outputs": [],
      "source": [
        "term = 'apple'\n",
        "# term = 'politecnico'\n",
        "print(f'Twitter embedding:   {model_twitter.most_similar(term)}')\n",
        "print(f'Wikipedia embedding: {model_wiki.most_similar(term)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBDEnr-0YHlN"
      },
      "source": [
        "Embedding spaces have interesting geometric properties, where translation between different word vectors caries semantic meaning.\n",
        "- Let's try running the famous analogy: king + (woman - man) = ?\n",
        "- To do that, first generate the resulting word embedding:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5cMZiNgYHlN"
      },
      "outputs": [],
      "source": [
        "vec = model_wiki.get_vector('king') + (model_wiki.get_vector('woman') - model_wiki.get_vector('man'))\n",
        "vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uYDSjJ7YHlN"
      },
      "source": [
        "- Then look for the most similar vectors to it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5ZMdc5WYHlN"
      },
      "outputs": [],
      "source": [
        "model_wiki.similar_by_vector(vec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tipFzCPnYHlN"
      },
      "source": [
        "Did it work?\n",
        "- Well, yes if you remove 'king' as an option, then it did!\n",
        "- Note that the most similar vector to the word 'king' was not 'queen' but 'prince', so the analogy is indeed changing the order ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDV5VRzAYHlN"
      },
      "outputs": [],
      "source": [
        "model_wiki.most_similar('king')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Io7Zm6EYHlN"
      },
      "source": [
        "Try it again but with the Twitter based model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2m511hj-YHlO"
      },
      "outputs": [],
      "source": [
        "model = model_twitter\n",
        "vec = model.get_vector('king') + (model.get_vector('woman') - model.get_vector('man'))\n",
        "model.similar_by_vector(vec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtEO2LWIYHlO"
      },
      "source": [
        "Doesn't seem that the Twitter model is as good on that analogy.\n",
        "- If you think about the average quality of text on Twitter versus Wikipedia, then that's probably not suprising!\n",
        "\n",
        "Try some other analogies:\n",
        "- What happens to Rome if we subtract Italy and add France?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXzOPQy5YHlO"
      },
      "outputs": [],
      "source": [
        "A = 'rome'\n",
        "B = 'italy'\n",
        "C = 'france'\n",
        "# C = 'indonesia'\n",
        "model = model_wiki\n",
        "vec = model.get_vector(A) - model.get_vector(B) + model.get_vector(C)\n",
        "model.similar_by_vector(vec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeUJZDSTYHlO"
      },
      "source": [
        "Now, **isn't that cool?** ;-)\n",
        "- Try some other countries ...\n",
        "\n",
        "Remember, we are only using the 'small' embeddings of 50 dimensions\n",
        "- you can download and try the bigger ones, some of them with 300 dimensions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stWE8L9GYgRH"
      },
      "source": [
        "## Classifying Tweets with word embeddings\n",
        "\n",
        "Let's try to use the word embeddings as features for a text classifier.\n",
        "- In particular, we'll try the tweet sentiment analysis task from the second session.\n",
        "- First download the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bckvn64GYqCZ"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('twitter_samples')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5nOSItcaEa9"
      },
      "source": [
        "Then prepare the dataset:\n",
        "- load the positive and negative tweets\n",
        "- remove emoticons from them\n",
        "- and merge them into a single dataset with class labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZBH76pnaTrB"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import twitter_samples\n",
        "\n",
        "positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
        "\n",
        "import re\n",
        "\n",
        "emoticon_regex = '(\\:\\w+\\:|\\<[\\/\\\\]?3|[\\(\\)\\\\\\D|\\*\\$][\\-\\^]?[\\:\\;\\=]|[\\:\\;\\=B8][\\-\\^]?[3DOPp\\@\\$\\*\\\\\\)\\(\\/\\|])(?=\\s|[\\!\\.\\?]|$)'\n",
        "positive_tweets_noemoticons = [re.sub(emoticon_regex,'',tweet) for tweet in positive_tweets]\n",
        "negative_tweets_noemoticons = [re.sub(emoticon_regex,'',tweet) for tweet in negative_tweets]\n",
        "\n",
        "tweets_x = positive_tweets_noemoticons + negative_tweets_noemoticons\n",
        "tweets_y = ['positive']*len(positive_tweets) + ['negative']*len(negative_tweets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ik6TlpDFa3Pt"
      },
      "source": [
        "Divide the data into train, validation and test sets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTDd49KVbC_o"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "temp_x, test_x, temp_y, test_y = train_test_split(tweets_x, tweets_y, test_size=0.2)\n",
        "train_x, valid_x, train_y, valid_y = train_test_split(temp_x, temp_y, test_size=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1aACZFHc_eg"
      },
      "source": [
        "Now we need to convert the tweets to an embedding representation.\n",
        "- We can do that by computing the sum (or average) of the embedding vectors of the words in the tweet.\n",
        "- To work out how to do that, let's have a look at the first tweet in the dataset, converting it to lowercase and tokenise it on whitespace:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVrlyZrqc_vz"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import re\n",
        "regex = '[' + string.punctuation + ']'\n",
        "\n",
        "print('tweet: \\'' + train_x[10] + '\\'')\n",
        "tokens = re.sub(regex, '', train_x[10].lower()).split()\n",
        "print('tokens: ', tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4eDTr_OkWUQ"
      },
      "source": [
        "- We can get the embedding vectors for the tokens present in the embedding vocabulary as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxgUgjVmkW61"
      },
      "outputs": [],
      "source": [
        "model = model_twitter\n",
        "embeddings = [model.get_vector(token) for token in tokens if token in model]\n",
        "embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p58DUnpNXenf"
      },
      "source": [
        "- the sum of the embeddings in the tweet is:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0uuM4q7sid9"
      },
      "outputs": [],
      "source": [
        "sum(embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpiF8tQCkZe5"
      },
      "source": [
        "- and the average of the embeddings is just:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ld2gtl6ukZty"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "np.mean(embeddings, axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCvTji3wlpGH"
      },
      "source": [
        "We will need to perform this vector transformation for all tweets in the training and also the test sets\n",
        "- We can define a procedure to do that for us"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uopuAE26d7gH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def vectorize(docs, embedding_model=model_twitter, useSum=True):\n",
        "    vectors = np.zeros((len(docs),50))\n",
        "    for i in range(len(docs)):\n",
        "        tokens = re.sub(regex, '', docs[i].lower()).split()\n",
        "        embeddings = [embedding_model.get_vector(token) for token in tokens if token in embedding_model]\n",
        "        if (len(embeddings) > 0):\n",
        "            if (useSum):\n",
        "                vectors[i] = sum(embeddings)\n",
        "            else:\n",
        "                vectors[i] = np.mean(embeddings, axis=0)\n",
        "    return vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WoMOcuFYcbM"
      },
      "source": [
        "Let's now vectorize the training set\n",
        "- and then print out one of the instances to check that the format is correct:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iviol4QhenZx"
      },
      "outputs": [],
      "source": [
        "train_x_vector = vectorize(train_x)\n",
        "train_x_vector[:3].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z39a21KpdBHb"
      },
      "source": [
        "Now that we have the vectorized training data, we can go ahead and train the model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCuF581vdBcp"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr_model = LogisticRegression(max_iter=1000).fit(train_x_vector, train_y)\n",
        "print(lr_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAQhGdw_Yyi1"
      },
      "source": [
        "Let's test the model on the example tweets from the second tutorial:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTb8hjCNkBf-"
      },
      "outputs": [],
      "source": [
        "tweets = []\n",
        "tweets.append('I can\\'t believe how much fun I\\'m having learning to train a text classifier using word embeddings!')\n",
        "tweets.append('I am really confused. I want my mommy.')\n",
        "tweets.append('The internet connection has been pretty annoying today!')\n",
        "tweets.append('They just played my favourite song on the radio.')\n",
        "tweets.append(\"I don't like going to the dentist.\")\n",
        "tweets.append(\"Can't wait for my three hour math class tomorrow morning. Yay!\")\n",
        "\n",
        "\n",
        "transformed_tweets = vectorize(tweets)\n",
        "predictions = lr_model.predict(transformed_tweets)\n",
        "predicted_probabilities = lr_model.predict_proba(transformed_tweets)\n",
        "\n",
        "for i in range(len(tweets)):\n",
        "  print(f'tweet:      {tweets[i]}')\n",
        "  print(f'prediction: {predictions[i]}')\n",
        "  print(f'confidence: {predicted_probabilities[i]}')\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLBJOO8cbVHP"
      },
      "source": [
        "We can have a look at the coefficients of the logistic regression classification model.\n",
        "- How many should there be?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPtPzQuLomrR"
      },
      "outputs": [],
      "source": [
        "lr_model.coef_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eso1pS5Ybevo"
      },
      "source": [
        "Let's vectorize the validaton data and see how well the embeddings-based classifier performs on it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DncyqQpinGHG"
      },
      "outputs": [],
      "source": [
        "valid_x_vector = vectorize(valid_x)\n",
        "pred_y = lr_model.predict(valid_x_vector)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(f'Accuracy: {accuracy_score(valid_y, pred_y)}')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "ConfusionMatrixDisplay.from_estimator(lr_model, valid_x_vector, valid_y, values_format='d')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7z23krami3W0"
      },
      "source": [
        "So pretty much the same accuracy as the bag-of-words based classifier.\n",
        "- but this time with feature vectors of size 50\n",
        "- what happens to the accuracy if we:\n",
        "  - use a different embedding: model_wiki instead of model_twitter\n",
        "  - use a bigger (higher dimensional) embedding: download a larger one to see\n",
        "  - use the average rather than the sum to generate the feature vector?\n",
        "- try it out:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ojy2UOofkQsE"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HR7lw-Ljey3g"
      },
      "outputs": [],
      "source": [
        "# Vectorise\n",
        "train_x_vector = vectorize(train_x, embedding_model=model_wiki)\n",
        "# Fit model\n",
        "lr_model = LogisticRegression(max_iter=1000).fit(train_x_vector, train_y)\n",
        "# Evaluate results\n",
        "valid_x_vector = vectorize(valid_x, embedding_model=model_wiki)\n",
        "pred_y = lr_model.predict(valid_x_vector)\n",
        "\n",
        "print(f'Accuracy: {accuracy_score(valid_y, pred_y)}')\n",
        "\n",
        "ConfusionMatrixDisplay.from_estimator(lr_model, valid_x_vector, valid_y, values_format='d')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RpC810Dey3g"
      },
      "outputs": [],
      "source": [
        "# Vectorise\n",
        "train_x_vector = vectorize(train_x, embedding_model=model_wiki, useSum=False)\n",
        "# Fit model\n",
        "lr_model = LogisticRegression(max_iter=1000).fit(train_x_vector, train_y)\n",
        "# Evaluate results\n",
        "valid_x_vector = vectorize(valid_x, embedding_model=model_wiki, useSum=False)\n",
        "pred_y = lr_model.predict(valid_x_vector)\n",
        "\n",
        "print(f'Accuracy: {accuracy_score(valid_y, pred_y)}')\n",
        "\n",
        "ConfusionMatrixDisplay.from_estimator(lr_model, valid_x_vector, valid_y, values_format='d')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "arZYGnXSey3g"
      },
      "outputs": [],
      "source": [
        "# Vecorise\n",
        "train_x_vector = vectorize(train_x, useSum=False)\n",
        "# Fit model\n",
        "lr_model = LogisticRegression(max_iter=1000).fit(train_x_vector, train_y)\n",
        "# Evaluate results\n",
        "valid_x_vector = vectorize(valid_x, useSum=False)\n",
        "pred_y = lr_model.predict(valid_x_vector)\n",
        "\n",
        "print(f'Accuracy: {accuracy_score(valid_y, pred_y)}')\n",
        "\n",
        "ConfusionMatrixDisplay.from_estimator(lr_model, valid_x_vector, valid_y, values_format='d')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyByBTXHey3h"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvWLcBqGkTFO"
      },
      "source": [
        "Also worth trying is doc2vec rather than word2vec embeddings:\n",
        "- in theory they should give slightly better performance on sentence classification tasks\n",
        "- see here: https://radimrehurek.com/gensim/auto_examples/tutorials/run_doc2vec_lee.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIvbxdRpYHlO"
      },
      "source": [
        "## Other uses for Word2Vec embeddings\n",
        "\n",
        "Have a look at this inventive post that learns Word2Vec embeddings for automobiles described in CSV file:\n",
        "- https://towardsdatascience.com/a-beginners-guide-to-word-embedding-with-gensim-word2vec-model-5970fa56cc92\n",
        "- The embeddings allow for similarity computations across  the vehicles.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YWk4FnIYHlO"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PifwcbdWqKz"
      },
      "source": [
        "## FastText (sub-word) embeddings\n",
        "\n",
        "Try training a fasttext model:\n",
        "\n",
        "https://pypi.org/project/fasttext/\n",
        "\n",
        "You can have a look at the API and documentation at this [link](https://fasttext.cc)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJn_r-pPHxim"
      },
      "source": [
        "Let's start by installing the fastText package.\n",
        "(Note that, alterantively, Genism has a specific API for fastText that wraps the package we are going to use)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52qmtcvvKmXD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5467f233-e444-4e79-afc7-9147d5a386d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.11/dist-packages (0.9.3)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.11/dist-packages (from fasttext) (2.13.6)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from fasttext) (75.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fasttext) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install fasttext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x62UPMmPwTZN"
      },
      "source": [
        "Now that we have installed the package, we can download one of the pre-trained models (you can find [here](https://fasttext.cc/docs/en/crawl-vectors.html) the list of available models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w332B-YpwTjV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eee46868-c2ce-4a6b-f549-f60004a4a160"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-12 10:16:10--  http://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 13.35.186.77, 13.35.186.32, 13.35.186.93, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|13.35.186.77|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4503593528 (4.2G) [application/octet-stream]\n",
            "Saving to: ‘cc.en.300.bin.gz.3’\n",
            "\n",
            "cc.en.300.bin.gz.3  100%[===================>]   4.19G  51.0MB/s    in 92s     \n",
            "\n",
            "2025-03-12 10:17:42 (46.6 MB/s) - ‘cc.en.300.bin.gz.3’ saved [4503593528/4503593528]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# !wget https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.en.zip\n",
        "!wget http://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n",
        "!gzip -d cc.en.300.bin.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bExOLO48vjwe"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tDcLNT9fKUl"
      },
      "source": [
        "Finally we can create a model istance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrDxcw89fKgr"
      },
      "outputs": [],
      "source": [
        "import fasttext\n",
        "\n",
        "ft_model = fasttext.load_model('./cc.en.300.bin')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnpPQ0j3mUiE"
      },
      "source": [
        "What is the size of the vocabulary?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhqskdAimTLa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f0f7672-018f-4105-eaee-c12f2855b0c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000000"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "len(ft_model.get_words())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19fBomf5mVDU"
      },
      "source": [
        "What is the size of the embeddings?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JK9X-b5XmTic",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86aeb42c-9e15-4029-826f-ac1338f4d73b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "ft_model.get_dimension()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEAa1rU2ey3j"
      },
      "source": [
        "How do we get the embedding of a word?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMzSd9-2ey3j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87c5cc2b-eb61-4b51-e73d-4568248d917e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.37498349e-01,  1.73652887e-01,  1.55173652e-02,  2.37601340e-01,\n",
              "       -2.04669774e-01,  1.87128603e-01,  2.91468382e-01,  3.73304449e-03,\n",
              "        4.89513204e-02,  2.60247648e-01, -8.31757560e-02, -1.56491295e-01,\n",
              "        8.69184956e-02, -4.78181392e-02, -1.18615523e-01,  1.54884279e-01,\n",
              "       -1.69153258e-01, -1.22394666e-01, -1.40723094e-01,  4.53762040e-02,\n",
              "       -3.81604545e-02, -1.46799475e-01,  1.36863321e-01, -1.50539711e-01,\n",
              "       -1.81618929e-02,  1.47275031e-02, -4.21417244e-02,  1.39445990e-01,\n",
              "        4.28556725e-02,  3.05333138e-01, -1.66591443e-02,  2.91614503e-01,\n",
              "       -3.32667604e-02, -4.68752086e-02,  2.67606732e-02,  8.71477500e-02,\n",
              "       -5.38966954e-02,  1.33774459e-01,  8.50976482e-02, -6.40801638e-02,\n",
              "       -1.03779674e-01, -1.81272849e-01, -1.10902652e-01,  1.66989714e-01,\n",
              "       -1.99763715e-01,  4.53899801e-03, -1.89182535e-02, -2.78699417e-02,\n",
              "       -2.93243110e-01, -5.81464916e-03,  1.75295904e-01,  1.08659819e-01,\n",
              "       -1.88145787e-02,  2.53145359e-02,  9.95914787e-02, -3.12647223e-02,\n",
              "        9.74955484e-02, -1.57494023e-01, -1.64722189e-01, -6.87088072e-02,\n",
              "        9.10460949e-05,  1.59804896e-02,  1.10373735e-01,  6.10446706e-02,\n",
              "        1.07483588e-01, -1.33552194e-01, -7.02596456e-02,  1.16452649e-01,\n",
              "        1.18472248e-01,  6.14816248e-02, -8.17625001e-02,  4.12990153e-03,\n",
              "        1.23452470e-02,  1.57015212e-02,  3.73466015e-02, -1.09414756e-02,\n",
              "       -8.77702013e-02,  2.94106871e-01, -1.09256595e-01, -7.45082274e-02,\n",
              "       -2.63583213e-01, -2.84229126e-02, -1.52215466e-01, -1.00488283e-01,\n",
              "        4.63331118e-02, -6.50667697e-02, -7.57237226e-02,  1.46466196e-02,\n",
              "       -3.01163793e-02, -6.27530664e-02,  7.32356012e-02, -3.39862436e-01,\n",
              "       -2.12151855e-02,  1.20418519e-01,  1.95152871e-02,  1.46374375e-01,\n",
              "        4.19964790e-02,  2.27189422e-01, -4.76691127e-02,  5.83246611e-02,\n",
              "       -1.18166231e-01,  1.94506012e-02,  1.29298002e-01, -8.22782367e-02,\n",
              "       -1.82408914e-01,  1.22837633e-01, -4.33400944e-02, -7.62889758e-02,\n",
              "       -1.49289474e-01,  1.32627741e-01,  2.07074419e-01, -2.40204573e-01,\n",
              "       -3.01707983e-02,  1.00110896e-01,  1.09480068e-01,  1.78128794e-01,\n",
              "        5.19588068e-02, -1.18714668e-01, -6.70131519e-02,  2.07650527e-01,\n",
              "       -3.13496441e-02,  2.84634590e-01, -8.52486044e-02, -2.01036707e-02,\n",
              "       -1.93305723e-02, -2.07597405e-01, -1.20448753e-01,  1.40477762e-01,\n",
              "        1.05674461e-01,  3.88197601e-03,  6.56490326e-02, -2.37631038e-01,\n",
              "       -3.56610008e-02, -8.02731290e-02, -2.24592313e-02, -1.23117693e-01,\n",
              "        1.51049644e-01,  2.43693039e-01,  1.88642144e-01,  3.11025791e-03,\n",
              "       -1.42823428e-01,  7.86538571e-02,  6.08236715e-03, -1.67422846e-01,\n",
              "       -8.55229050e-02,  7.95976892e-02, -3.45605433e-01,  5.82623780e-02,\n",
              "       -1.06225297e-01, -1.78768754e-01, -4.63169813e-02, -7.22998232e-02,\n",
              "        6.99614957e-02, -1.17765516e-02, -1.15494572e-01, -5.82705364e-02,\n",
              "        1.16676003e-01,  5.70290461e-02, -7.90311471e-02,  8.35967138e-02,\n",
              "        8.16148371e-02, -1.73566580e-01,  2.34466106e-01,  3.13998163e-02,\n",
              "       -2.83091217e-02, -3.13015580e-02,  1.57410666e-01, -1.23833120e-02,\n",
              "       -6.04008958e-02,  1.00380607e-01,  1.09081395e-01,  5.35128973e-02,\n",
              "       -1.12907238e-01, -2.18785390e-01, -2.26536058e-02, -2.15117663e-01,\n",
              "       -1.11640386e-01, -3.89714614e-02,  8.59435648e-02, -1.97914347e-01,\n",
              "       -4.17543389e-02, -1.15136296e-01,  4.49582487e-02, -1.30544692e-01,\n",
              "       -6.05523065e-02,  3.08122993e-01, -4.84386310e-02, -5.04352376e-02,\n",
              "        5.67938611e-02,  1.03469603e-01,  3.77609134e-02,  1.75252743e-03,\n",
              "        2.36129127e-02,  1.28008991e-01, -9.24589187e-02, -1.44171059e-01,\n",
              "        3.02452624e-01, -1.20941728e-01,  2.55626217e-02, -4.43983078e-02,\n",
              "        1.31773561e-01,  5.05378768e-02,  4.99319136e-02, -4.53851558e-02,\n",
              "       -1.25326589e-01,  1.03378303e-01,  9.02659371e-02,  8.87431204e-03,\n",
              "        1.90032590e-02,  6.09402731e-02,  8.95207599e-02, -9.70865861e-02,\n",
              "       -9.47063640e-02,  2.91972943e-02, -1.52865816e-02, -1.61617801e-01,\n",
              "        3.19432677e-03, -6.58987164e-02,  6.43858016e-02, -2.62204409e-02,\n",
              "        7.66740441e-02, -3.07367295e-02, -1.66517615e-01, -4.53550480e-02,\n",
              "        1.12862349e-01,  2.02228762e-02, -6.31066635e-02, -2.73563862e-01,\n",
              "       -8.24580714e-02, -7.55187646e-02,  2.45882347e-01,  7.84016699e-02,\n",
              "       -7.31700063e-02, -5.58071174e-02, -2.08459049e-02,  1.32113360e-02,\n",
              "       -1.15614533e-01, -1.28816754e-01, -7.76782110e-02,  1.39297172e-02,\n",
              "        7.68901408e-02,  3.53115499e-02, -7.35836700e-02, -1.48101956e-01,\n",
              "        1.57499254e-01,  2.79525697e-01, -7.00949654e-02, -1.30779624e-01,\n",
              "       -6.56079650e-02, -3.89638245e-02,  2.90693641e-02,  2.53306665e-02,\n",
              "       -1.87344216e-02,  8.13647956e-02,  1.52117580e-01,  5.24173714e-02,\n",
              "       -2.27155939e-01,  3.56054865e-02,  1.05434768e-02, -6.52607605e-02,\n",
              "        9.73352417e-02, -6.46137819e-02, -2.53503621e-02,  1.22090224e-02,\n",
              "       -1.39826387e-01, -7.75838494e-02, -2.07123429e-01, -7.15182126e-02,\n",
              "        8.69591534e-03,  1.41621977e-02, -1.93011254e-01,  2.27474242e-01,\n",
              "       -1.15029059e-01,  4.09493409e-02, -8.25189203e-02, -7.64346272e-02,\n",
              "       -9.39211100e-02,  4.57039848e-02,  2.61136368e-02, -3.34188640e-02,\n",
              "        4.32544090e-02, -1.03707597e-01, -1.41373813e-01, -1.44344121e-01,\n",
              "        1.59042463e-01,  9.89959389e-03,  2.83480138e-02, -2.38574252e-01,\n",
              "       -2.76446074e-01, -8.09888542e-02, -4.18215282e-02,  1.75330192e-02,\n",
              "       -1.65929049e-01,  1.04931220e-01, -1.10928323e-02,  9.20476243e-02,\n",
              "        6.67028055e-02,  2.07736552e-01,  8.53124261e-02, -1.40121192e-01],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "ft_model.get_word_vector('car')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44hYw0bAey3k"
      },
      "source": [
        "Alterantively you can use it as a Python dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QZOh_e2ey3k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9cded34-2fc3-464e-8d5c-16e7265761a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2.05102742e-01, -1.17439777e-01, -1.55425537e-02,  1.79349303e-01,\n",
              "       -2.28049219e-01, -1.24558017e-01,  1.23250902e-01,  5.38473055e-02,\n",
              "        4.11795303e-02, -5.67295495e-03, -8.39752406e-02,  1.84653439e-02,\n",
              "       -8.60689804e-02,  1.12930965e-02, -1.33117482e-01,  1.38373390e-01,\n",
              "       -1.25412792e-01, -3.86665910e-02, -1.22192718e-01,  1.07491598e-01,\n",
              "        7.44868889e-02,  1.43000856e-01, -2.68281717e-02,  7.85946473e-03,\n",
              "       -3.62306088e-02, -2.08035931e-02,  9.95780062e-03, -5.96441068e-02,\n",
              "        3.78727615e-02,  1.31439894e-01, -6.71993792e-02,  6.71701431e-02,\n",
              "        1.11701377e-01, -1.82819627e-02, -1.02341630e-01,  9.74911451e-03,\n",
              "        4.25241441e-02, -1.59083098e-01,  3.72390151e-02, -1.32961005e-01,\n",
              "       -6.62351400e-02,  1.17778786e-01, -3.11643854e-02, -4.58469465e-02,\n",
              "       -1.54904723e-01,  2.37882137e-03,  2.09096503e-02, -6.17710687e-03,\n",
              "       -2.41204053e-01,  8.73834118e-02,  6.91391528e-02,  1.11958645e-01,\n",
              "       -1.52415112e-02, -1.00177675e-01, -6.60216436e-02,  7.77632892e-02,\n",
              "        9.00297761e-02,  3.69252376e-02, -2.52914429e-02,  2.36923918e-02,\n",
              "       -1.53724262e-02,  3.27921212e-02, -1.39887005e-01,  1.09796673e-02,\n",
              "        7.74039626e-02, -7.29498342e-02,  3.66372019e-02,  6.94629326e-02,\n",
              "       -4.31373864e-02,  3.86431366e-02, -2.37832926e-02, -2.62797046e-02,\n",
              "       -8.52299929e-02, -1.24506094e-03, -1.66640848e-01, -7.69969672e-02,\n",
              "        1.00765273e-01,  3.93868051e-03,  1.25144869e-02,  1.72688425e-01,\n",
              "       -4.70201746e-02, -7.07887039e-02,  2.69618072e-02,  8.90153423e-02,\n",
              "       -8.63350183e-02,  5.59332669e-02,  6.88511878e-02, -1.81689560e-02,\n",
              "        1.49315774e-01, -2.06480175e-03, -4.99112904e-02,  9.12162587e-02,\n",
              "        6.12079501e-02,  3.40343006e-02, -1.59623727e-01,  9.91314650e-03,\n",
              "        1.47123680e-01,  7.51622468e-02,  1.25847980e-01,  7.28560686e-02,\n",
              "       -1.20911151e-01,  1.33074015e-01, -2.40076296e-02, -8.61709863e-02,\n",
              "       -1.79991545e-03,  3.91840525e-02, -3.06748301e-02, -1.10395163e-01,\n",
              "       -1.44113809e-01,  3.47533152e-02,  1.26442760e-01,  1.51098520e-01,\n",
              "       -1.47495106e-01,  9.89220962e-02,  1.07589796e-01,  9.38937441e-02,\n",
              "       -1.53009564e-01, -1.30068827e-02, -1.14716075e-01, -1.30422384e-01,\n",
              "        1.86000764e-02,  5.32120466e-05, -2.31985860e-02, -1.07203282e-01,\n",
              "       -3.31636667e-02,  4.47869375e-02,  2.25304645e-02,  1.85147613e-01,\n",
              "        5.13294712e-03, -1.23191781e-01,  8.12826157e-02, -8.51961747e-02,\n",
              "       -9.72918421e-02, -1.90278441e-02, -6.44630939e-02, -1.08691052e-01,\n",
              "        2.70893425e-02,  1.02976874e-01,  1.80976331e-01, -1.63971558e-02,\n",
              "       -7.17620775e-02, -7.96736404e-02, -9.61826518e-02, -1.91508874e-01,\n",
              "        2.70473287e-02,  1.24248281e-01, -3.49661916e-01, -1.33518144e-01,\n",
              "       -2.82961894e-02, -9.26014706e-02, -4.25025821e-04, -2.86594480e-02,\n",
              "       -3.91338617e-02, -9.90596265e-02, -4.65282984e-02, -8.72748494e-02,\n",
              "        1.51935905e-01, -1.91162080e-02,  9.13072601e-02,  1.89611129e-02,\n",
              "       -1.08969875e-01, -2.90214196e-02,  8.61809775e-02, -2.18289584e-01,\n",
              "       -1.40584171e-01, -2.89806034e-02,  8.69408399e-02,  1.18448846e-02,\n",
              "        9.80549902e-02,  5.18676490e-02, -3.34505178e-03,  8.01285952e-02,\n",
              "        6.87225088e-02,  1.70012593e-01,  3.26067172e-02,  1.63739957e-02,\n",
              "        3.87846790e-02, -1.26889497e-02, -3.26282345e-02,  9.15853605e-02,\n",
              "        5.58803044e-03,  1.06696427e-01, -4.73687798e-02, -1.07843116e-01,\n",
              "       -8.31641108e-02,  1.36591256e-01,  2.29387909e-01, -2.46172547e-02,\n",
              "        2.01673638e-02, -2.14638207e-02, -1.00305840e-01,  1.96577206e-01,\n",
              "        1.44458741e-01,  9.78642032e-02,  1.25113457e-01, -5.35797067e-02,\n",
              "       -6.95556924e-02, -1.35392934e-01,  3.14381532e-02,  1.78394511e-01,\n",
              "        5.15805036e-02,  3.73208970e-02,  1.08873099e-01,  5.15858382e-02,\n",
              "        3.36884856e-02,  9.44927931e-02,  9.98455137e-02, -5.56635223e-02,\n",
              "       -1.62284330e-01,  2.38388091e-01,  8.31078738e-03, -7.34476894e-02,\n",
              "       -1.08296201e-01,  6.40900210e-02, -1.30532300e-02,  1.64562717e-01,\n",
              "        5.02874181e-02, -1.77713811e-01, -4.69116122e-03, -2.90708076e-02,\n",
              "        1.00689061e-01,  1.28326267e-01, -1.63036004e-01,  1.28823876e-01,\n",
              "       -4.02787179e-02, -1.83677584e-01,  7.98890889e-02, -4.12471667e-02,\n",
              "       -3.48612294e-02, -6.26894534e-02, -1.59047395e-01,  1.87391803e-01,\n",
              "        3.71768177e-02,  2.79565807e-02,  1.63159668e-01,  3.75718437e-02,\n",
              "        7.86873326e-02, -2.44909581e-02, -6.72861934e-02, -3.14295776e-02,\n",
              "        1.51372068e-02, -5.56141920e-02,  4.48027030e-02, -1.93316251e-01,\n",
              "        2.06538424e-01, -8.87603462e-02, -9.88327265e-02,  2.40609385e-02,\n",
              "       -1.47456363e-01,  8.88570175e-02, -9.27246436e-02, -9.50970054e-02,\n",
              "        1.18448839e-01,  3.29303920e-01,  1.54580414e-01,  1.43435687e-01,\n",
              "       -1.28814936e-01,  7.68910497e-02,  3.72115988e-03,  1.75254852e-01,\n",
              "       -8.40665251e-02, -2.76442617e-02, -5.33436462e-02,  7.45012611e-02,\n",
              "       -5.63166961e-02, -9.66539606e-04,  1.13127068e-01,  2.83497237e-02,\n",
              "        5.91475405e-02, -7.03010559e-02, -4.37492207e-02,  5.44570349e-02,\n",
              "       -2.06605077e-01,  3.03150155e-02, -1.34049416e-01, -3.00040841e-02,\n",
              "       -2.13847756e-02,  5.49306124e-02, -1.04515314e-01, -4.16764542e-02,\n",
              "       -5.24726398e-02, -5.46058267e-02, -1.92172214e-01, -2.53393352e-01,\n",
              "        1.28208563e-01, -3.39920893e-02,  5.07736392e-02,  3.05913612e-02,\n",
              "       -9.96698514e-02, -5.63710779e-02,  4.16795760e-02,  8.36478733e-03,\n",
              "       -1.09555885e-01,  4.91313301e-02,  3.91997732e-02,  2.97623277e-02,\n",
              "       -5.84195256e-02,  2.64039308e-01,  1.03534430e-01,  2.85770763e-02],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "ft_model['man']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7cqE-3XfAM9"
      },
      "source": [
        "Now we can test a bit the capabilities of fastText (examples are taken from [here](https://fasttext.cc/docs/en/unsupervised-tutorial.html))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdNL7kcTlIzH"
      },
      "source": [
        "A base functionality is to search for close vectors in the embedding space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85EKLO7FfAXA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "773429a6-0158-4503-89ba-691ec7a645d6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.7746413350105286, 'aspargus'),\n",
              " (0.7368614077568054, 'Asparagus'),\n",
              " (0.7233701944351196, 'broccoli'),\n",
              " (0.7113494873046875, 'broccolini'),\n",
              " (0.7106742262840271, 'leeks'),\n",
              " (0.7096290588378906, 'artichokes'),\n",
              " (0.7028921842575073, 'asparagas'),\n",
              " (0.6759673953056335, 'kohlrabi'),\n",
              " (0.6757089495658875, 'radishes'),\n",
              " (0.6669561862945557, 'spinach')]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "word = 'asparagus'\n",
        "\n",
        "ft_model.get_nearest_neighbors(word)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5dCaN3Dey3k"
      },
      "source": [
        "The first search takes additional time because the model is doing some sort of indexing in the embedding space. fastText uses a tool called FAISS to speed up the search in the embedding space (https://github.com/facebookresearch/faiss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8t5WUH-fJSQ"
      },
      "source": [
        "We can also solve analogies directly, without doing the computations by hand"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXrLJK8jfJbN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7afa2e7-c8df-4d00-8685-2338951d5eb7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.6729540228843689, 'kings'),\n",
              " (0.6174856424331665, 'king-'),\n",
              " (0.6076122522354126, 'king.'),\n",
              " (0.5779222249984741, 'King'),\n",
              " (0.5720189213752747, 'king.The'),\n",
              " (0.5601366758346558, 'kingly'),\n",
              " (0.5598397254943848, 'prince'),\n",
              " (0.5453356504440308, 'king.But'),\n",
              " (0.5429127812385559, 'lord'),\n",
              " (0.5420817136764526, '-king')]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "ft_model.get_analogies(\"man\", \"woman\", \"king\")\n",
        "# ft_model.get_analogies(\"psx\", \"sony\", \"nintendo\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAEZQAPNmjTv"
      },
      "source": [
        "Note that we are dealing with a model using also subword n-grams, so we can get the representation and the similarity even of out of vocabulary words\n",
        "\n",
        "For example we can search for the word **confuzzling** (which is an actual real fake word https://en.wiktionary.org/wiki/confuzzling):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WIkjsmJvn-Ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ff2620f-4fc3-48e9-dfe3-995adf655b1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is the word \"confuzzling\" in the fastText model vocabulary? False\n",
            "0.613641083240509: confuzzled\n",
            "0.550931990146637: Confuzzled\n",
            "0.4055270850658417: confuddled\n",
            "0.3816613256931305: confusing\n",
            "0.36328595876693726: confused\n",
            "0.36032891273498535: nondescriptive\n",
            "0.359388530254364: Wikipedia-Page-Suzannah-B-Troy-6-yrs-after-Misogynist-Cyber-Vandalism-Censorship-via-Deletion-on-a-page-about-Censorship-Wikipedia-Agrees-to-retur\n",
            "0.3525550067424774: muddly\n",
            "0.3524904251098633: official-like\n",
            "0.3516576588153839: unflattering.Coordinating\n"
          ]
        }
      ],
      "source": [
        "word = \"confuzzling\"\n",
        "print(f'Is the word \"{word}\" in the fastText model vocabulary? {word in ft_model}')\n",
        "for s, w in ft_model.get_nearest_neighbors(word):\n",
        "    print(f'{s}: {w}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2pV3BOHoAn4"
      },
      "source": [
        "This is why character n-grams are so important"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CiyFm3Oey3l"
      },
      "source": [
        "We can also encode a sentence (sequence of tokens) into a single vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpkXDCiEey3m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "661a7b73-e949-46cb-aa70-701045203533"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 9.72567871e-03, -1.81693081e-02,  1.98467262e-02,  3.74992117e-02,\n",
              "       -3.59138474e-02, -4.57771569e-02, -2.72532683e-02,  1.52418101e-02,\n",
              "        3.52445617e-02, -7.53624178e-03,  9.12996754e-03, -2.10552160e-02,\n",
              "        1.56272377e-03, -9.82039783e-05, -8.77684914e-03,  3.65382321e-02,\n",
              "        3.64734158e-02, -7.05009839e-03, -2.33118087e-02,  6.08711829e-03,\n",
              "       -1.99545734e-02,  1.54522238e-02,  6.07244065e-03, -8.34608357e-03,\n",
              "       -3.15462463e-02, -9.89805069e-03, -5.55238919e-04, -6.88232016e-03,\n",
              "       -1.15120355e-02,  1.13332726e-01,  2.06005611e-02, -1.42829418e-02,\n",
              "       -4.10122750e-03, -1.72664113e-02,  3.63585819e-03, -1.34615647e-02,\n",
              "       -4.80954209e-03,  4.18015793e-02, -8.03579669e-03, -5.55655640e-03,\n",
              "       -3.50303599e-03,  5.23055904e-03, -2.29117647e-02,  2.92630084e-02,\n",
              "        2.04842985e-02,  3.14234160e-02,  2.69671367e-03,  4.90053743e-02,\n",
              "        1.12765245e-02,  4.62619215e-03,  5.81054529e-03, -1.93861313e-02,\n",
              "        2.83782464e-03, -1.67906247e-02, -2.73843724e-02, -1.90940611e-02,\n",
              "       -2.87314001e-02, -2.75015947e-03, -6.57397807e-02, -6.99969940e-03,\n",
              "        1.24857184e-02, -8.20487388e-04, -1.48562761e-02, -2.38044374e-02,\n",
              "       -1.55957444e-02,  6.65766560e-03,  1.01082725e-02, -2.63807271e-02,\n",
              "        5.37982397e-03, -1.97686311e-02, -1.71130747e-02, -1.01001766e-02,\n",
              "       -1.09787043e-02, -1.05317784e-02, -9.84023418e-03, -8.84000864e-03,\n",
              "        2.20294278e-02,  1.01807080e-02, -2.01867130e-02, -1.07014319e-02,\n",
              "       -2.30140449e-03, -1.70639548e-02, -6.14872994e-03,  3.77793796e-02,\n",
              "       -1.51983332e-02,  8.82430526e-04,  1.63081381e-02,  3.15420181e-02,\n",
              "        3.46342996e-02, -2.07642070e-03, -1.01455227e-02, -2.21963469e-02,\n",
              "        1.20085992e-01, -2.47170683e-02, -3.93651379e-03,  1.47843389e-02,\n",
              "       -2.19641663e-02,  3.33386399e-02,  6.30210200e-03, -5.31568774e-04,\n",
              "        9.85516049e-03,  1.57738347e-02,  2.45013870e-02, -5.04032895e-02,\n",
              "       -2.86772917e-03,  3.74312233e-03,  5.90666989e-03, -1.19731538e-02,\n",
              "       -9.51060839e-03,  3.18147354e-02, -4.23025386e-03, -2.50816215e-02,\n",
              "       -4.44951048e-03,  5.48362173e-02, -5.97885251e-03,  3.35490418e-04,\n",
              "        5.40257385e-03,  1.93157159e-02,  9.49823856e-03,  9.22990963e-03,\n",
              "       -6.44654315e-03,  1.84089541e-02,  6.97864406e-03, -9.98760853e-03,\n",
              "        2.60523483e-02,  3.91055793e-02, -1.44942291e-02, -3.06311846e-02,\n",
              "       -1.64818224e-02,  2.83545423e-02,  6.74407184e-03, -3.35399993e-02,\n",
              "        4.63601090e-02,  1.43400459e-02,  1.51103102e-02, -3.57168838e-02,\n",
              "       -7.21709505e-02,  9.89099871e-03,  1.72942702e-04,  1.05020022e-02,\n",
              "       -2.54397653e-02, -2.65723094e-03,  7.78966863e-03,  3.41638178e-03,\n",
              "        2.90719923e-02,  2.88213808e-02, -2.04293147e-01, -7.63232820e-03,\n",
              "        4.07393230e-03,  2.32063141e-03, -5.25560267e-02, -2.20788294e-03,\n",
              "        1.10511016e-02,  3.85448784e-02, -7.09905615e-03, -1.07400753e-02,\n",
              "        6.98973909e-02,  9.88921523e-03,  1.12778405e-02,  6.80889981e-03,\n",
              "       -4.44709882e-03,  1.29796355e-03, -1.72076363e-03, -5.56946965e-03,\n",
              "        5.87231293e-03,  6.33573765e-03,  2.31747981e-02, -7.90966395e-03,\n",
              "        1.42229358e-02,  1.28066996e-02,  6.79592090e-03,  2.46544043e-03,\n",
              "       -1.16840629e-02,  6.73506968e-03,  1.11606503e-02, -2.94231921e-02,\n",
              "       -4.80693625e-03, -3.77772190e-02,  2.07332522e-02, -1.08723072e-02,\n",
              "        1.20459739e-02,  2.76545398e-02, -7.18570314e-03,  2.37664431e-02,\n",
              "        1.52243748e-02,  1.62549820e-02, -5.45680337e-03, -1.56360455e-02,\n",
              "        1.35150431e-02, -1.02946321e-02, -3.60844545e-02, -5.81913395e-03,\n",
              "       -2.99452688e-04, -1.34269800e-02, -1.33235017e-02,  4.67933854e-03,\n",
              "       -5.23591042e-03, -7.61942146e-03,  1.55100925e-02,  4.34672050e-02,\n",
              "       -3.93452123e-02,  7.63231665e-02, -5.74396225e-03, -2.23684981e-02,\n",
              "       -9.29937419e-03,  1.39698514e-03, -2.73167957e-02, -3.16865183e-02,\n",
              "        9.01725609e-03, -1.52197666e-02,  2.87998165e-03, -6.78938907e-03,\n",
              "       -1.75043494e-02,  8.25327064e-04,  5.83430799e-03, -1.03405640e-02,\n",
              "        1.68033578e-02,  1.82143655e-02,  2.17762217e-02, -3.85117112e-03,\n",
              "        1.55988140e-02,  3.93333882e-02, -1.15634808e-02,  1.36978207e-02,\n",
              "       -1.20003102e-02, -3.80420797e-02,  1.70185268e-02, -1.69083364e-02,\n",
              "       -4.47914330e-03,  1.10276509e-03, -6.27888803e-05,  5.13450429e-03,\n",
              "       -2.36676801e-02,  1.75183604e-03, -5.80153009e-03, -4.86875996e-02,\n",
              "       -2.43026740e-03, -5.56256901e-03,  1.50256902e-02, -9.55843367e-03,\n",
              "        2.34674127e-03,  1.41580636e-02, -7.86390621e-03, -7.69271106e-02,\n",
              "        2.54464388e-01, -1.19995847e-02, -3.09936162e-02,  2.66964808e-02,\n",
              "        1.56647675e-02, -5.45657892e-03,  3.70361917e-02, -1.24057243e-03,\n",
              "       -1.31606916e-02, -3.42799649e-02, -3.24210990e-03, -7.40021467e-03,\n",
              "       -3.67991813e-03, -2.00018543e-03,  1.92347188e-02,  9.79715493e-03,\n",
              "        1.03291485e-03,  3.97863425e-02,  1.01542631e-02,  5.11851441e-03,\n",
              "       -1.80702619e-02, -4.18641046e-03,  1.49878440e-02,  5.19764423e-03,\n",
              "        9.14397370e-03, -6.96600154e-02, -7.67690083e-03, -3.66979875e-02,\n",
              "       -2.45904680e-02,  3.70250712e-03,  2.24400274e-02, -2.23757178e-02,\n",
              "        1.79715436e-02, -8.35847482e-03,  5.23335813e-03,  2.31429515e-03,\n",
              "       -1.48976902e-02, -1.14535531e-02, -1.33328527e-01, -2.64611933e-02,\n",
              "        1.99319292e-02, -7.68285769e-04,  9.32648126e-03, -7.84917027e-02,\n",
              "       -1.71542703e-03, -7.22914794e-03,  4.42805514e-02, -8.75132810e-06,\n",
              "       -8.98919031e-02,  9.89831518e-03, -2.02262457e-02, -1.59065821e-03,\n",
              "        2.72551887e-02,  1.09358311e-01, -3.25395651e-02, -3.00224405e-02],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "sent = ft_model.get_sentence_vector(\"Hello, is it me you're looking for? I can see it in your eyes. I can see it in your smile.\")\n",
        "sent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cqf6h0C_ey3m"
      },
      "source": [
        "(Maybe this can be useful to train a classifier for the twitter sentiment analysis...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vpo8CajYey3m"
      },
      "source": [
        "What if we want to train a model on our own (maybe with smaller embeddings)?\n",
        "You can find a quick reference to the API [here](https://fasttext.cc/docs/en/python-module.html)\n",
        "\n",
        "To train a model we need to convert the data set into the appropriate format, a text file containing al the samples we have.\n",
        "We can start from the sentences we have from before"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgg5eGt5ey3m"
      },
      "outputs": [],
      "source": [
        "with open('./data.txt', 'w') as f:\n",
        "    f.write('\\n'.join(sentences))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHufV8W3ey3m"
      },
      "source": [
        "We can even choose whether to use a Skipgram based approach:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xn_KnZEPey3n"
      },
      "outputs": [],
      "source": [
        "ft_skip_model = fasttext.train_unsupervised('data.txt', model='skipgram', dim=30, minCount=5, ws=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUxk7rbOey3n"
      },
      "source": [
        "Or a Continuos Bag-of-Words (CBoW) approach:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXcPqs9fey3n"
      },
      "outputs": [],
      "source": [
        "ft_cbow_model = fasttext.train_unsupervised('data.txt', model='cbow')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RODgaWTJey3n"
      },
      "source": [
        "Try to do the same visualisation we tried before, see how the same words are placed in a downprojection of the representation space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpEV77Ewey3n"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrDKKIASey3n"
      },
      "source": [
        "### Building a word representation from the sub-words\n",
        "\n",
        "How does fastText actually get to the word representation?\n",
        "Can we get a look at how the representation is built?\n",
        "\n",
        "If you want some additional details on what's going on under the hood, please take a look at this link: http://christopher5106.github.io/deep/learning/2020/04/02/fasttext_pretrained_embeddings_subword_word_representations.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smezp0dLey3o"
      },
      "source": [
        "We can use the `get_subwords()` method to get all the character n-grams composing a word and the corresponding IDs.\n",
        "The model we are using was trained with character 5-grams."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fh6Euh1Vey3p"
      },
      "source": [
        "Let's see what happens when we pass a word to out function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-D3plkP_ey3p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c82a4130-d1d1-4f9f-bb4e-28fd8ab1829b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['happiness', '<happ', 'happi', 'appin', 'ppine', 'pines', 'iness', 'ness>']\n",
            "[   5303 3639000 2151425 3043427 3604793 2523952 2457215 2227900]\n"
          ]
        }
      ],
      "source": [
        "word = 'happiness'\n",
        "sub_words, sub_word_ids = ft_model.get_subwords(word)\n",
        "print(sub_words)\n",
        "print(sub_word_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bLw-dW_ey3p"
      },
      "source": [
        "The first array contains the word to encode followed by its character n-grams, the second array contains the indices of the word and its n-grams in the fastText encoding matrix.\n",
        "\n",
        "What happens if we pass a word that's not in the model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1R4PMCFTey3p"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZ4tpb31ey3p"
      },
      "source": [
        "Finally, we can compute the word representation as the average of the embeddings of the word itself and the embeddings of its character n-grams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFbMYPh3geBW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f4e7829-570e-44f2-9146-6716aaf0a288"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2.43761260e-02,  3.08370143e-02, -1.82935037e-02,  1.92747042e-02,\n",
              "        5.24661969e-03, -3.39045264e-02, -1.22417193e-02,  6.79974556e-02,\n",
              "        2.97031924e-02,  1.41781345e-02, -5.99632552e-03,  3.24566700e-02,\n",
              "       -6.19982481e-02,  7.10059237e-03,  3.57817323e-03, -3.29337753e-02,\n",
              "        7.59602641e-04, -1.92011595e-02, -5.47431074e-02,  4.62299399e-03,\n",
              "       -1.46642867e-02,  8.20630416e-02, -1.03985146e-02, -2.70312317e-02,\n",
              "       -3.93761918e-02,  1.33094080e-02, -1.58767700e-02, -5.90743832e-02,\n",
              "        4.97353896e-02,  8.92114043e-02,  5.08440509e-02, -3.04298364e-02,\n",
              "       -3.62707898e-02,  1.76737197e-02, -1.84959592e-03, -2.82385275e-02,\n",
              "        2.00545900e-02,  1.88715346e-02,  5.23229986e-02, -3.57023366e-02,\n",
              "       -5.00665791e-02,  5.56163443e-03, -1.07403509e-02,  5.34310527e-02,\n",
              "       -3.49775925e-02, -1.46959256e-03,  2.75344364e-02, -3.54247838e-02,\n",
              "       -1.98210757e-02, -3.99537161e-02, -4.37548906e-02,  5.29136742e-03,\n",
              "       -6.46033790e-03, -2.11020559e-02, -8.33227783e-02,  3.06888502e-02,\n",
              "        3.89677286e-02, -1.75225213e-02, -6.73726648e-02, -7.35343155e-03,\n",
              "       -3.80792213e-03, -2.38059033e-02, -3.26873139e-02, -2.40203366e-03,\n",
              "       -2.45236009e-02,  1.81855373e-02,  5.21273278e-02,  2.75492258e-02,\n",
              "       -1.23875402e-02,  5.43958023e-02, -8.78447760e-03, -4.58408445e-02,\n",
              "       -2.87884772e-02, -3.45445536e-02, -4.78063934e-02, -5.90667129e-02,\n",
              "       -8.12903866e-02,  3.68469022e-02, -2.17578746e-03,  5.96710388e-03,\n",
              "        2.59693339e-02,  2.98789181e-02, -8.68188916e-04,  2.57422756e-02,\n",
              "       -1.35573503e-02, -6.31085485e-02,  3.43239792e-02, -2.97417939e-02,\n",
              "       -1.43305827e-02,  2.19782125e-02, -7.79741630e-02, -2.77987383e-02,\n",
              "        1.79748256e-02, -1.66316759e-02,  1.82693414e-02,  2.31197011e-02,\n",
              "        3.66869345e-02,  5.49370907e-02, -2.50525121e-02, -3.84743474e-02,\n",
              "        5.41631654e-02, -3.22258379e-03, -1.57271307e-02,  2.82019079e-02,\n",
              "        5.14290482e-03,  3.99415940e-02, -4.22844552e-02, -5.16160727e-02,\n",
              "       -8.51662606e-02,  4.12943214e-02,  2.81122327e-03, -3.88853624e-02,\n",
              "       -4.63203005e-02,  4.30510677e-02, -3.10722515e-02, -6.91417372e-05,\n",
              "       -3.49915810e-02,  1.25323073e-03, -5.44217788e-03,  5.05799353e-02,\n",
              "        8.71812776e-02,  4.74442057e-02, -5.13566881e-02, -1.23618683e-02,\n",
              "        2.93553211e-02,  3.47397812e-02, -2.13506594e-02, -6.47193044e-02,\n",
              "       -5.84755689e-02,  1.21798720e-02, -2.74393223e-02, -1.67746507e-02,\n",
              "        2.65790746e-02,  7.06325192e-03,  3.23037133e-02, -3.11213434e-02,\n",
              "        3.02323718e-02, -7.32418895e-02,  3.88385057e-02, -5.29803447e-02,\n",
              "       -3.25780436e-02, -6.03005243e-03, -2.65895687e-02, -5.89839295e-02,\n",
              "       -3.08223143e-02, -3.63278054e-02, -6.88481629e-02,  1.87926777e-02,\n",
              "        2.44538598e-02, -8.21650214e-03, -1.01965358e-02, -3.44917402e-02,\n",
              "       -7.85811990e-03,  2.68215202e-02,  2.61807721e-02, -4.39158604e-02,\n",
              "        2.77042091e-02, -5.37077598e-02,  4.05189544e-02, -3.51586267e-02,\n",
              "       -8.80582072e-03, -4.20970507e-02, -4.80171293e-05, -1.14688827e-02,\n",
              "       -2.63095498e-02, -4.12876308e-02,  4.64802831e-02, -2.07530870e-03,\n",
              "        7.72867650e-02, -5.59825562e-02, -4.38053533e-02, -3.21695693e-02,\n",
              "       -2.43611056e-02,  2.97143627e-02, -6.67000329e-03, -4.10863608e-02,\n",
              "        3.42117995e-02,  3.25413682e-02, -5.09670712e-02, -3.63938361e-02,\n",
              "       -1.78588368e-02, -4.90688048e-02,  5.54219121e-03, -2.74044257e-02,\n",
              "       -1.07904393e-02,  2.70653442e-02, -2.86887810e-02, -4.93078344e-02,\n",
              "        2.41081752e-02, -6.01483211e-02,  5.01797050e-02,  6.53500408e-02,\n",
              "       -5.82428724e-02,  2.55513340e-02,  3.02193966e-02, -8.90765525e-03,\n",
              "       -3.56865190e-02,  2.61622574e-02, -6.02983637e-03,  3.70613486e-02,\n",
              "        5.66252843e-02,  3.02074943e-03, -2.29285751e-02, -2.99923737e-02,\n",
              "       -2.90422793e-02, -2.93860696e-02, -5.24010137e-02, -4.33018990e-02,\n",
              "        1.38238836e-02,  8.39067400e-02, -1.45187313e-02, -9.14442539e-02,\n",
              "        4.47705388e-03, -3.80011275e-04, -2.76892241e-02,  6.34342339e-03,\n",
              "       -1.60162169e-02, -1.53088942e-02,  1.13351978e-02,  8.92383829e-02,\n",
              "       -3.20932604e-02, -2.25169789e-02,  2.11793836e-02, -3.76144350e-02,\n",
              "       -4.57356572e-02, -4.22400050e-02,  2.88321748e-02, -8.15630518e-03,\n",
              "        4.20552343e-02, -4.62269448e-02,  6.10891916e-03,  4.42727609e-03,\n",
              "        6.90615689e-03,  5.75772151e-02,  3.03004980e-02, -3.02721951e-02,\n",
              "        4.16897573e-02,  3.94802503e-02, -2.33752541e-02, -3.59145068e-02,\n",
              "        4.58222395e-03,  3.69192325e-02, -2.09903605e-02, -5.01421541e-02,\n",
              "        2.97323763e-02, -1.93621032e-02, -1.00074429e-02, -1.96661577e-02,\n",
              "        3.38150859e-02,  5.16679510e-03,  1.01780482e-02,  1.06609957e-02,\n",
              "       -2.20471248e-03, -1.04015935e-02, -4.25644666e-02, -9.29920096e-03,\n",
              "       -5.45251518e-02,  2.20365468e-02, -2.73922570e-02, -4.81523648e-02,\n",
              "        8.41728318e-03, -2.29191408e-02, -1.82414372e-02, -5.17862402e-02,\n",
              "       -5.12596592e-03, -4.68518808e-02,  4.77616228e-02,  6.92860456e-03,\n",
              "       -1.82616636e-02, -8.94955918e-03,  1.70803536e-02,  1.89393274e-02,\n",
              "       -1.25003587e-02,  9.39648785e-03,  8.57291394e-04, -3.97665277e-02,\n",
              "       -3.43222395e-02,  2.91521940e-03,  1.27181131e-02,  4.11672033e-02,\n",
              "       -2.29718927e-02,  3.50051671e-02, -3.43964882e-02, -8.41140188e-03,\n",
              "        9.29306746e-02,  3.89201916e-04,  8.75943340e-03,  1.29394569e-02,\n",
              "        4.74389717e-02, -7.70587474e-02,  1.53834000e-02,  3.00232023e-02,\n",
              "       -1.56497527e-02,  2.17576511e-02,  4.28436473e-02, -4.29545157e-02,\n",
              "        4.36081812e-02,  6.95104897e-02, -3.45086530e-02,  3.36973779e-02],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "word = 'happiness'\n",
        "sub_words, sub_word_ids = ft_model.get_subwords(word)\n",
        "\n",
        "embedding = np.mean([ft_model.get_input_vector(idx) for idx in sub_word_ids], axis=0)\n",
        "\n",
        "embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XgjH0qJey3p"
      },
      "source": [
        "Let's compare the embedding we retrieved with the original one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZM5G1UFey3q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d09d49c4-b5a9-4501-9895-5ac753470a34"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "np.sum((embedding - ft_model[word]) ** 2) ** 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YuQ94IvEhiXn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "6PifwcbdWqKz"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}