{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MoeinDSP/NLP_Projects/blob/main/Classification%20with%20Transformers%20and%20Semantic%20Search/08_Semantic_Search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3302ac4-3ac7-4e3a-9bd7-c88a5565179a",
      "metadata": {
        "id": "e3302ac4-3ac7-4e3a-9bd7-c88a5565179a"
      },
      "source": [
        "# Semantic Search\n",
        "\n",
        "This notebook shows hot to make use of pre-trained Transformer models for document embeddings.\n",
        "These models are trained using *supervised* or *unsupervised* approaches to encode text at sentence-level, paragraph-level or even entire document-level.\n",
        "They can be applied to many different tasks\n",
        "- Semantic similarity\n",
        "- Paraphrase detection\n",
        "- Natural Langage Inference\n",
        "- Question Answering\n",
        "- Information retreival\n",
        "- Clustering\n",
        "\n",
        "Most of the material is based on the tuorial and examples on [Sentence Transformers](https://www.sbert.net/docs/)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3853140",
      "metadata": {
        "id": "b3853140"
      },
      "source": [
        "**Optional for Colab users**\n",
        "\n",
        "Before starting, we can set up the connection with the Google Dive storage, to keep there our documents.\n",
        "Just execute the following passages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f607da3a",
      "metadata": {
        "id": "f607da3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ec95791-0c7c-42fa-c9dd-70c100f545c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d37090fe",
      "metadata": {
        "id": "d37090fe"
      },
      "source": [
        "Make sure that the variable path contains the correct sequence of folders separate by a `'/'` to get to your lecture files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7aca7284",
      "metadata": {
        "id": "7aca7284",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "51442ccb-5885-4e17-df5b-303e056f305e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Practical_08__Semantic-Search'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "path = '/content/drive/MyDrive/Practical_08__Semantic-Search'\n",
        "\n",
        "os.chdir(f'{path}')\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93f37bfa-3a06-4cf0-9c51-ea39d7874703",
      "metadata": {
        "id": "93f37bfa-3a06-4cf0-9c51-ea39d7874703"
      },
      "source": [
        "## Prepare environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pPwP85MlYxV7",
      "metadata": {
        "id": "pPwP85MlYxV7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af28498a-9e1d-4ba7-eb79-18d294dac131"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.51.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.14.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.30.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.13.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
            "Downloading sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.7/345.7 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m101.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence-transformers\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: sentence-transformers\n",
            "    Found existing installation: sentence-transformers 3.4.1\n",
            "    Uninstalling sentence-transformers-3.4.1:\n",
            "      Successfully uninstalled sentence-transformers-3.4.1\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 sentence-transformers-4.1.0\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Collecting hnswlib\n",
            "  Downloading hnswlib-0.8.0.tar.gz (36 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from hnswlib) (2.0.2)\n",
            "Building wheels for collected packages: hnswlib\n",
            "  Building wheel for hnswlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hnswlib: filename=hnswlib-0.8.0-cp311-cp311-linux_x86_64.whl size=2389207 sha256=5fa8253d6c9ccb65d796086d67c551da1e025bef4016d30e80f9d7c6da637bfa\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/4e/27/39aebca9958719776e36fada290845a7ef10f053ad70e22ceb\n",
            "Successfully built hnswlib\n",
            "Installing collected packages: hnswlib\n",
            "Successfully installed hnswlib-0.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U sentence-transformers\n",
        "!pip install datasets\n",
        "!pip install hnswlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Z8DkyIdKZsBV",
      "metadata": {
        "id": "Z8DkyIdKZsBV"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3c0629c-1820-4b1f-a4ee-1597e459f3bd",
      "metadata": {
        "id": "a3c0629c-1820-4b1f-a4ee-1597e459f3bd"
      },
      "source": [
        "## Sentence transformer models\n",
        "\n",
        "Today we are going to use an extension of the [Transformers library](https://huggingface.co/docs/transformers/index) designed for sentence level analysis (and more): [Sentece Transfromers](https://www.sbert.net) (origianlly known as SenteceBERT or SBERT)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "L1fbWzivlZ_b",
      "metadata": {
        "id": "L1fbWzivlZ_b"
      },
      "source": [
        "First of all we need to import the sentence transformer and some utilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87afda88-dc16-4f73-b48e-95458a7ff69a",
      "metadata": {
        "id": "87afda88-dc16-4f73-b48e-95458a7ff69a"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6dde3423-64dd-4361-a064-45f8005411a3",
      "metadata": {
        "id": "6dde3423-64dd-4361-a064-45f8005411a3"
      },
      "source": [
        "### Embedding text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OUSIilKglfLt",
      "metadata": {
        "id": "OUSIilKglfLt"
      },
      "source": [
        "Let's create an instance of sentence embedding model based on BERT.\n",
        "Here you have a list of the available pre-trained models for sentence embedding https://www.sbert.net/docs/pretrained_models.html."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rwCx3iQCY-93",
      "metadata": {
        "id": "rwCx3iQCY-93"
      },
      "outputs": [],
      "source": [
        "model = SentenceTransformer('all-mpnet-base-v2')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "w9bEavhQlzay",
      "metadata": {
        "id": "w9bEavhQlzay"
      },
      "source": [
        "Let's define a corpus of a few sentences to try out the embedding model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9bffafc0-4bbc-4b61-b283-0aac9b383e65",
      "metadata": {
        "id": "9bffafc0-4bbc-4b61-b283-0aac9b383e65"
      },
      "outputs": [],
      "source": [
        "corpus = [\n",
        "    'A man is eating food.',\n",
        "    'A man is eating a piece of bread.',\n",
        "    'The girl is carrying a baby.',\n",
        "    'A man is riding a horse.',\n",
        "    'A woman is playing violin.',\n",
        "    'Two men pushed carts through the woods.',\n",
        "    'A man is riding a white horse on an enclosed ground.',\n",
        "    'A monkey is playing drums.',\n",
        "    'A cheetah is running behind its prey.'\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "u2441m3Ll9xQ",
      "metadata": {
        "id": "u2441m3Ll9xQ"
      },
      "source": [
        "We can embed the text in batches with the `encode()` method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2c39e70-efb6-41c8-b659-193384d3a8ad",
      "metadata": {
        "id": "a2c39e70-efb6-41c8-b659-193384d3a8ad"
      },
      "outputs": [],
      "source": [
        "corpus_embeddings = model.encode(corpus, convert_to_tensor=True)\n",
        "corpus_embeddings.size()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KwcFdAxbmFYz",
      "metadata": {
        "id": "KwcFdAxbmFYz"
      },
      "source": [
        "Let's give a look at one of the embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jEmLNvr6mJGS",
      "metadata": {
        "id": "jEmLNvr6mJGS"
      },
      "outputs": [],
      "source": [
        "corpus_embeddings[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63b2049d-7ad6-4c4c-b04f-c4fd1f51cfb7",
      "metadata": {
        "id": "63b2049d-7ad6-4c4c-b04f-c4fd1f51cfb7"
      },
      "source": [
        "### Cosine similarity between embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86ec6492-0f50-47b3-9949-e6a3968c5087",
      "metadata": {
        "id": "86ec6492-0f50-47b3-9949-e6a3968c5087"
      },
      "source": [
        "We can compute the similarity of embedding pairs in our corpus. We first create a matrix by stacking vertically (torch.vstack()) the similarity (util.cos_sim()) between each embedding and all the others."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5c16f18-ed0b-42bb-923f-e4eff5448c95",
      "metadata": {
        "id": "e5c16f18-ed0b-42bb-923f-e4eff5448c95"
      },
      "outputs": [],
      "source": [
        "similarity_matrix = torch.vstack(\n",
        "    [util.cos_sim(embedding, corpus_embeddings)[0] for embedding in corpus_embeddings]\n",
        ")\n",
        "similarity_matrix.size()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jKU_zdq_k8FK",
      "metadata": {
        "id": "jKU_zdq_k8FK"
      },
      "source": [
        "And show the similarities in a matrix.\n",
        "Here the brighter the colour the higher the similarity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "la-2LWeZZh2B",
      "metadata": {
        "id": "la-2LWeZZh2B"
      },
      "outputs": [],
      "source": [
        "plt.matshow(similarity_matrix.cpu().numpy())\n",
        "plt.xlabel('Sentence index')\n",
        "plt.ylabel('Sentence index')\n",
        "plt.colorbar()\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GoYlKVp6xCCt",
      "metadata": {
        "id": "GoYlKVp6xCCt"
      },
      "source": [
        "What do you think of the results? These are the sentences we used"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jJYPYwWHw-US",
      "metadata": {
        "id": "jJYPYwWHw-US"
      },
      "outputs": [],
      "source": [
        "for idx, sentence in enumerate(corpus):\n",
        "    print(f\"{idx}:\\t\\\"{sentence}\\\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0tNslTNtlPzZ",
      "metadata": {
        "id": "0tNslTNtlPzZ"
      },
      "source": [
        "On the diagonal we have a perfect match since we are computing the similarity between a piece of text and itself."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97a4e659-4596-4e09-8a39-7408db102043",
      "metadata": {
        "id": "97a4e659-4596-4e09-8a39-7408db102043"
      },
      "source": [
        "### Visualising the embedding space"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4LhJGhsjmOV7",
      "metadata": {
        "id": "4LhJGhsjmOV7"
      },
      "source": [
        "Ok, looking at lists of numbers is not very useful.\n",
        "We can try to do some visualisation here.\n",
        "\n",
        "Let's start by showing the embeddings we computed early."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "L6R40mgPmYlR",
      "metadata": {
        "id": "L6R40mgPmYlR"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(10, 8))\n",
        "plt.matshow(corpus_embeddings.cpu().numpy(), aspect='auto')\n",
        "plt.xlabel('Feature');\n",
        "plt.ylabel('Sentence');"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HK0hL-PymY0x",
      "metadata": {
        "id": "HK0hL-PymY0x"
      },
      "source": [
        "Yeah, that's not very informative.\n",
        "\n",
        "Now let's load a bigger data set so we can learn one of those fancy down-projection like TSNE to visualise the embeddings in a 2D or 3D space.\n",
        "We can use the sentences in the [SNLI](https://arxiv.org/abs/1508.05326) data set, it is avaialble through the HuggingFace Datasets package (https://huggingface.co/datasets/snli)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zT4IZm71moZM",
      "metadata": {
        "id": "zT4IZm71moZM"
      },
      "outputs": [],
      "source": [
        "import datasets\n",
        "\n",
        "snli = datasets.load_dataset('snli', split='train')\n",
        "snli[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RExQs6PGolrI",
      "metadata": {
        "id": "RExQs6PGolrI"
      },
      "source": [
        "This data set is used for a task called \"Natural Language Inference\" (NLI), the task is to recognise the relationship between two sentences:\n",
        "- Neutral\n",
        "- Entailment\n",
        "- Contradiction\n",
        "\n",
        "We are just interested in the sentences, so we can drop the structure of the data set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YCcxnt2epgJE",
      "metadata": {
        "id": "YCcxnt2epgJE"
      },
      "outputs": [],
      "source": [
        "sentences = list(set(sample[key] for sample in snli for key in ['premise', 'hypothesis']))\n",
        "len(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences[0]"
      ],
      "metadata": {
        "id": "9R4IheDo6Huf"
      },
      "id": "9R4IheDo6Huf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "7yVulbH3qi5h",
      "metadata": {
        "id": "7yVulbH3qi5h"
      },
      "source": [
        "We can embed a subset of these sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6wVK4yiqiF4",
      "metadata": {
        "id": "f6wVK4yiqiF4"
      },
      "outputs": [],
      "source": [
        "corpus_embeddings = model.encode(sentences[::300], convert_to_tensor=True).cpu().numpy()\n",
        "corpus_embeddings.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YRlNSZ9ZpzBT",
      "metadata": {
        "id": "YRlNSZ9ZpzBT"
      },
      "source": [
        "Now let's use TSNE to learn a low dimensional representation..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ECI8RufpzNT",
      "metadata": {
        "id": "6ECI8RufpzNT"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "tsne = TSNE(n_components=3, n_iter=500)\n",
        "tsne_embedding = tsne.fit_transform(corpus_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UvmRDoxup91w",
      "metadata": {
        "id": "UvmRDoxup91w"
      },
      "source": [
        "... and plot it in three dimensions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-HB1tvSLqTQp",
      "metadata": {
        "id": "-HB1tvSLqTQp"
      },
      "outputs": [],
      "source": [
        "!pip install plotly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pTgWzUh2p9Fs",
      "metadata": {
        "id": "pTgWzUh2p9Fs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import plotly.express as px\n",
        "\n",
        "x, y, z = np.transpose(tsne_embedding)\n",
        "\n",
        "fig = px.scatter_3d(x=x, y=y, z=z)\n",
        "fig.update_traces(marker=dict(size=3,line=dict(width=2)))\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MkFJZWi50nkF",
      "metadata": {
        "id": "MkFJZWi50nkF"
      },
      "source": [
        "Now let's select randomly a few sentences to display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TUC8hTv24S41",
      "metadata": {
        "id": "TUC8hTv24S41"
      },
      "outputs": [],
      "source": [
        "# Select ranomly the sentences\n",
        "embed_idxs = np.random.choice(np.arange(len(tsne_embedding)), 10)\n",
        "sent_idxs = np.arange(0, len(sentences), 300)[embed_idxs]\n",
        "\n",
        "# Plot the selected sentences\n",
        "fig = px.scatter_3d(x=x[embed_idxs], y=y[embed_idxs], z=z[embed_idxs], text=embed_idxs)\n",
        "fig.update_traces(marker=dict(size=3,line=dict(width=2)))\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "X2RjnDcL3O9g",
      "metadata": {
        "id": "X2RjnDcL3O9g"
      },
      "source": [
        "Let's give a look at the text of the selected sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jUf_QX-H3PMs",
      "metadata": {
        "id": "jUf_QX-H3PMs"
      },
      "outputs": [],
      "source": [
        "for e_idx, s_idx in zip(embed_idxs, sent_idxs):\n",
        "    print(f\"{e_idx:6d}:\\t\\\"{sentences[s_idx]}\\\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53ae9259-929d-45ad-8ce3-255fb94ebe79",
      "metadata": {
        "id": "53ae9259-929d-45ad-8ce3-255fb94ebe79"
      },
      "source": [
        "### Multi-lingual models\n",
        "\n",
        "We have models working with multiple languages, this means we can compute also cross-language similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OS8a8E8TbynR",
      "metadata": {
        "id": "OS8a8E8TbynR"
      },
      "outputs": [],
      "source": [
        "multilingual_model = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CpgwzusQiYFb",
      "metadata": {
        "id": "CpgwzusQiYFb"
      },
      "source": [
        "Let's pick a sentence and translate it in multiple languages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ou_VhMqwby6h",
      "metadata": {
        "id": "Ou_VhMqwby6h"
      },
      "outputs": [],
      "source": [
        "# multilingual_corpus = [\n",
        "#     \"Where is the library?\",\n",
        "#     \"¿Donde está la biblioteca?\",\n",
        "#     \"Dov'è la biblioteca?\"\n",
        "# ]\n",
        "multilingual_corpus = [\n",
        "    \"Io sono Nicolò Brunello e sono del Veneto, tu chi sei?\",\n",
        "    \"I am Mark Carman and I'm from Australia... Mate!\",\n",
        "    \"Sono Mark Carman e vengo dall'Australia... Amico!\",\n",
        "    \"Soy Mark Carman y soy de Australia... Compañero!\",\n",
        "    \"Ich bin Mark Carman und ich komme aus Australien... Kumpel!\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5IQNQd0PikeN",
      "metadata": {
        "id": "5IQNQd0PikeN"
      },
      "source": [
        "Now let's compute the similarity between translation pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hhrXPDE2ciZr",
      "metadata": {
        "id": "hhrXPDE2ciZr"
      },
      "outputs": [],
      "source": [
        "for idx, s1 in enumerate(multilingual_corpus):\n",
        "    for s2 in multilingual_corpus[idx + 1:]:\n",
        "        s1_embeddings = model.encode(s1, convert_to_tensor=True)\n",
        "        s2_embeddings = model.encode(s2, convert_to_tensor=True)\n",
        "\n",
        "        print(f\"Sentence 1: \\\"{s1}\\\"\")\n",
        "        print(f\"Sentence 2: \\\"{s2}\\\"\")\n",
        "        print(\"---------------------------------------------------------------\")\n",
        "        print(f\"Cosine similarity: {util.cos_sim(s1_embeddings, s2_embeddings)[0].item():.2f}\")\n",
        "        print(\"\\n\\n\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UxXljoPC57_E",
      "metadata": {
        "id": "UxXljoPC57_E"
      },
      "source": [
        "## Semantic search\n",
        "\n",
        "Contextual embedding models allow for semantic search.\n",
        "\n",
        "We can use the cosine similarity between the embeddings of documents and queries to search through a collection of documents exploting semantics (meaning) rather than syntax.\n",
        "We can compute the cosine similarity between the embedding of a document and the embedding of a query to compute their matching score.\n",
        "\n",
        "Alternatively, instead of encoding separately the document and the query, we can learn a model that works on both at the same time and predicts directly the matching score."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d654093-19e4-40ce-afb8-02bf9e574590",
      "metadata": {
        "id": "1d654093-19e4-40ce-afb8-02bf9e574590"
      },
      "source": [
        "### Computing document-query similarity\n",
        "\n",
        "We can do semantic seach using the cosine similarity between embeddings or we can learn a model predicting directly the matching probability."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "iP7m4gOJ6hTM",
      "metadata": {
        "id": "iP7m4gOJ6hTM"
      },
      "source": [
        "#### Cosine similarity search\n",
        "\n",
        "We can use an encoder model like BERT to extract the emebeddings of two sentences seprately and compare them though cosine similarity.\n",
        "\n",
        "![BERT_visual_bienc.png](data:image/png;base64,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)\n",
        "\n",
        "Note that since sentences are encoded separately one from the other, we can pre-compute the embeddings forming some sort of indexed data base and exploit the pre computed embeddings for a later search."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9HEba_wDsb3a",
      "metadata": {
        "id": "9HEba_wDsb3a"
      },
      "source": [
        "Let's get back at the examples sentence from before and embed them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abbb2973-a892-445e-a1ef-af047cd2fbda",
      "metadata": {
        "id": "abbb2973-a892-445e-a1ef-af047cd2fbda"
      },
      "outputs": [],
      "source": [
        "docs = [\n",
        "    'A man is eating food.',\n",
        "    'A man is eating a piece of bread.',\n",
        "    'The girl is carrying a baby.',\n",
        "    'A man is riding a horse.',\n",
        "    'A woman is playing violin.',\n",
        "    'Two men pushed carts through the woods.',\n",
        "    'A man is riding a white horse on an enclosed ground.',\n",
        "    'A monkey is playing drums.',\n",
        "    'A cheetah is running behind its prey.'\n",
        "]\n",
        "docs_embeddings = model.encode(docs, convert_to_tensor=True, device='cuda')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wV_q6PUItHbM",
      "metadata": {
        "id": "wV_q6PUItHbM"
      },
      "source": [
        "Now we can create a set of queries for semantic similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cfc5ffa-0429-4de9-86a9-c5e217f8d05c",
      "metadata": {
        "id": "5cfc5ffa-0429-4de9-86a9-c5e217f8d05c"
      },
      "outputs": [],
      "source": [
        "queries = [\n",
        "    'A man is eating pasta.',\n",
        "    'Someone in a gorilla costume is playing a set of drums.',\n",
        "    'A cheetah chases prey on across a field.'\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad0c8c7b-10cd-415f-a5e2-15d54d347fe5",
      "metadata": {
        "id": "ad0c8c7b-10cd-415f-a5e2-15d54d347fe5"
      },
      "source": [
        "Let's find the closest 5 sentences of the corpus for each query sentence based on cosine similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f2867da-88fc-4b1b-bb1e-5cdcbcb5e170",
      "metadata": {
        "id": "3f2867da-88fc-4b1b-bb1e-5cdcbcb5e170"
      },
      "outputs": [],
      "source": [
        "# Let's set the maximum number of matches to retrieve\n",
        "top_k = min(5, len(corpus))\n",
        "# Iterate over queries\n",
        "for query in queries:\n",
        "    # Embed query\n",
        "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
        "    # Use cosine-similarity and torch.topk to find the highest 5 scores\n",
        "    cos_scores = util.cos_sim(query_embedding, docs_embeddings)[0]\n",
        "    top_results = torch.topk(cos_scores, k=top_k)\n",
        "    # Print the result\n",
        "    print(f\"Query: \\\"{query}\\\"\")\n",
        "    print(\"Top 5 most similar sentences in corpus:\")\n",
        "    print(\"---------------------------------------\")\n",
        "    for score, idx in zip(top_results[0], top_results[1]):\n",
        "        print(f\"Score: {score:.2f} - Document: \\\"{corpus[idx]}\\\"\")\n",
        "    print(\"\\n\\n\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ziZPdt4UvfAI",
      "metadata": {
        "id": "ziZPdt4UvfAI"
      },
      "source": [
        "Alternatively, we can use the built in function for semantic search that computes automatically all the query-document similarity pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WTk53OG8vfMp",
      "metadata": {
        "id": "WTk53OG8vfMp"
      },
      "outputs": [],
      "source": [
        "query_embeddings = model.encode(queries, convert_to_tensor=True)\n",
        "\n",
        "util.semantic_search(query_embeddings, docs_embeddings, score_function=util.cos_sim)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RHcJVNNEszdf",
      "metadata": {
        "id": "RHcJVNNEszdf"
      },
      "source": [
        "#### Speed up cosine similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71af4a5d-c00d-4f9b-970e-fe016b1d356c",
      "metadata": {
        "id": "71af4a5d-c00d-4f9b-970e-fe016b1d356c"
      },
      "source": [
        "We can speed-up the process by pre-nomalising the embeddings and compute directly the dot-product instead of cosine similarity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "219db30f-f14a-4157-a88a-402995ab8a85",
      "metadata": {
        "id": "219db30f-f14a-4157-a88a-402995ab8a85"
      },
      "outputs": [],
      "source": [
        "normlaised_docs_embeddings = util.normalize_embeddings(model.encode(docs, convert_to_tensor=True))\n",
        "normalised_query_embeddings = util.normalize_embeddings(model.encode(queries, convert_to_tensor=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43f329dd-aa9b-4ee3-8a19-c104f6814892",
      "metadata": {
        "id": "43f329dd-aa9b-4ee3-8a19-c104f6814892"
      },
      "outputs": [],
      "source": [
        "hits = util.semantic_search(normalised_query_embeddings, normlaised_docs_embeddings, score_function=util.dot_score)\n",
        "hits"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22b91088-565b-4bf3-805c-a917ac6969b8",
      "metadata": {
        "id": "22b91088-565b-4bf3-805c-a917ac6969b8"
      },
      "source": [
        "#### Cross-encoder\n",
        "\n",
        "Cross encoder models work by encoding together the sentences in a pair or a document-query pair.\n",
        "\n",
        "![BERT_visual_xenc.png](data:image/png;base64,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)\n",
        "\n",
        "Differently from the previous models that can be trained either with a supervised approach or with an unsupervised approach, in this case they only work if trained for some supervised target like classification (e.g., paraphrase detection) or regression (e.g., sentence similarity)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Vkav6gth97yQ",
      "metadata": {
        "id": "Vkav6gth97yQ"
      },
      "source": [
        "Let's load a cross-encoder model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RVcPzZiL98BI",
      "metadata": {
        "id": "RVcPzZiL98BI"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import CrossEncoder\n",
        "\n",
        "model = CrossEncoder('cross-encoder/stsb-distilroberta-base')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sQ2ABi3B98Us",
      "metadata": {
        "id": "sQ2ABi3B98Us"
      },
      "source": [
        "Let's use this model to compute the similarity between the queries and the documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BFZyvK1E98f_",
      "metadata": {
        "id": "BFZyvK1E98f_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Iterate over queries\n",
        "for query in queries:\n",
        "    # Prepare model inputs\n",
        "    model_inputs = [[query, doc] for doc in docs]\n",
        "    # Predict similarity score\n",
        "    scores = model.predict(model_inputs)\n",
        "    # Print the result\n",
        "    print(f\"Query: \\\"{query}\\\"\")\n",
        "    print(\"---------------------------------------\")\n",
        "    for idx in np.argsort(-scores):\n",
        "        print(f\"Score: {scores[idx]:.4f} - Document: \\\"{corpus[idx]}\\\"\")\n",
        "    print(\"\\n\\n\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VBcWYl7r6xlN",
      "metadata": {
        "id": "VBcWYl7r6xlN"
      },
      "source": [
        "### Question answering pipeline\n",
        "\n",
        "Ok this is cool, but what can we do when we have a large data set and complex applications like question answering?\n",
        "Let's try out!\n",
        "\n",
        "The following example is based on this one https://github.com/UKPLab/sentence-transformers/blob/master/examples/applications/retrieve_rerank/retrieve_rerank_simple_wikipedia.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sRHrj6HqAZ4V",
      "metadata": {
        "id": "sRHrj6HqAZ4V"
      },
      "source": [
        "Let's start by loading a sentence embedding model and a cross encoder model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Q2Uqvlr8AaEu",
      "metadata": {
        "id": "Q2Uqvlr8AaEu"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer, CrossEncoder, util\n",
        "\n",
        "semb_model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')\n",
        "xenc_model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73d8fd91-bf88-49e5-a624-15e2d0dcff7d",
      "metadata": {
        "id": "73d8fd91-bf88-49e5-a624-15e2d0dcff7d"
      },
      "source": [
        "#### Prepare data\n",
        "\n",
        "We can load a reduced copy of Wikipedia ([Simple Wikipedia](https://simple.wikipedia.org/wiki/Main_Page), which is different from Simple Jack from Tropic Thunder 😬).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7HJxQNkn_Tz_",
      "metadata": {
        "id": "7HJxQNkn_Tz_"
      },
      "source": [
        "Let's start by downloading the data set if it is not avaialble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cB805G0K_P_s",
      "metadata": {
        "id": "cB805G0K_P_s"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "wikipedia_filepath = 'simplewiki-2020-11-01.jsonl.gz'\n",
        "if not os.path.exists(wikipedia_filepath):\n",
        "    util.http_get('http://sbert.net/datasets/simplewiki-2020-11-01.jsonl.gz', wikipedia_filepath)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xf_y12Zl_ZpM",
      "metadata": {
        "id": "xf_y12Zl_ZpM"
      },
      "source": [
        "Now let's load the first paragraph of each document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95OoeI9K_Z29",
      "metadata": {
        "id": "95OoeI9K_Z29"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import gzip\n",
        "\n",
        "passages = []\n",
        "# Open the file with the dump of Simple Wikipedia\n",
        "with gzip.open(wikipedia_filepath, 'rt', encoding='utf8') as f:\n",
        "    # Iterate over the lines\n",
        "    for line in f:\n",
        "        # Parse the document using JSON\n",
        "        data = json.loads(line.strip())\n",
        "        # Add all paragraphs\n",
        "        #passages.extend(data['paragraphs'])\n",
        "        # Only add the first paragraph\n",
        "        passages.append(data['paragraphs'][0])\n",
        "\n",
        "print(f\"Retreived {len(passages)} passages\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ccMuWe7ATfL",
      "metadata": {
        "id": "0ccMuWe7ATfL"
      },
      "source": [
        "Now we can embed the retrieved passaged using the sentence embedding model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rLwe49q4ATsc",
      "metadata": {
        "id": "rLwe49q4ATsc"
      },
      "outputs": [],
      "source": [
        "corpus_embeddings = semb_model.encode(passages, convert_to_tensor=True, show_progress_bar=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1036f0e-f2c9-4a2e-bb73-36bc3d0279a4",
      "metadata": {
        "id": "e1036f0e-f2c9-4a2e-bb73-36bc3d0279a4"
      },
      "source": [
        "#### Approximated Nearest Neighbor search\n",
        "\n",
        "When we use an embedding model with cosine similarity, we can pre-compute the embeddings in our data set and index them to speed-up the search.\n",
        "There are techniques for Approximate Nearest Neighbor (ANN), which use clustering to index the embedding space and speed-up the search process.\n",
        "\n",
        "Note that this is not applicable to cross-encoder models, which encode document and query together.\n",
        "\n",
        "Sentence transformers support different libraries for ANN:\n",
        "- [HNSWLIB](https://github.com/nmslib/hnswlib/)\n",
        "- [Annoy](https://github.com/spotify/annoy)\n",
        "- [FAISS](https://github.com/spotify/annoy)\n",
        "\n",
        "Let's try indexing with **HNSWLIB** (yes yes I know, do or do not, there is not try...)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9vfeR2RMEPbD",
      "metadata": {
        "id": "9vfeR2RMEPbD"
      },
      "source": [
        "Import the HNSWLIB library and create and empty index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AwJjV_wxEOa4",
      "metadata": {
        "id": "AwJjV_wxEOa4"
      },
      "outputs": [],
      "source": [
        "import hnswlib\n",
        "\n",
        "index = hnswlib.Index(space='cosine', dim=corpus_embeddings.size(1))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "I10ItvdQEWBb",
      "metadata": {
        "id": "I10ItvdQEWBb"
      },
      "source": [
        "Now we can index our data. The index we compute can be saved and loaded, so we can check if it is already availabel and load it (this will save time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05SpZx1dExeu",
      "metadata": {
        "id": "05SpZx1dExeu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Define hnswlib index path\n",
        "index_path = \"./hnswlib.index\"\n",
        "\n",
        "# Load index if available\n",
        "if os.path.exists(index_path):\n",
        "    print(\"Loading index...\")\n",
        "    index.load_index(index_path)\n",
        "# Else index data collection\n",
        "else:\n",
        "    # Initialise the index\n",
        "    print(\"Start creating HNSWLIB index\")\n",
        "    index.init_index(max_elements=corpus_embeddings.size(0), ef_construction=400, M=64)\n",
        "    #  Compute the HNSWLIB index (it may take a while)\n",
        "    index.add_items(corpus_embeddings.cpu(), list(range(len(corpus_embeddings))))\n",
        "    # Save the index to a file for future loading\n",
        "    print(\"Saving index to:\", index_path)\n",
        "    index.save_index(index_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "S_M-yqrSFqv2",
      "metadata": {
        "id": "S_M-yqrSFqv2"
      },
      "source": [
        "Is it really faster to search? Let's see.\n",
        "\n",
        "We can create a query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3egoMGPAGZs_",
      "metadata": {
        "id": "3egoMGPAGZs_"
      },
      "outputs": [],
      "source": [
        "query = \"Why is it that the plural of finger is fingers and not hand?\"\n",
        "query_embedding = semb_model.encode(query, convert_to_tensor=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KKagl2pMGZ8N",
      "metadata": {
        "id": "KKagl2pMGZ8N"
      },
      "source": [
        "And measure the running time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VLO-0byOFrHI",
      "metadata": {
        "id": "VLO-0byOFrHI"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# Search using index\n",
        "t_start = datetime.now()\n",
        "_ = index.knn_query(query_embedding.cpu(), k=128)\n",
        "t_stop = datetime.now()\n",
        "print(f\"Search time with index: {t_stop - t_start}\")\n",
        "\n",
        "# Search without index\n",
        "t_start = datetime.now()\n",
        "_ = util.semantic_search(query_embedding, corpus_embeddings, score_function=util.cos_sim, top_k=128)\n",
        "t_stop = datetime.now()\n",
        "print(f\"Search time without index: {t_stop - t_start}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7146c4c7-4dea-4283-bd69-764001ef50dc",
      "metadata": {
        "id": "7146c4c7-4dea-4283-bd69-764001ef50dc"
      },
      "source": [
        "### Re-ranking\n",
        "\n",
        "Cross-encoder models empirically yield better results, but are slow at inference.\n",
        "Embedding models with cosine similarity, on the other side, are less precise, but are also faster at inference.\n",
        "\n",
        "We can take advantage of both: We can do a first search with bi-encoder models and then re-rank the top-$k$ results with a cross-encoder.\n",
        "We call this approach *retrieve and re-rank*.\n",
        "\n",
        "Let's use the ANN index we just computed and a cross encoder model to build a retrieval pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eyIli6VHIYgE",
      "metadata": {
        "id": "eyIli6VHIYgE"
      },
      "source": [
        "Define a query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hCLoQ96wIXjr",
      "metadata": {
        "id": "hCLoQ96wIXjr"
      },
      "outputs": [],
      "source": [
        "query = \"Which is the capital of the United States?\"\n",
        "query_embedding = semb_model.encode(query, convert_to_tensor=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1kw8zAXCIaf8",
      "metadata": {
        "id": "1kw8zAXCIaf8"
      },
      "source": [
        "Search using ANN index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oVtbQRLjIZmT",
      "metadata": {
        "id": "oVtbQRLjIZmT"
      },
      "outputs": [],
      "source": [
        "corpus_ids, distances = index.knn_query(query_embedding.cpu(), k=3)\n",
        "scores = 1 - distances\n",
        "\n",
        "print(\"Cosine similarity model search results\")\n",
        "print(f\"Query: \\\"{query}\\\"\")\n",
        "print(\"---------------------------------------\")\n",
        "for idx, score in zip(corpus_ids[0], scores[0]):\n",
        "    print(f\"Score: {score:.4f}\\nDocument: \\\"{passages[idx]}\\\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6p1evNY2Iqlt",
      "metadata": {
        "id": "6p1evNY2Iqlt"
      },
      "source": [
        "Let's add the re-ranking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3_LdOhYhIq4C",
      "metadata": {
        "id": "3_LdOhYhIq4C"
      },
      "outputs": [],
      "source": [
        "corpus_ids, _ = index.knn_query(query_embedding.cpu(), k=128)\n",
        "\n",
        "model_inputs = [(query, passages[idx]) for idx in corpus_ids[0]]\n",
        "cross_scores = xenc_model.predict(model_inputs)\n",
        "\n",
        "print(\"Cross-encoder model re-ranking results\")\n",
        "print(f\"Query: \\\"{query}\\\"\")\n",
        "print(\"---------------------------------------\")\n",
        "for idx in np.argsort(-cross_scores)[:3]:\n",
        "    print(f\"Score: {cross_scores[idx]:.4f}\\nDocument: \\\"{passages[corpus_ids[0][idx]]}\\\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lDe4L3MFIbfq",
      "metadata": {
        "id": "lDe4L3MFIbfq"
      },
      "source": [
        "Try out other queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "J0isqjMWIdKJ",
      "metadata": {
        "id": "J0isqjMWIdKJ"
      },
      "outputs": [],
      "source": [
        "query = \"What is the best orchestra in the world?\"\n",
        "query_embedding = semb_model.encode(query, convert_to_tensor=True)\n",
        "\n",
        "corpus_ids, _ = index.knn_query(query_embedding.cpu(), k=128)\n",
        "\n",
        "model_inputs = [(query, passages[idx]) for idx in corpus_ids[0]]\n",
        "cross_scores = xenc_model.predict(model_inputs)\n",
        "\n",
        "print(\"Cross-encoder model re-ranking results\")\n",
        "print(f\"Query: \\\"{query}\\\"\")\n",
        "print(\"---------------------------------------\")\n",
        "for idx in np.argsort(-cross_scores)[:3]:\n",
        "    print(f\"Score: {cross_scores[idx]:.4f}\\nDocument: \\\"{passages[corpus_ids[0][idx]]}\\\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rmU626jUIdWs",
      "metadata": {
        "id": "rmU626jUIdWs"
      },
      "outputs": [],
      "source": [
        "query = \"Number countries Europe\"\n",
        "query_embedding = semb_model.encode(query, convert_to_tensor=True)\n",
        "\n",
        "corpus_ids, _ = index.knn_query(query_embedding.cpu(), k=128)\n",
        "\n",
        "model_inputs = [(query, passages[idx]) for idx in corpus_ids[0]]\n",
        "cross_scores = xenc_model.predict(model_inputs)\n",
        "\n",
        "print(\"Cross-encoder model re-ranking results\")\n",
        "print(f\"Query: \\\"{query}\\\"\")\n",
        "print(\"---------------------------------------\")\n",
        "for idx in np.argsort(-cross_scores)[:3]:\n",
        "    print(f\"Score: {cross_scores[idx]:.4f}\\nDocument: \\\"{passages[corpus_ids[0][idx]]}\\\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hsnmCzi6Idi3",
      "metadata": {
        "id": "hsnmCzi6Idi3"
      },
      "outputs": [],
      "source": [
        "query = \"When did the cold war end?\"\n",
        "query_embedding = semb_model.encode(query, convert_to_tensor=True)\n",
        "\n",
        "corpus_ids, _ = index.knn_query(query_embedding.cpu(), k=128)\n",
        "\n",
        "model_inputs = [(query, passages[idx]) for idx in corpus_ids[0]]\n",
        "cross_scores = xenc_model.predict(model_inputs)\n",
        "\n",
        "print(\"Cross-encoder model re-ranking results\")\n",
        "print(f\"Query: \\\"{query}\\\"\")\n",
        "print(\"---------------------------------------\")\n",
        "for idx in np.argsort(-cross_scores)[:3]:\n",
        "    print(f\"Score: {cross_scores[idx]:.4f}\\nDocument: \\\"{passages[corpus_ids[0][idx]]}\\\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39ba866b-244d-4273-9119-f9ad31d80a5b",
      "metadata": {
        "id": "39ba866b-244d-4273-9119-f9ad31d80a5b"
      },
      "source": [
        "## Retrieval-based chatbots\n",
        "\n",
        "During the lectures you have started getting familiar with *chabots* (open-domain conversational agents).\n",
        "\n",
        "We can use these semantic search pipelines to build a retrieval-based chatbot.\n",
        "It is a data-driven kind of chatbot that gets responses from a data set.\n",
        "\n",
        "We can use the same retreive and re-rank pipeline from before, let's start by importing the models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "amISMhw2NgBu",
      "metadata": {
        "id": "amISMhw2NgBu"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer, CrossEncoder, util\n",
        "\n",
        "semb_model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')\n",
        "xenc_model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "I3HENFkbNlDV",
      "metadata": {
        "id": "I3HENFkbNlDV"
      },
      "source": [
        "We are going to use a slightly different appraoch.\n",
        "1. First we are going to rank by similarity of the last user sentence and the sentences in out corpus (the initial matches).\n",
        "2. Then we we are going to extract the response to the matches in our data set. Intuitively, semantic similarity gives us a sentence that is similar to the query one, so we want to get the responses to to a possible match.\n",
        "3. We are going to re-rank the user-message and retreived-response pairs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56a54170-251d-4a23-9013-a9634b4bd046",
      "metadata": {
        "id": "56a54170-251d-4a23-9013-a9634b4bd046"
      },
      "source": [
        "### Dialogue data\n",
        "\n",
        "For this part we are going to use the [EmpatheticDialogues](https://arxiv.org/pdf/1811.00207.pdf) data set, again available via the HuggingFace datasets library"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "723b0ec3-3d42-4e0c-ad12-26369109c15f",
      "metadata": {
        "id": "723b0ec3-3d42-4e0c-ad12-26369109c15f"
      },
      "source": [
        "#### Load\n",
        "\n",
        "Let's start by loading our data set.\n",
        "For simplicity we are going to use only the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ePwU83MHPuyE",
      "metadata": {
        "id": "ePwU83MHPuyE"
      },
      "outputs": [],
      "source": [
        "import datasets\n",
        "\n",
        "empdialogues = datasets.load_dataset('empathetic_dialogues', split='train', trust_remote_code=True)\n",
        "empdialogues[:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "if1Ty18ZQsn9",
      "metadata": {
        "id": "if1Ty18ZQsn9"
      },
      "source": [
        "Now we need to build all the message-response pairs.\n",
        "\n",
        "We start by grouping together the utterances (turns) that belong to the same dialogue.\n",
        "First we convert the data set to a Pandas DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "h5CCmDH9Q8ZT",
      "metadata": {
        "id": "h5CCmDH9Q8ZT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(empdialogues)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GlYJsUZnQ8wU",
      "metadata": {
        "id": "GlYJsUZnQ8wU"
      },
      "source": [
        "Now we can goup the samples and go through individual dialogues to build the pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yNU5sMk1Rwz_",
      "metadata": {
        "id": "yNU5sMk1Rwz_"
      },
      "outputs": [],
      "source": [
        "data_pairs = []\n",
        "# Iterate over dialogues\n",
        "for _, dialogue_df in df.groupby('conv_id', sort=False):\n",
        "    # Extract utterances text\n",
        "    uttrances = dialogue_df['utterance'].values\n",
        "    # Iterarte over pairs\n",
        "    for message, response in zip(uttrances[:-1], uttrances[1:]):\n",
        "        # Add pair to collection\n",
        "        data_pairs.append(\n",
        "            {'message': message.replace('_comma_', ','), 'response': response.replace('_comma_', ',')}\n",
        "        )\n",
        "\n",
        "len(data_pairs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e678963-290c-4ed1-94c2-7e56d9a7fbed",
      "metadata": {
        "id": "8e678963-290c-4ed1-94c2-7e56d9a7fbed"
      },
      "source": [
        "#### Index\n",
        "\n",
        "Now we can embed the messages in our data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "T3-siUaZT0XN",
      "metadata": {
        "id": "T3-siUaZT0XN"
      },
      "outputs": [],
      "source": [
        "corpus_embeddings = semb_model.encode([sample['message'] for sample in data_pairs], convert_to_tensor=True, show_progress_bar=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fUciorFqT0vm",
      "metadata": {
        "id": "fUciorFqT0vm"
      },
      "source": [
        "And we can build an ANN index to do a quick cosine similarity search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EJsloDmiT1PU",
      "metadata": {
        "id": "EJsloDmiT1PU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import hnswlib\n",
        "\n",
        "# Create empty index\n",
        "hnswlib_index = hnswlib.Index(space='cosine', dim=corpus_embeddings.size(1))\n",
        "\n",
        "# Define hnswlib index path\n",
        "index_path = \"./emp_dialogue_hnswlib.index\"\n",
        "\n",
        "# Load index if available\n",
        "if os.path.exists(index_path):\n",
        "    print(\"Loading index...\")\n",
        "    hnswlib_index.load_index(index_path)\n",
        "# Else index data collection\n",
        "else:\n",
        "    # Initialise the index\n",
        "    print(\"Start creating HNSWLIB index\")\n",
        "    hnswlib_index.init_index(max_elements=corpus_embeddings.size(0), ef_construction=400, M=64)\n",
        "    #  Compute the HNSWLIB index (it may take a while)\n",
        "    hnswlib_index.add_items(corpus_embeddings.cpu(), list(range(len(corpus_embeddings))))\n",
        "    # Save the index to a file for future loading\n",
        "    print(\"Saving index to:\", index_path)\n",
        "    hnswlib_index.save_index(index_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97aab601-e10a-40cf-a88f-9918a6d0f786",
      "metadata": {
        "id": "97aab601-e10a-40cf-a88f-9918a6d0f786"
      },
      "source": [
        "### Search for response\n",
        "\n",
        "We are going to search for a response in the following way:\n",
        "1. Search for a similar message to the latest user input.\n",
        "2. Retrieve response associated to the message.\n",
        "2. Re-rank possible responses."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yzyWccwUX0tE",
      "metadata": {
        "id": "yzyWccwUX0tE"
      },
      "source": [
        "#### Retrieval function\n",
        "\n",
        "Let's define a response function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf31044c-404b-4069-bb24-3820dc2269a9",
      "metadata": {
        "id": "bf31044c-404b-4069-bb24-3820dc2269a9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_response(message, mes_resp_pairs, index, re_ranking_model=None, top_k=32):\n",
        "    message_embedding = semb_model.encode(message, convert_to_tensor=True).cpu()\n",
        "\n",
        "    corpus_ids, _ = index.knn_query(message_embedding, k=top_k)\n",
        "\n",
        "    model_inputs = [(message, mes_resp_pairs[idx]['response']) for idx in corpus_ids[0]]\n",
        "    cross_scores = xenc_model.predict(model_inputs)\n",
        "\n",
        "    idx = np.argsort(-cross_scores)[0]\n",
        "\n",
        "    return mes_resp_pairs[corpus_ids[0][idx]]['response']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tRBJNCzDTacH",
      "metadata": {
        "id": "tRBJNCzDTacH"
      },
      "source": [
        "Note that the use of re-ranking is optional (you can pass a none `re_ranking_model`) and the top results to re-score are configurable.\n",
        "You can play a bit with these hyperaparameters to see how responses change."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ZyjivDZX5SO",
      "metadata": {
        "id": "8ZyjivDZX5SO"
      },
      "source": [
        "Let's try out the retreival function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ORqwQqDWX5iD",
      "metadata": {
        "id": "ORqwQqDWX5iD"
      },
      "outputs": [],
      "source": [
        "chatbot_response = get_response(\n",
        "    \"I like going out with my puppies.\", data_pairs, hnswlib_index, re_ranking_model=xenc_model\n",
        ")\n",
        "chatbot_response"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "614a808a-c7f1-4fdd-91e8-443a95720a03",
      "metadata": {
        "id": "614a808a-c7f1-4fdd-91e8-443a95720a03"
      },
      "source": [
        "#### Conversation loop\n",
        "\n",
        "Let's try chatting with our retreival system"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55395e14-1647-4801-a7ef-02489fd13b20",
      "metadata": {
        "id": "55395e14-1647-4801-a7ef-02489fd13b20"
      },
      "outputs": [],
      "source": [
        "# Initialise dialogue history\n",
        "dialogue_history = [\"Hello, how are you?\"]\n",
        "\n",
        "# Start chatting\n",
        "print(\"Press [Ctrl-C] to stop\\n\\n\\n\\n\")\n",
        "print(f\"Chatbot: {dialogue_history[0]}\")\n",
        "# Keep talking until stop\n",
        "running = True\n",
        "while running:\n",
        "    try:\n",
        "        # Read user message\n",
        "        user_message = input(\"User: \")\n",
        "        # Append message to dialogue history\n",
        "        dialogue_history.append(user_message)\n",
        "        # Search for a chatbot response\n",
        "        chatbot_response = get_response(\n",
        "            user_message, data_pairs, hnswlib_index, re_ranking_model=xenc_model\n",
        "        )\n",
        "        # Append chatbot response to dialogue history\n",
        "        dialogue_history.append(chatbot_response)\n",
        "        # Print chatbot response\n",
        "        print(f\"Chatbot: {chatbot_response}\")\n",
        "    except KeyboardInterrupt:\n",
        "        running = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JOk6dbuoWsP1",
      "metadata": {
        "id": "JOk6dbuoWsP1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}